#!/usr/bin/env python3
"""
æ—¶é—´çª—å£é•¿åº¦å®éªŒ - ç»“æœåˆ†æè„šæœ¬

æœ¬è„šæœ¬åˆ†æä¸åŒæ—¶é—´çª—å£é…ç½®ä¸‹çš„æ¨¡å‹æ€§èƒ½ï¼Œ
ç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”åˆ†ææŠ¥å‘Šã€‚

ä½œè€…: MSI5001é¡¹ç›®ç»„
æ—¥æœŸ: 2024å¹´
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def load_results():
    """åŠ è½½æ¨¡å‹è®­ç»ƒç»“æœ"""
    results_path = "../results/model_training_results.csv"
    if not os.path.exists(results_path):
        raise FileNotFoundError("æœªæ‰¾åˆ°æ¨¡å‹è®­ç»ƒç»“æœæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ window_experiment_models.py")
    
    df = pd.read_csv(results_path)
    print(f"åŠ è½½äº† {len(df)} ä¸ªæ¨¡å‹è®­ç»ƒç»“æœ")
    return df

def analyze_window_length_impact(df):
    """åˆ†ææ—¶é—´çª—å£é•¿åº¦å¯¹æ€§èƒ½çš„å½±å“"""
    print("\n=== åˆ†ææ—¶é—´çª—å£é•¿åº¦å¯¹æ€§èƒ½çš„å½±å“ ===")
    
    analysis_results = {}
    
    # æŒ‰é¢„æµ‹è·¨åº¦åˆ†ç»„åˆ†æ
    for forecast_hours in df['forecast_hours'].unique():
        forecast_data = df[df['forecast_hours'] == forecast_hours]
        
        print(f"\né¢„æµ‹è·¨åº¦: {forecast_hours:.1f} å°æ—¶")
        
        # æŒ‰æ¨¡å‹ç±»å‹åˆ†æ
        model_analysis = {}
        for model_type in forecast_data['model_type'].unique():
            model_data = forecast_data[forecast_data['model_type'] == model_type]
            
            # è®¡ç®—ç›¸å…³æ€§
            correlation_r2 = model_data['history_hours'].corr(model_data['r2_score'])
            correlation_rmse = model_data['history_hours'].corr(model_data['rmse'])
            
            # æ‰¾åˆ°æœ€ä½³é…ç½®
            best_idx = model_data['r2_score'].idxmax()
            best_config = model_data.loc[best_idx]
            
            model_analysis[model_type] = {
                'correlation_r2_history': correlation_r2,
                'correlation_rmse_history': correlation_rmse,
                'best_r2': best_config['r2_score'],
                'best_history_hours': best_config['history_hours'],
                'best_config': best_config['config'],
                'performance_trend': 'improving' if correlation_r2 > 0.1 else 'declining' if correlation_r2 < -0.1 else 'stable'
            }
            
            print(f"  {model_type:12} - æœ€ä½³RÂ²: {best_config['r2_score']:.4f} (å†å²çª—å£: {best_config['history_hours']:.1f}h)")
        
        analysis_results[f"{forecast_hours:.1f}h"] = model_analysis
    
    return analysis_results

def create_performance_comparison_plots(df):
    """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
    print("\n=== ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨ ===")
    
    # åˆ›å»ºå¯è§†åŒ–ç›®å½•
    viz_dir = "../visualizations"
    os.makedirs(viz_dir, exist_ok=True)
    
    # 1. RÂ²åˆ†æ•° vs å†å²çª—å£é•¿åº¦
    plt.figure(figsize=(15, 10))
    
    forecast_hours_list = sorted(df['forecast_hours'].unique())
    
    for i, forecast_hours in enumerate(forecast_hours_list):
        plt.subplot(2, 2, i+1)
        forecast_data = df[df['forecast_hours'] == forecast_hours]
        
        for model_type in forecast_data['model_type'].unique():
            model_data = forecast_data[forecast_data['model_type'] == model_type]
            plt.plot(model_data['history_hours'], model_data['r2_score'], 
                    marker='o', label=model_type, linewidth=2, markersize=6)
        
        plt.xlabel('å†å²çª—å£é•¿åº¦ (å°æ—¶)')
        plt.ylabel('RÂ² åˆ†æ•°')
        plt.title(f'é¢„æµ‹è·¨åº¦: {forecast_hours:.1f} å°æ—¶')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"{viz_dir}/r2_vs_history_window.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. RMSE vs å†å²çª—å£é•¿åº¦
    plt.figure(figsize=(15, 10))
    
    for i, forecast_hours in enumerate(forecast_hours_list):
        plt.subplot(2, 2, i+1)
        forecast_data = df[df['forecast_hours'] == forecast_hours]
        
        for model_type in forecast_data['model_type'].unique():
            model_data = forecast_data[forecast_data['model_type'] == model_type]
            plt.plot(model_data['history_hours'], model_data['rmse'], 
                    marker='s', label=model_type, linewidth=2, markersize=6)
        
        plt.xlabel('å†å²çª—å£é•¿åº¦ (å°æ—¶)')
        plt.ylabel('RMSE')
        plt.title(f'é¢„æµ‹è·¨åº¦: {forecast_hours:.1f} å°æ—¶')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"{viz_dir}/rmse_vs_history_window.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    plt.figure(figsize=(12, 8))
    
    # æŒ‰æ¨¡å‹ç±»å‹å’Œå†å²çª—å£é•¿åº¦åˆ†ç»„
    pivot_time = df.pivot_table(values='training_time', 
                               index='history_hours', 
                               columns='model_type', 
                               aggfunc='mean')
    
    for model_type in pivot_time.columns:
        plt.plot(pivot_time.index, pivot_time[model_type], 
                marker='d', label=model_type, linewidth=2, markersize=6)
    
    plt.xlabel('å†å²çª—å£é•¿åº¦ (å°æ—¶)')
    plt.ylabel('å¹³å‡è®­ç»ƒæ—¶é—´ (ç§’)')
    plt.title('è®­ç»ƒæ—¶é—´ vs å†å²çª—å£é•¿åº¦')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦
    
    plt.tight_layout()
    plt.savefig(f"{viz_dir}/training_time_vs_history_window.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 4. çƒ­åŠ›å›¾ - æœ€ä½³é…ç½®æ€»è§ˆ
    plt.figure(figsize=(12, 8))
    
    # åˆ›å»ºæœ€ä½³RÂ²åˆ†æ•°çš„çƒ­åŠ›å›¾
    heatmap_data = df.pivot_table(values='r2_score', 
                                 index='model_type', 
                                 columns='history_hours', 
                                 aggfunc='max')
    
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlBu_r', 
                cbar_kws={'label': 'RÂ² åˆ†æ•°'})
    plt.title('å„æ¨¡å‹åœ¨ä¸åŒå†å²çª—å£é•¿åº¦ä¸‹çš„æœ€ä½³RÂ²åˆ†æ•°')
    plt.xlabel('å†å²çª—å£é•¿åº¦ (å°æ—¶)')
    plt.ylabel('æ¨¡å‹ç±»å‹')
    
    plt.tight_layout()
    plt.savefig(f"{viz_dir}/best_r2_heatmap.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ“ å›¾è¡¨å·²ä¿å­˜åˆ°: {viz_dir}/")

def generate_detailed_report(df, analysis_results):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
    print("\n=== ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š ===")
    
    report_path = "../docs/window_length_analysis_report.md"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# æ—¶é—´çª—å£é•¿åº¦å¯¹é¢„æµ‹æ€§èƒ½å½±å“åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # æ‰§è¡Œæ‘˜è¦
        f.write("## æ‰§è¡Œæ‘˜è¦\n\n")
        f.write("æœ¬æŠ¥å‘Šåˆ†æäº†ä¸åŒå†å²æ—¶é—´çª—å£é•¿åº¦å¯¹å˜å‹å™¨æ²¹æ¸©é¢„æµ‹æ€§èƒ½çš„å½±å“ã€‚")
        f.write("é€šè¿‡ç³»ç»Ÿæ€§å®éªŒï¼Œæˆ‘ä»¬æµ‹è¯•äº†å¤šç§çª—å£é•¿åº¦é…ç½®åœ¨1å°æ—¶ã€1å¤©å’Œ1å‘¨é¢„æµ‹ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚\n\n")
        
        # å®éªŒé…ç½®
        f.write("## å®éªŒé…ç½®\n\n")
        f.write("### æµ‹è¯•çš„æ—¶é—´çª—å£é…ç½®\n\n")
        
        config_summary = df.groupby(['forecast_hours', 'history_hours']).size().reset_index(name='model_count')
        
        for forecast_hours in sorted(config_summary['forecast_hours'].unique()):
            f.write(f"**{forecast_hours:.1f}å°æ—¶é¢„æµ‹**:\n")
            forecast_configs = config_summary[config_summary['forecast_hours'] == forecast_hours]
            for _, row in forecast_configs.iterrows():
                f.write(f"- å†å²çª—å£: {row['history_hours']:.1f}å°æ—¶ ({int(row['history_hours']/0.25)}ä¸ªæ—¶é—´ç‚¹)\n")
            f.write("\n")
        
        f.write("### è¯„ä¼°æ¨¡å‹\n")
        f.write("- **Random Forest**: é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œé€‚åˆå¤„ç†éçº¿æ€§å…³ç³»\n")
        f.write("- **Ridge Regression**: çº¿æ€§å›å½’ï¼Œå…·æœ‰L2æ­£åˆ™åŒ–\n")
        f.write("- **MLP**: å¤šå±‚æ„ŸçŸ¥æœºç¥ç»ç½‘ç»œ\n\n")
        
        f.write("### è¯„ä¼°æŒ‡æ ‡\n")
        f.write("- **RÂ² Score**: å†³å®šç³»æ•°ï¼Œè¡¡é‡æ¨¡å‹è§£é‡Šæ–¹å·®çš„èƒ½åŠ›\n")
        f.write("- **RMSE**: å‡æ–¹æ ¹è¯¯å·®ï¼Œè¡¡é‡é¢„æµ‹ç²¾åº¦\n")
        f.write("- **MAE**: å¹³å‡ç»å¯¹è¯¯å·®\n")
        f.write("- **Training Time**: æ¨¡å‹è®­ç»ƒæ—¶é—´\n\n")
        
        # ä¸»è¦å‘ç°
        f.write("## ä¸»è¦å‘ç°\n\n")
        
        # æœ€ä½³é…ç½®
        f.write("### æœ€ä½³é…ç½®æ€»ç»“\n\n")
        best_configs = df.loc[df.groupby(['forecast_hours', 'model_type'])['r2_score'].idxmax()]
        
        for forecast_hours in sorted(best_configs['forecast_hours'].unique()):
            f.write(f"**{forecast_hours:.1f}å°æ—¶é¢„æµ‹çš„æœ€ä½³é…ç½®**:\n\n")
            forecast_best = best_configs[best_configs['forecast_hours'] == forecast_hours]
            
            for _, row in forecast_best.iterrows():
                f.write(f"- **{row['model_type']}**: ")
                f.write(f"å†å²çª—å£ {row['history_hours']:.1f}å°æ—¶, ")
                f.write(f"RÂ² = {row['r2_score']:.4f}, ")
                f.write(f"RMSE = {row['rmse']:.4f}\n")
            f.write("\n")
        
        # æ€§èƒ½è¶‹åŠ¿åˆ†æ
        f.write("### æ€§èƒ½è¶‹åŠ¿åˆ†æ\n\n")
        
        for forecast_key, models in analysis_results.items():
            f.write(f"**{forecast_key}é¢„æµ‹**:\n\n")
            
            for model_type, analysis in models.items():
                trend_desc = {
                    'improving': 'éšå†å²çª—å£å¢é•¿è€Œæ”¹å–„',
                    'declining': 'éšå†å²çª—å£å¢é•¿è€Œä¸‹é™',
                    'stable': 'ç›¸å¯¹ç¨³å®š'
                }
                
                f.write(f"- **{model_type}**: {trend_desc[analysis['performance_trend']]} ")
                f.write(f"(RÂ²ä¸å†å²çª—å£ç›¸å…³æ€§: {analysis['correlation_r2_history']:.3f})\n")
            f.write("\n")
        
        # è¯¦ç»†ç»“æœè¡¨æ ¼
        f.write("## è¯¦ç»†å®éªŒç»“æœ\n\n")
        
        for forecast_hours in sorted(df['forecast_hours'].unique()):
            f.write(f"### {forecast_hours:.1f}å°æ—¶é¢„æµ‹ç»“æœ\n\n")
            
            forecast_data = df[df['forecast_hours'] == forecast_hours]
            
            # åˆ›å»ºç»“æœè¡¨æ ¼
            f.write("| å†å²çª—å£(h) | æ¨¡å‹ç±»å‹ | RÂ² Score | RMSE | MAE | è®­ç»ƒæ—¶é—´(s) |\n")
            f.write("|-------------|----------|----------|------|-----|-------------|\n")
            
            for _, row in forecast_data.sort_values(['history_hours', 'model_type']).iterrows():
                f.write(f"| {row['history_hours']:.1f} | {row['model_type']} | ")
                f.write(f"{row['r2_score']:.4f} | {row['rmse']:.4f} | ")
                f.write(f"{row['mae']:.4f} | {row['training_time']:.2f} |\n")
            
            f.write("\n")
        
        # å…³é”®æ´å¯Ÿ
        f.write("## å…³é”®æ´å¯Ÿä¸å»ºè®®\n\n")
        
        # æ‰¾å‡ºæ•´ä½“æœ€ä½³æ¨¡å‹
        overall_best = df.loc[df['r2_score'].idxmax()]
        f.write(f"### æ•´ä½“æœ€ä½³é…ç½®\n\n")
        f.write(f"- **æ¨¡å‹**: {overall_best['model_type']}\n")
        f.write(f"- **é¢„æµ‹è·¨åº¦**: {overall_best['forecast_hours']:.1f}å°æ—¶\n")
        f.write(f"- **å†å²çª—å£**: {overall_best['history_hours']:.1f}å°æ—¶\n")
        f.write(f"- **æ€§èƒ½**: RÂ² = {overall_best['r2_score']:.4f}, RMSE = {overall_best['rmse']:.4f}\n\n")
        
        # è®¡ç®—æ”¹è¿›æ•ˆæœ
        f.write("### çª—å£é•¿åº¦ä¼˜åŒ–æ•ˆæœ\n\n")
        
        for forecast_hours in sorted(df['forecast_hours'].unique()):
            forecast_data = df[df['forecast_hours'] == forecast_hours]
            
            for model_type in forecast_data['model_type'].unique():
                model_data = forecast_data[forecast_data['model_type'] == model_type]
                
                if len(model_data) > 1:
                    best_r2 = model_data['r2_score'].max()
                    worst_r2 = model_data['r2_score'].min()
                    improvement = ((best_r2 - worst_r2) / worst_r2) * 100
                    
                    f.write(f"- **{model_type}** ({forecast_hours:.1f}hé¢„æµ‹): ")
                    f.write(f"æœ€ä¼˜çª—å£ç›¸æ¯”æœ€å·®çª—å£æå‡ {improvement:.1f}%\n")
        
        f.write("\n### å®ç”¨å»ºè®®\n\n")
        f.write("1. **çŸ­æœŸé¢„æµ‹(1å°æ—¶)**: å»ºè®®ä½¿ç”¨è¾ƒé•¿çš„å†å²çª—å£ä»¥æ•è·æ›´å¤šæ¨¡å¼\n")
        f.write("2. **ä¸­æœŸé¢„æµ‹(1å¤©)**: å¹³è¡¡å†å²ä¿¡æ¯é‡ä¸è®¡ç®—æ•ˆç‡\n")
        f.write("3. **é•¿æœŸé¢„æµ‹(1å‘¨)**: å…³æ³¨é•¿æœŸè¶‹åŠ¿ï¼Œé¿å…è¿‡åº¦æ‹ŸåˆçŸ­æœŸæ³¢åŠ¨\n")
        f.write("4. **æ¨¡å‹é€‰æ‹©**: Random Foresté€šå¸¸è¡¨ç°æœ€ä½³ï¼ŒMLPé€‚åˆå¤æ‚æ¨¡å¼è¯†åˆ«\n")
        f.write("5. **è®¡ç®—èµ„æº**: è€ƒè™‘è®­ç»ƒæ—¶é—´ä¸æ€§èƒ½çš„æƒè¡¡\n\n")
        
        # å±€é™æ€§å’Œæœªæ¥å·¥ä½œ
        f.write("## å±€é™æ€§ä¸æœªæ¥å·¥ä½œ\n\n")
        f.write("### å½“å‰å±€é™æ€§\n")
        f.write("- å®éªŒåŸºäºå•ä¸€æ•°æ®é›†ï¼Œæ³›åŒ–æ€§æœ‰å¾…éªŒè¯\n")
        f.write("- æœªè€ƒè™‘å­£èŠ‚æ€§å’Œå‘¨æœŸæ€§å› ç´ çš„å½±å“\n")
        f.write("- è®¡ç®—èµ„æºé™åˆ¶äº†æ›´å¤§çª—å£é•¿åº¦çš„æµ‹è¯•\n\n")
        
        f.write("### æœªæ¥æ”¹è¿›æ–¹å‘\n")
        f.write("- æµ‹è¯•æ›´å¤šæ ·åŒ–çš„æ•°æ®é›†\n")
        f.write("- å¼•å…¥è‡ªé€‚åº”çª—å£é•¿åº¦é€‰æ‹©æœºåˆ¶\n")
        f.write("- ç»“åˆé¢†åŸŸçŸ¥è¯†ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹\n")
        f.write("- æ¢ç´¢æ·±åº¦å­¦ä¹ æ¨¡å‹çš„çª—å£é•¿åº¦æ•æ„Ÿæ€§\n\n")
        
        f.write("---\n")
        f.write("*æœ¬æŠ¥å‘Šç”±MSI5001é¡¹ç›®ç»„è‡ªåŠ¨ç”Ÿæˆ*\n")
    
    print(f"âœ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("=== æ—¶é—´çª—å£é•¿åº¦å®éªŒ - ç»“æœåˆ†æ ===")
    print("åˆ†æä¸åŒå†å²çª—å£é•¿åº¦å¯¹é¢„æµ‹æ€§èƒ½çš„å½±å“\n")
    
    try:
        # åŠ è½½ç»“æœ
        df = load_results()
        
        # åˆ†æçª—å£é•¿åº¦å½±å“
        analysis_results = analyze_window_length_impact(df)
        
        # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        create_performance_comparison_plots(df)
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        generate_detailed_report(df, analysis_results)
        
        print(f"\n{'='*60}")
        print("âœ“ åˆ†æå®Œæˆï¼")
        print("âœ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  - ../docs/window_length_analysis_report.md (è¯¦ç»†æŠ¥å‘Š)")
        print("  - ../visualizations/*.png (æ€§èƒ½å¯¹æ¯”å›¾è¡¨)")
        print(f"\næ€»ç»“:")
        print(f"- æµ‹è¯•äº† {len(df)} ä¸ªæ¨¡å‹é…ç½®")
        print(f"- æ¶µç›– {len(df['forecast_hours'].unique())} ç§é¢„æµ‹è·¨åº¦")
        print(f"- ä½¿ç”¨ {len(df['model_type'].unique())} ç§æ¨¡å‹ç±»å‹")
        
        # æ˜¾ç¤ºæœ€ä½³é…ç½®
        best_overall = df.loc[df['r2_score'].idxmax()]
        print(f"\nğŸ† æ•´ä½“æœ€ä½³é…ç½®:")
        print(f"   {best_overall['model_type']} - {best_overall['forecast_hours']:.1f}hé¢„æµ‹")
        print(f"   å†å²çª—å£: {best_overall['history_hours']:.1f}h, RÂ²: {best_overall['r2_score']:.4f}")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()