# 项目结构与模型推导审查报告

## 审查范围与方法
- 阅读并核对仓库根目录的 `README.md`、`PROJECT_STRUCTURE.md` 与 `docs/project_report.md` 等文档。
- 审查 `scripts/preprocessing/optimized_preprocessing.py`、`scripts/models/simple_ml_models.py`、`scripts/models/simple_deep_models.py` 的核心实现。
- 对比文档描述与实现细节，评估结构设计、可读性以及模型推导的合理性。

## 项目结构与文档一致性
- 根目录 `README.md` 和 `docs/README.md` 都将主要脚本列在仓库根目录，但真实路径位于 `scripts/` 子目录，容易导致使用者在根目录找不到文件。
- `PROJECT_STRUCTURE.md` 指出了 `data/` 目录及其 CSV/NPY 文件，但仓库未提供这些数据，且预处理脚本直接从工作目录读取 `trans_1.csv`、`trans_2.csv`，缺乏清晰的数据获取说明。
- 文档声称“所有模型都经过了交叉验证”，但训练脚本仅做一次随机划分，未实现交叉验证流程，容易误导读者。
- `docs/project_report.md` 宣称使用“时间分组策略”，但代码采用 `shuffle=True` 的随机分割；该差异会造成时间序列上的信息泄露，与报告描述不符。

## 数据预处理流程评估
- 标准化器在拆分数据前对全部样本拟合，包含未来信息，违背时间序列建模的因果性，建议仅在训练集上拟合再对验证/测试集变换。
- `train_test_split(..., shuffle=True)` 会打乱时间顺序，与预测未来场景相悖；应改用时间切分或滑动窗口评估。
- `create_sequences` 将三维时间序列展平成一维向量并固定窗口长度，各配置最多生成 10,000 条序列；后续训练又只随机抽取 2,000 条样本，导致大量信息被丢弃。

## 模型推导与实验设计
- 三种预测配置的回溯窗口长度（4/8/16 小时）与预测跨度（1 小时/1 天/1 周）不成比例，缺乏对中长期预测所需信息的论证，难以支撑报告中对模型性能的解释。
- 模型层面仅比较线性模型、固定参数的随机森林与三种规模的 `MLPRegressor`，没有实际的超参数调优流程，与报告中提到的“全面对比”“深度模型优化不足”存在差距。
- 深度学习脚本依赖先运行传统模型生成的 CSV，再追加写入；若直接执行深度学习脚本会因缺失 `simple_ml_results.csv` 报错，流程耦合紧密但文档未说明依赖顺序。

## 可读性与可维护性
- 脚本结构清晰，函数职责单一，但缺少类型注解与参数文档，难以快速了解输入输出格式。
- 多处硬编码常量（窗口长度、最大样本数、MLP结构）未集中配置，后续调参需要修改多处代码，可考虑集中于配置文件或字典中管理。

## 结论与建议
1. **同步文档与代码**：更新 README 和报告，使路径、数据获取方式、评估策略与实现保持一致；明确运行脚本的依赖顺序和输入数据位置。
2. **修正数据泄露风险**：在拆分前保留时间顺序，仅用训练集拟合标准化器，并采用时间序列交叉验证或滚动窗口评估。
3. **完善模型推导**：为长跨度预测提供更长的历史窗口或附加特征，补充超参数搜索或模型对比的实验依据，并在报告中解释参数选择逻辑。
4. **提高可维护性**：引入配置化设计、类型注解和日志记录，方便后续扩展与调试。

> 本报告反映了文档与代码之间的主要不一致、潜在的数据泄露问题以及模型设计上的不足，建议优先修正数据流程与文档，再迭代模型实验。
