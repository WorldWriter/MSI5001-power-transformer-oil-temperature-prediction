Grading Criteria
The project is graded out of 100 marks, but only comments and final letter grades
(derived from your score) will be released. The grading scheme, report format, and
presentation requirements are outlined below:
2.1 Technical Implementation – 30%
This criteria evaluates the quality, correctness, and clarity of your AI model and data
workflow.
1. Clean Data Pipeline: Demonstrates proper preprocessing, including handling of
missing values, encoding of categorical variables, feature scaling, and effective
feature selection or engineering.
2. Appropriate Model Choice: Selects AI models that are well-suited to the dataset
and problem type.
3. Baseline Model Comparison: Includes a simple, meaningful baseline model (e.g.,
majority class predictor or mean regressor) for benchmarking performance.
4. Readability & Reproducibility: Code is well-organized, commented, and easy to
follow. The notebook (e.g., Colab/Jupyter) should allow another person (including
the grader) to run and understand the workflow without needing clarification.
5. Creativity / Customization: Shows thoughtful adaptation of models or pipeline
design to improve performance, robustness, or domain relevance.
2.2 Evaluation & Insight – 20%
This criteria assesses how well the model’s performance is measured, interpreted, and
connected back to the problem context.
1. Use of Appropriate Metrics: Evaluation metrics are correctly chosen based on the
machine learning task, and align with the project’s goals.
2. Clarity of Evaluation Process: The evaluation strategy (e.g., train/test split, crossvalidation) is clearly explained and correctly implemented.
3. Baseline Comparison: Results are compared against a meaningful baseline, showing how the chosen model performs relative to a simple benchmark.
4. Interpretation of Results: Results are clearly explained in relation to the original
problem, highlighting key takeaways, surprising findings, or practical implications.
5. Limitations & Error Analysis (Encouraged): Discussion includes possible reasons for poor performance, sources of error, or constraints due to data quality, model
assumptions, or overfitting.
2.3 Report & Presentation – 30%
This component evaluates how clearly and effectively your work is communicated, both
in writing and during the final presentation. The report must adhere to the specified
format provided here2.
2.3.1 Report – 15%
• Structure: Report follows a clear and logical format — Introduction, Methodology,
Results, Insights, Conclusion. The main report should be 2 pages, with additional
2 pages for appendix to add references, additional figures, tables, etc.
• Language: Writing is concise, coherent, and professional. Follows the prescribed
formatting guidelines (e.g., font size, spacing, page limit).
• Visuals: Tables, charts, and diagrams are used effectively to present results and
support key points.
• References: All external resources — including datasets, tools, academic works,
or conceptual inspiration — are properly cited.
2.3.2 Presentation – 15%
• Slide Design: Slides are visually clean, with readable fonts, meaningful headings,
and minimal clutter. Visuals aid understanding.
• Flow: Problem → Data → Model → Results → Insights. Your presentation should
follow a clear and logical flow, starting from the problem definition, followed by
an overview of the dataset, explanation of the model(s) used, presentation of the
results, and concluding with key insights or takeaways.
• Delivery: All team members actively participate. Presenters speak clearly, stay
within time limits, and demonstrate strong grasp of the
Additional Guidelines
• Citing External Sources: Acknowledge all external resources, including code, AIgenerated content, or reference material, in the report, code, or slides. Failure to
do so may incur penalties.
• Tracking Contributions: Use collaborative platforms (e.g., Google Docs, Slides) to
document contributions; this may be used for dispute resolution (if any).
• Planning Workload: Agree early on workload distribution to ensure smooth collaboration.
• Comprehension Over Execution: Not everyone must code, but all members should
understand the project and be able to explain it clearly.
• Responsible AI Tool Use: Tools like ChatGPT or GitHub Copilot may assist your
work, but usage must be declared. You will be evaluated on understanding and
application of concepts, not the tool’s output.