# 变压器油温预测实验方案 / Power Transformer Oil Temperature Prediction Experiment Plan

基于公开的ETT (Electric Transformer Temperature) 数据集，设计一个系统化的实验方案，评估各个因素对时序预测模型性能的影响。

---

## 实验目标 / Objectives

1. **理解各因素影响**：系统地分析每个维度对模型性能的独立贡献
2. **找到最优配置**：确定在该数据集上表现最佳的模型和参数组合
3. **验证泛化能力**：在不同数据分布上测试模型的鲁棒性

---

## 实验设计原则 / Design Principles

### 1. 控制变量法 (Controlled Variable Method)

- **每次只改变一个维度**，固定其他参数
- 确保实验结果的可归因性
- 避免混淆变量的影响

### 2. 分阶段推进策略 (Staged Progression)

- **从基础到高级**：先建立基准，再逐步优化
- **每阶段基于前一阶段的最优配置**：避免在次优基础上调优
- **支持早停**：如某阶段发现无显著改进，可跳过后续细粒度调优

### 3. 数据集选择策略 (Dataset Strategy)

- **主实验数据集**：train2.csv（数值范围更大，更容易训练）
- **验证数据集**：train1.csv（不同数据分布，测试泛化能力）
- **避免指数爆炸**：在单一数据集上充分实验，最后交叉验证

---

## 实验维度概览 / Experiment Dimensions Overview

| 维度 | 测试值 | 测试阶段 | 重要性 |
|------|--------|----------|--------|
| **1. 算法类型** | Linear / RNN / LSTM / GRU | 阶段1, 5 | ⭐⭐⭐⭐⭐ |
| **2. 预测场景** | 1小时 / 1天 / 1周 | 所有阶段 | ⭐⭐⭐⭐⭐ |
| **3. 数据异常值剔除** | 无 / 0.5% / 1% / 5% | 阶段2 | ⭐⭐⭐ |
| **4. 训练/测试划分方式** | sequential / random / label_random | 阶段2 | ⭐⭐⭐⭐ |
| **5. 时间特征** | 有 / 无 | 阶段3 | ⭐⭐⭐ |
| **6. 自变量特征数量** | 全部6个 / 筛选3-4个 | 阶段3 | ⭐⭐ |
| **7. 时间窗口长度** | 8 / 16 / 32 / 64 | 阶段4 | ⭐⭐⭐⭐ |
| **8. 学习率** | 0.0001 / 0.001 / 0.01 | 阶段6 | ⭐⭐⭐ |
| **9. Batch size** | 16 / 32 / 64 / 128 | 阶段6 | ⭐⭐ |
| **10. 隐藏层大小** | 32 / 64 / 128 | 阶段6 | ⭐⭐⭐ |
| **11. Dropout率** | 0.0 / 0.2 / 0.4 | 阶段6 | ⭐⭐ |

---

## 详细实验阶段设计 / Detailed Stage Design

### 阶段1：建立基准 (Baseline) - 6个模型

#### 目标
确定各预测场景的基准性能，比较 Linear 和 RNN 两种基础算法

#### 实验配置

**固定参数**：
- 数据集：train2.csv（69,680行，6个负载特征）
- 异常值处理：无
- 时间特征：无（仅使用6个负载特征：HUFL, HULL, MUFL, MULL, LUFL, LULL）
- 数据划分：sequential（前80%训练，后20%测试，避免数据泄露）
- seq_length：16
- 学习率：0.001
- batch_size：32
- num_epochs：100
- early_stopping_patience：10

**变化维度**：
- **算法**：Linear, RNN
- **预测场景**：
  - 1小时预测：offset=4（使用t-20到t-4的数据预测t时刻）
  - 1天预测：offset=96（使用t-112到t-96的数据预测t时刻）
  - 1周预测：offset=672（使用t-688到t-672的数据预测t时刻）

#### 模型计算
```
算法数量：2 (Linear, RNN)
预测场景：3 (1h, 1d, 1w)
总模型数 = 2 × 3 = 6个模型
```

#### 实验ID示例
- `stage1_linear_h`：Linear模型，1小时预测
- `stage1_rnn_d`：RNN模型，1天预测
- `stage1_linear_w`：Linear模型，1周预测

#### 预期输出
- 确定哪个算法在不同预测范围下表现更好
- 建立后续阶段的基准R²和MAE
- 识别预测难度：1小时 < 1天 < 1周（通常）

---

### 阶段2：数据预处理影响分析 - 10个模型

#### 目标
评估异常值处理和数据划分方式对模型性能的影响

#### 基准配置
- **算法**：阶段1中R²最高的模型（Linear 或 RNN）
- **预测场景**：主要在**1小时**测试（最快迭代），最后在3个场景验证
- 其他参数：同阶段1

#### 子实验 2.1：异常值剔除比例测试 - 4个模型

**测试配置**：
- 无异常值处理（baseline）
- 0.5% 阈值（Z-score=3.0，约移除69,680 × 0.005 ≈ 350行）
- 1.0% 阈值（约移除700行）
- 5.0% 阈值（约移除3,500行）

**异常值检测方法**：Z-score方法
```python
# 对每个特征计算Z-score
z_scores = (df[feature] - df[feature].mean()) / df[feature].std()
# 标记 |z_score| > threshold 的行为异常值
```

**模型计算**：4个异常值配置 × 1个场景（1小时）= **4个模型**

**实验ID示例**：
- `stage2_outlier_none_h`
- `stage2_outlier_05pct_h`
- `stage2_outlier_1pct_h`
- `stage2_outlier_5pct_h`

#### 子实验 2.2：数据划分方式测试 - 3个模型

**测试配置**：
- **sequential**：时序分割（前80%训练，后20%测试）
  - 优点：无数据泄露，最接近真实预测场景
  - 缺点：测试集仅覆盖时间末段

- **random**：分组随机
  - 将数据分为20组（每组约3,484个样本）
  - 随机选择16组（80%）训练，4组（20%）测试
  - 优点：测试集覆盖整个时间范围
  - 缺点：可能存在轻微数据泄露（组内连续）

- **label_random**：完全随机
  - 随机打乱所有样本，按80/20分割
  - 优点：充分利用数据
  - 缺点：存在数据泄露（滑动窗口重叠）
  - 注意：R²可能虚高！

**模型计算**：3个划分方式 × 1个场景（1小时）= **3个模型**

**实验ID示例**：
- `stage2_split_sequential_h`
- `stage2_split_random_h`
- `stage2_split_label_random_h`

#### 子实验 2.3：最优组合验证 - 3个模型

**配置**：
- 使用2.1的最优异常值处理方法
- 使用2.2的最优数据划分方式
- 在**3个预测场景**（1h/1d/1w）下验证

**模型计算**：1个最优组合 × 3个场景 = **3个模型**

**实验ID示例**：
- `stage2_best_combo_h`
- `stage2_best_combo_d`
- `stage2_best_combo_w`

#### 阶段2总计
4 + 3 + 3 = **10个模型**

---

### 阶段3：特征工程影响分析 - 12个模型

#### 目标
评估时间特征和负载特征选择对模型性能的影响

#### 基准配置
- **算法**：阶段1的最优算法
- **数据预处理**：阶段2的最优配置
- 其他参数：同阶段1

#### 子实验 3.1：时间特征影响 - 6个模型

**测试配置**：
- **无时间特征**（baseline）：
  - 特征：6个负载特征（HUFL, HULL, MUFL, MULL, LUFL, LULL）
  - 特征数量：6

- **有时间特征**：
  - 负载特征：6个
  - 时间特征：5个（hour, dayofweek, month, day, is_weekend）
  - 特征数量：11

**时间特征提取**：
```python
df['hour'] = df['date'].dt.hour            # 0-23
df['dayofweek'] = df['date'].dt.dayofweek  # 0-6 (Monday=0)
df['month'] = df['date'].dt.month          # 1-12
df['day'] = df['date'].dt.day              # 1-31
df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)  # 0 or 1
```

**模型计算**：2个配置 × 3个场景 = **6个模型**

**实验ID示例**：
- `stage3_time_no_time_h`：无时间特征，1小时预测
- `stage3_time_with_time_h`：有时间特征，1小时预测

#### 子实验 3.2：特征选择影响 - 6个模型

**测试配置**：
- **全部负载特征**（baseline）：
  - 6个特征：HUFL, HULL, MUFL, MULL, LUFL, LULL

- **筛选负载特征**：
  - 基于与OT的皮尔逊相关系数，选择Top 3-4个特征
  - 示例：如果相关性排序为 HUFL > HULL > MUFL > MULL > LUFL > LULL
  - 则选择：HUFL, HULL, MUFL, MULL

**相关性分析**（在阶段3开始前执行）：
```python
correlations = df[['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL']].corrwith(df['OT'])
top_features = correlations.abs().sort_values(ascending=False).head(4).index.tolist()
```

**模型计算**：2个配置 × 3个场景 = **6个模型**

**实验ID示例**：
- `stage3_feat_all_h`：全部6个负载特征
- `stage3_feat_selected_h`：筛选后的3-4个特征

#### 阶段3总计
6 + 6 = **12个模型**

---

### 阶段4：时间窗口长度影响 - 12个模型

#### 目标
确定最优的输入序列长度（seq_length）

#### 基准配置
- **算法**：阶段1的最优算法
- **数据预处理**：阶段2的最优配置
- **特征配置**：阶段3的最优配置
- 其他参数：同阶段1

#### 实验配置

**测试seq_length**：
- **8**：较短的历史窗口（约2小时，15分钟 × 8）
- **16**：中等窗口（约4小时）【默认值】
- **32**：较长窗口（约8小时）
- **64**：长窗口（约16小时）

**权衡**：
- seq_length越大：
  - ✅ 优点：包含更多历史信息
  - ❌ 缺点：模型参数增多，训练时间增加，可能过拟合
- seq_length越小：
  - ✅ 优点：模型简单，训练快速
  - ❌ 缺点：历史信息不足，可能欠拟合

**模型计算**：4个seq_length × 3个场景 = **12个模型**

**实验ID示例**：
- `stage4_seq8_h`：seq_length=8，1小时预测
- `stage4_seq32_d`：seq_length=32，1天预测

---

### 阶段5：算法对比 - 12个模型

#### 目标
比较不同深度学习算法在最优配置下的性能

#### 基准配置
- **数据预处理**：阶段2的最优配置
- **特征配置**：阶段3的最优配置
- **时间窗口**：阶段4的最优seq_length
- 其他参数：同阶段1

#### 实验配置

**测试算法**：

1. **Linear (多层全连接网络)**
   ```python
   input: (batch, seq_length, num_features)
   flatten: (batch, seq_length * num_features)
   fc1: hidden_sizes[0] (例如64)
   relu + dropout
   fc2: hidden_sizes[1] (例如32)
   relu + dropout
   output: 1
   ```

2. **RNN (循环神经网络)**
   ```python
   input: (batch, seq_length, num_features)
   rnn: hidden_size=64, num_layers=2
   output: last hidden state
   fc: 1
   ```

3. **LSTM (长短期记忆网络)**
   ```python
   input: (batch, seq_length, num_features)
   lstm: hidden_size=64, num_layers=2
   output: last hidden state
   fc: 1
   ```

4. **GRU (门控循环单元)**
   ```python
   input: (batch, seq_length, num_features)
   gru: hidden_size=64, num_layers=2
   output: last hidden state
   fc: 1
   ```

**模型计算**：4个算法 × 3个场景 = **12个模型**

**实验ID示例**：
- `stage5_linear_h`
- `stage5_lstm_d`
- `stage5_gru_w`

**预期对比**：
- Linear：适合线性关系
- RNN：适合短序列，训练快
- LSTM：适合长序列，防止梯度消失
- GRU：LSTM的简化版，参数更少

---

### 阶段6：超参数精调 - 15-27个模型

#### 目标
找到最优超参数组合，最大化模型性能

#### 基准配置
- **算法**：阶段5的最优算法
- **数据预处理**：阶段2的最优配置
- **特征配置**：阶段3的最优配置
- **时间窗口**：阶段4的最优seq_length

#### 策略
- **主测试场景**：仅在**1小时预测**测试（最快迭代）
- **最终验证**：将最优超参数组合应用到3个场景

#### 子实验 6.1：学习率 - 3个模型

**测试值**：
- 0.0001：较小，收敛慢但稳定
- 0.001：默认值【baseline】
- 0.01：较大，收敛快但可能不稳定

**模型计算**：3个学习率 × 1个场景（1h）= **3个模型**

#### 子实验 6.2：Batch size - 3个模型

**测试值**：
- 16：小batch，梯度估计噪声大，正则化效果强
- 32：默认值【baseline】
- 64：大batch，梯度估计准确，训练快

**模型计算**：3个batch size × 1个场景（1h）= **3个模型**

#### 子实验 6.3：隐藏层大小 - 3个模型

**测试值**（针对RNN系列）：
- 32：较小，参数少
- 64：默认值【baseline】
- 128：较大，表达能力强

**对于Linear模型**：调整hidden_sizes列表

**模型计算**：3个hidden size × 1个场景（1h）= **3个模型**

#### 子实验 6.4：Dropout率 - 3个模型

**测试值**：
- 0.0：无dropout
- 0.2：默认值【baseline】
- 0.4：较强的正则化

**模型计算**：3个dropout × 1个场景（1h）= **3个模型**

#### 子实验 6.5：最优超参数验证 - 3个模型

**配置**：
- 学习率：6.1的最优值
- Batch size：6.2的最优值
- Hidden size：6.3的最优值
- Dropout：6.4的最优值

**模型计算**：1个最优组合 × 3个场景 = **3个模型**

#### 阶段6总计（保守估算）
3 + 3 + 3 + 3 + 3 = **15个模型**

**如果做网格搜索**（可选）：
3学习率 × 3batch size × 3hidden size × 3dropout = 81个组合
选择Top 9个组合验证，再加上3个场景验证 = **12-27个模型**

---

### 阶段7：最终验证与消融实验 - 9个模型

#### 目标
- 在不同数据分布上验证模型泛化能力
- 通过消融实验验证关键组件的贡献

#### 基准配置
使用**阶段1-6的所有最优配置**

#### 子实验 7.1：train1数据集验证 - 3个模型

**配置**：
- 数据集：切换到**train1.csv**
- 其他参数：完全相同的最优配置

**目的**：
- train2.csv：负载值范围 ~3-42，OT范围 ~37-39°C
- train1.csv：负载值范围 ~1-6，OT范围 ~27-31°C
- 测试模型在不同数据分布下的鲁棒性

**模型计算**：1个最优配置 × 3个场景 = **3个模型**

**实验ID示例**：
- `stage7_train1_h`
- `stage7_train1_d`
- `stage7_train1_w`

#### 子实验 7.2：消融实验 (Ablation Study) - 6个模型

**数据集**：回到train2.csv

**消融场景**：

1. **移除时间特征**（如果阶段3证明时间特征有用）
   - 配置：使用最优配置，但time_features = []
   - 目的：量化时间特征的贡献
   - 在3个场景测试 = **3个模型**

2. **移除异常值处理**（如果阶段2证明异常值处理有用）
   - 配置：使用最优配置，但remove_outliers = False
   - 目的：量化异常值处理的贡献
   - 在3个场景测试 = **3个模型**

**模型计算**：2个消融 × 3个场景 = **6个模型**

**实验ID示例**：
- `stage7_ablation_no_time_h`：移除时间特征，1小时预测
- `stage7_ablation_no_outlier_d`：移除异常值处理，1天预测

#### 阶段7总计
3 + 6 = **9个模型**

---

## 模型数量统计 / Model Count Summary

### 详细计算

| 阶段 | 实验内容 | 计算公式 | 模型数 | 累计 |
|------|----------|----------|--------|------|
| 1 | 建立基准 | 2算法 × 3场景 | 6 | 6 |
| 2.1 | 异常值剔除 | 4配置 × 1场景 | 4 | 10 |
| 2.2 | 数据划分 | 3配置 × 1场景 | 3 | 13 |
| 2.3 | 最优组合验证 | 1组合 × 3场景 | 3 | 16 |
| 3.1 | 时间特征 | 2配置 × 3场景 | 6 | 22 |
| 3.2 | 特征选择 | 2配置 × 3场景 | 6 | 28 |
| 4 | 时间窗口 | 4窗口 × 3场景 | 12 | 40 |
| 5 | 算法对比 | 4算法 × 3场景 | 12 | 52 |
| 6.1-6.4 | 超参数调优 | 4类超参数 × 3值 × 1场景 | 12 | 64 |
| 6.5 | 最优超参数验证 | 1组合 × 3场景 | 3 | 67 |
| 7.1 | train1验证 | 1配置 × 3场景 | 3 | 70 |
| 7.2 | 消融实验 | 2消融 × 3场景 | 6 | 76 |

### 总计算公式

```
总模型数 = 6 + (4+3+3) + (6+6) + 12 + 12 + (12+3) + (3+6)
         = 6 + 10 + 12 + 12 + 12 + 15 + 9
         = 76个模型

如果阶段6做完整网格搜索：76 + 12 = 88个模型
```

### 避免指数爆炸的策略

**如果所有维度组合**（假设）：
- 2算法 × 3场景 × 4异常值 × 3划分 × 2时间特征 × 2特征选择 × 4窗口 × 3学习率 × 3batch × 3hidden × 3dropout
- = 2 × 3 × 4 × 3 × 2 × 2 × 4 × 3 × 3 × 3 × 3
- = **279,936个模型** ❌ **指数爆炸！**

**我们的方案**：
- ✅ **控制变量法**：每次只变一个维度
- ✅ **分阶段推进**：基于前一阶段最优配置
- ✅ **部分场景测试**：阶段2、6仅在1小时场景初步测试
- ✅ **最终仅76-88个模型**

---

## 预期时间估算 / Time Estimation

### 单模型训练时间（估算）

| 模型类型 | seq_length | Epochs | 预计时间 |
|----------|------------|--------|----------|
| Linear | 16 | 100 | 2-5分钟 |
| RNN | 16 | 100 | 3-6分钟 |
| LSTM | 16 | 100 | 4-7分钟 |
| GRU | 16 | 100 | 3-6分钟 |

**影响因素**：
- Early stopping可能提前结束（平均60-80 epochs）
- seq_length增大会延长训练时间
- batch_size增大会缩短训练时间

### 各阶段时间估算

| 阶段 | 模型数 | 平均时间/模型 | 总时间 |
|------|--------|--------------|--------|
| 1 | 6 | 4分钟 | 24分钟 |
| 2 | 10 | 3分钟 | 30分钟 |
| 3 | 12 | 4分钟 | 48分钟 |
| 4 | 12 | 5分钟 | 60分钟 |
| 5 | 12 | 5分钟 | 60分钟 |
| 6 | 15 | 3分钟 | 45分钟 |
| 7 | 9 | 4分钟 | 36分钟 |

**总计：约5-6小时**

**优化建议**：
- 支持**断点续传**：中断后可继续
- 可**分多天完成**：每天完成1-2个阶段
- 可**并行运行**：如有多个GPU

---

## 评估指标 / Evaluation Metrics

### 主要指标

1. **R² Score (决定系数)**
   - 范围：(-∞, 1]，1表示完美拟合
   - 公式：R² = 1 - (SS_res / SS_tot)
   - **主要对比指标**：用于排序模型性能
   - 目标：R² > 0.7（可接受），R² > 0.85（优秀）

2. **MSE (均方误差)**
   - 范围：[0, +∞)，越小越好
   - 公式：MSE = mean((y_true - y_pred)²)
   - 用途：训练损失函数

3. **MAE (平均绝对误差)**
   - 范围：[0, +∞)，越小越好
   - 单位：℃（温度）
   - 公式：MAE = mean(|y_true - y_pred|)
   - **可解释性强**：直接表示平均预测偏差

### 次要指标

4. **Training Time (训练时间)**
   - 单位：秒
   - 用途：效率对比

5. **Model Parameters (模型参数量)**
   - 用途：模型复杂度对比

---

## 实验结果记录 / Results Recording

所有实验结果统一记录到 `experiments/results.csv`：

### CSV字段结构

| 字段类别 | 字段名 | 说明 |
|----------|--------|------|
| **标识** | experiment_id | 唯一ID，如stage1_linear_h |
|  | stage | 阶段编号 (1-7) |
| **数据** | dataset | 数据集名称 (train1/train2) |
| **模型** | model_type | 算法类型 (linear/rnn/lstm/gru) |
|  | prediction_scenario | 预测场景 (hour/day/week) |
|  | offset | 预测偏移量 (4/96/672) |
|  | seq_length | 序列长度 (8/16/32/64) |
| **预处理** | outlier_removal | 异常值方法 (none/zscore) |
|  | split_method | 划分方式 (sequential/random/label_random) |
|  | use_time_features | 是否用时间特征 (True/False) |
|  | num_features | 特征总数 (6/11) |
| **超参数** | learning_rate | 学习率 (0.0001/0.001/0.01) |
|  | batch_size | 批次大小 (16/32/64/128) |
|  | hidden_size | 隐藏层大小 (32/64/128) |
|  | dropout | Dropout率 (0.0/0.2/0.4) |
| **性能** | test_r2 | **测试集R²（主指标）** |
|  | test_mse | 测试集MSE |
|  | test_mae | 测试集MAE |
|  | training_time_sec | 训练时间（秒） |
| **备注** | notes | 实验说明 |

### 结果分析流程

每个阶段完成后：
1. 运行 `analyze_stage_results(stage_number)`
2. 生成统计报告和可视化图表
3. 确定最优配置，更新下一阶段的baseline

---

## 预期成果 / Expected Outcomes

### 1. 因素影响排序

根据各阶段实验，得到各维度对R²提升的贡献排序：

**预期（从大到小）**：
1. 算法类型（LSTM vs Linear可能相差0.1-0.2 R²）
2. 时间窗口长度（最优窗口可能提升0.05-0.15 R²）
3. 数据划分方式（sequential vs random可能相差0.05-0.1 R²）
4. 预测场景（1小时 vs 1周可能相差0.2-0.3 R²）
5. 时间特征（可能提升0.02-0.08 R²）
6. 学习率（最优值可能提升0.01-0.05 R²）
7. 异常值处理（可能提升0.01-0.03 R²）
8. 特征选择（影响较小）

### 2. 最优配置文档

包含：
- 最优算法
- 最优数据预处理方法
- 最优特征组合
- 最优seq_length
- 最优超参数

### 3. 泛化能力报告

- train2上的性能
- train1上的性能（泛化能力）
- 消融实验结果（各组件贡献）

### 4. 实验报告和论文素材

- 各阶段对比图表
- 统计显著性分析
- 实验结论和建议

---

## 实验执行建议 / Execution Recommendations

### 1. 优先级策略

**必须完成**：
- ✅ 阶段1：建立基准（20-30分钟）
- ✅ 阶段2：数据预处理（30-40分钟）

**强烈建议**：
- ✅ 阶段3：特征工程（40-50分钟）
- ✅ 阶段4：时间窗口（40-50分钟）

**可选（如时间充裕）**：
- ⭕ 阶段5：算法对比（如阶段1已确定最优算法可跳过）
- ⭕ 阶段6：超参数精调（如使用默认参数已足够）

**建议完成**：
- ✅ 阶段7：最终验证（30-40分钟）

### 2. 质量控制

每个阶段完成后检查：
- ✅ R²是否提升？如否，分析原因
- ✅ 是否存在数据泄露？（test_r2 异常高）
- ✅ 训练/测试loss是否收敛？
- ✅ 是否过拟合？（train_r2 >> test_r2）

### 3. 灵活调整

如果某阶段发现：
- R²提升不明显（<0.01）→ 该维度影响小，可快速通过
- R²显著提升（>0.05）→ 该维度关键，可增加测试粒度
- 训练时间过长 → 减少epochs或增大batch_size

---

## 技术实现 / Technical Implementation

实验框架已搭建完成，包括：

### 1. 配置管理
- `experiments/experiment_configs.py`：88个实验配置
- 支持 `get_stage_configs(stage_number)` 获取配置

### 2. 批量执行
- `notebooks/linear_regression.ipynb`：Linear模型+批量实验
- `notebooks/rnn.ipynb`：RNN/LSTM/GRU模型+批量实验
- 支持断点续传（`skip_completed=True`）

### 3. 结果记录
- 自动保存到 `experiments/results.csv`
- 失败日志：`experiments/failed_experiments.log`

### 4. 分析工具
- `analyze_stage_results(stage)`：生成统计摘要
- `generate_stage_report(stage)`：生成Markdown报告和图表

---

## 参考文档 / References

- **实验执行指南**：`experiments/README.md`
- **项目说明**：`CLAUDE.md`
- **代码实现**：`notebooks/linear_regression.ipynb`, `notebooks/rnn.ipynb`
- **工具函数**：`notebooks/utils.py`

---

**实验设计完成！准备开始执行。 / Experiment design completed! Ready to execute.** 🚀
