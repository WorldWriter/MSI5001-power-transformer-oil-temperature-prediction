# å®žéªŒç®¡ç†æ¡†æž¶ / Experiment Management Framework

æœ¬æ–‡æ¡£æ˜¯å˜åŽ‹å™¨æ²¹æ¸©é¢„æµ‹å®žéªŒçš„å®Œæ•´æŒ‡å—ï¼ŒåŒ…å«88ä¸ªç³»ç»ŸåŒ–å®žéªŒçš„é…ç½®ã€æ‰§è¡Œå’Œåˆ†æžæ–¹æ³•ã€‚

---

## ç›®å½• / Contents

1. [æ¡†æž¶æ¦‚è§ˆ](#æ¡†æž¶æ¦‚è§ˆ)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [å®žéªŒé˜¶æ®µè¯´æ˜Ž](#å®žéªŒé˜¶æ®µè¯´æ˜Ž)
4. [æŸ¥çœ‹å’Œåˆ†æžç»“æžœ](#æŸ¥çœ‹å’Œåˆ†æžç»“æžœ)
5. [ç»§ç»­åŽç»­é˜¶æ®µ](#ç»§ç»­åŽç»­é˜¶æ®µ)
6. [è‡ªå®šä¹‰å®žéªŒ](#è‡ªå®šä¹‰å®žéªŒ)
7. [å¸¸è§é—®é¢˜ FAQ](#å¸¸è§é—®é¢˜-faq)
8. [results.csv å­—æ®µè¯´æ˜Ž](#resultscsv-å­—æ®µè¯´æ˜Ž)
9. [æ³¨æ„äº‹é¡¹](#æ³¨æ„äº‹é¡¹)

---

## æ¡†æž¶æ¦‚è§ˆ

### æ–‡ä»¶ç»“æž„

```
experiments/
â”œâ”€â”€ README.md                   # æœ¬æ–‡ä»¶
â”œâ”€â”€ experiment_configs.py       # æ‰€æœ‰å®žéªŒé…ç½®ï¼ˆ88ä¸ªæ¨¡åž‹ï¼‰
â”œâ”€â”€ results.csv                 # å®žéªŒç»“æžœæ±‡æ€»ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ failed_experiments.log      # å¤±è´¥å®žéªŒæ—¥å¿—ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ stage_summaries/            # å„é˜¶æ®µæ€»ç»“æŠ¥å‘Šï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚   â”œâ”€â”€ stage1_summary.md
â”‚   â”œâ”€â”€ stage2_summary.md
â”‚   â””â”€â”€ ...
â””â”€â”€ visualizations/             # å¯¹æ¯”å›¾è¡¨ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
    â”œâ”€â”€ stage1_comparison.png
    â””â”€â”€ ...

notebooks/
â”œâ”€â”€ linear_regression.ipynb     # Linearæ¨¡åž‹ + æ‰¹é‡å®žéªŒåŠŸèƒ½
â”œâ”€â”€ rnn.ipynb                   # RNNæ¨¡åž‹ + æ‰¹é‡å®žéªŒåŠŸèƒ½
â””â”€â”€ utils.py                    # å…±äº«å·¥å…·å‡½æ•°
```

### å®žéªŒé˜¶æ®µè§„åˆ’

| é˜¶æ®µ | ç›®æ ‡ | æ¨¡åž‹æ•°é‡ | ä¸»è¦å˜é‡ | é¢„è®¡æ—¶é—´ |
|------|------|----------|----------|----------|
| 1 | å»ºç«‹åŸºå‡† | 6 | ç®—æ³•ç±»åž‹ã€é¢„æµ‹åœºæ™¯ | 20-30åˆ†é’Ÿ |
| 2 | æ•°æ®é¢„å¤„ç† | 10 | å¼‚å¸¸å€¼å¤„ç†ã€åˆ’åˆ†æ–¹å¼ | 30-40åˆ†é’Ÿ |
| 3 | ç‰¹å¾å·¥ç¨‹ | 12 | æ—¶é—´ç‰¹å¾ã€ç‰¹å¾é€‰æ‹© | 40-50åˆ†é’Ÿ |
| 4 | æ—¶é—´çª—å£ | 12 | seq_length | 40-50åˆ†é’Ÿ |
| 5 | ç®—æ³•å¯¹æ¯” | 12 | Linear/RNN/informer | 40-60åˆ†é’Ÿ |
| 6 | è¶…å‚æ•°ç²¾è°ƒ | 27 | å­¦ä¹ çŽ‡ã€batch sizeç­‰ | 60-90åˆ†é’Ÿ |
| 7 | æœ€ç»ˆéªŒè¯ | 9 | train1éªŒè¯ã€æ¶ˆèžå®žéªŒ | 30-40åˆ†é’Ÿ |

**æ€»è®¡ï¼š88ä¸ªæ¨¡åž‹ï¼Œé¢„è®¡5-6å°æ—¶**ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå¯åˆ†å¤šæ¬¡è¿è¡Œï¼‰

---

## å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1ï¼šæ‰“å¼€ Jupyter Notebook

```bash
cd notebooks
jupyter notebook
```

### æ­¥éª¤2ï¼šè¿è¡Œ Linear æ¨¡åž‹å®žéªŒ

1. **æ‰“å¼€ `linear_regression.ipynb`**

2. **æ»šåŠ¨åˆ°æœ€åŽçš„"æ‰¹é‡å®žéªŒæ‰§è¡ŒåŠŸèƒ½"éƒ¨åˆ†**

3. **ä¾æ¬¡è¿è¡Œä»¥ä¸‹ cells ä»¥åŠ è½½å¿…è¦çš„å‡½æ•°**ï¼š
   - "æ‰¹é‡å®žéªŒæ‰§è¡ŒåŠŸèƒ½" - Markdownè¯´æ˜Ž
   - "å¯¼å…¥å®žéªŒé…ç½®å’Œå·¥å…·" - å¯¼å…¥é…ç½®
   - "ç»“æžœä¿å­˜å‡½æ•°" - å®šä¹‰ä¿å­˜å‡½æ•°
   - "æ‰¹é‡å®žéªŒæ‰§è¡Œå‡½æ•°" - å®šä¹‰æ‰§è¡Œå‡½æ•°
   - "é˜¶æ®µåˆ†æžå’Œå¯è§†åŒ–å‡½æ•°" - å®šä¹‰åˆ†æžå‡½æ•°

4. **åœ¨æ–° cell ä¸­è¿è¡Œä»¥ä¸‹ä»£ç **ï¼š

```python
# èŽ·å–é˜¶æ®µ1çš„Linearæ¨¡åž‹é…ç½®ï¼ˆ3ä¸ªå®žéªŒï¼‰
stage1_configs = get_stage_configs(1)
stage1_configs_linear = [c for c in stage1_configs if c['model_type'] == 'linear']

# æ‰¹é‡è¿è¡Œå®žéªŒ
results_stage1_linear = run_experiments_batch(
    stage1_configs_linear,
    skip_completed=True,  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
    save_models=True      # ä¿å­˜æ¨¡åž‹æ–‡ä»¶åˆ° models/
)

# è¿™å°†è¿è¡Œ3ä¸ªå®žéªŒï¼š
# - stage1_linear_h (1å°æ—¶é¢„æµ‹, offset=4)
# - stage1_linear_d (1å¤©é¢„æµ‹, offset=96)
# - stage1_linear_w (1å‘¨é¢„æµ‹, offset=672)
```

**é¢„è®¡æ—¶é—´**ï¼šæ¯ä¸ªæ¨¡åž‹çº¦2-5åˆ†é’Ÿï¼Œæ€»è®¡10-15åˆ†é’Ÿã€‚

### æ­¥éª¤3ï¼šè¿è¡Œ RNN æ¨¡åž‹å®žéªŒ

1. **æ‰“å¼€ `rnn.ipynb`**

2. **æ»šåŠ¨åˆ°æœ€åŽçš„"æ‰¹é‡å®žéªŒæ‰§è¡ŒåŠŸèƒ½"éƒ¨åˆ†**

3. **è¿è¡ŒåŠ è½½å‡½æ•°çš„ cells**ï¼ˆåŒæ­¥éª¤2ï¼‰

4. **åœ¨æ–° cell ä¸­è¿è¡Œä»¥ä¸‹ä»£ç **ï¼š

```python
# èŽ·å–é˜¶æ®µ1çš„RNNæ¨¡åž‹é…ç½®ï¼ˆ3ä¸ªå®žéªŒï¼‰
stage1_configs = get_stage_configs(1)
stage1_configs_rnn = [c for c in stage1_configs if c['model_type'] == 'rnn']

# æ‰¹é‡è¿è¡ŒRNNå®žéªŒ
results_stage1_rnn = run_rnn_experiments_batch(
    stage1_configs_rnn,
    skip_completed=True,
    save_models=True
)

# è¿™å°†è¿è¡Œ3ä¸ªå®žéªŒï¼š
# - stage1_rnn_h (1å°æ—¶é¢„æµ‹)
# - stage1_rnn_d (1å¤©é¢„æµ‹)
# - stage1_rnn_w (1å‘¨é¢„æµ‹)
```

**é¢„è®¡æ—¶é—´**ï¼šæ¯ä¸ªæ¨¡åž‹çº¦3-6åˆ†é’Ÿï¼Œæ€»è®¡15-20åˆ†é’Ÿã€‚

---

## å®žéªŒé˜¶æ®µè¯´æ˜Ž

### é˜¶æ®µ1ï¼šå»ºç«‹åŸºå‡† (Baseline)

**ç›®æ ‡**ï¼šç¡®å®šå„é¢„æµ‹åœºæ™¯çš„åŸºå‡†æ€§èƒ½

**å®žéªŒé…ç½®**ï¼š
- **æ•°æ®é›†**ï¼štrain2.csv
- **ç®—æ³•**ï¼šLinear, RNN
- **é¢„æµ‹åœºæ™¯**ï¼š1å°æ—¶(offset=4), 1å¤©(offset=96), 1å‘¨(offset=672)
- **æ¨¡åž‹æ•°é‡**ï¼š2ç®—æ³• Ã— 3åœºæ™¯ = **6ä¸ªæ¨¡åž‹**
- **å›ºå®šå‚æ•°**ï¼š
  - å¼‚å¸¸å€¼å¤„ç†ï¼šæ— 
  - æ—¶é—´ç‰¹å¾ï¼šæ— ï¼ˆä»…6ä¸ªè´Ÿè½½ç‰¹å¾ï¼‰
  - åˆ’åˆ†æ–¹å¼ï¼šsequential (80/20)
  - seq_lengthï¼š16
  - å­¦ä¹ çŽ‡ï¼š0.001
  - batch_sizeï¼š32

**å®žéªŒIDæ ¼å¼**ï¼š`stage1_{model}_{scenario}`
- ç¤ºä¾‹ï¼š`stage1_linear_h`, `stage1_rnn_d`

---

### é˜¶æ®µ2ï¼šæ•°æ®é¢„å¤„ç†å½±å“åˆ†æž

**ç›®æ ‡**ï¼šè¯„ä¼°å¼‚å¸¸å€¼å¤„ç†å’Œæ•°æ®åˆ’åˆ†æ–¹å¼çš„å½±å“

**åŸºå‡†é…ç½®**ï¼šä½¿ç”¨é˜¶æ®µ1ä¸­RÂ²æœ€é«˜çš„ç®—æ³•

**å®žéªŒåˆ†ç»„**ï¼š

#### 2.1 å¼‚å¸¸å€¼å‰”é™¤æ¯”ä¾‹ - 4ä¸ªæ¨¡åž‹
- æ— å¼‚å¸¸å€¼å¤„ç†
- 0.5% é˜ˆå€¼ (Z-score=3.0)
- 1.0% é˜ˆå€¼
- 5.0% é˜ˆå€¼

ä»…åœ¨**1å°æ—¶é¢„æµ‹**åœºæ™¯æµ‹è¯•ï¼ˆæœ€å¿«è¿­ä»£ï¼‰

#### 2.2 æ•°æ®åˆ’åˆ†æ–¹å¼ - 3ä¸ªæ¨¡åž‹
- sequentialï¼šæ—¶åºåˆ†å‰²ï¼Œæ— æ•°æ®æ³„éœ²
- randomï¼šåˆ†20ç»„ï¼Œéšæœºåˆ†é…80%/20%
- label_randomï¼šå®Œå…¨éšæœºï¼Œå¯èƒ½å­˜åœ¨çª—å£é‡å æ³„éœ²

#### 2.3 æœ€ä¼˜ç»„åˆéªŒè¯ - 3ä¸ªæ¨¡åž‹
å°†2.1å’Œ2.2çš„æœ€ä¼˜é…ç½®ç»„åˆï¼Œåœ¨3ä¸ªé¢„æµ‹åœºæ™¯ä¸‹éªŒè¯

**æ¨¡åž‹æ•°é‡**ï¼š4 + 3 + 3 = **10ä¸ªæ¨¡åž‹**

**å®žéªŒIDæ ¼å¼**ï¼š`stage2_{dimension}_{value}_{scenario}`
- ç¤ºä¾‹ï¼š`stage2_outlier_1pct_h`, `stage2_split_random_h`

---

### é˜¶æ®µ3ï¼šç‰¹å¾å·¥ç¨‹å½±å“åˆ†æž

**ç›®æ ‡**ï¼šè¯„ä¼°æ—¶é—´ç‰¹å¾å’Œç‰¹å¾é€‰æ‹©çš„å½±å“

**åŸºå‡†é…ç½®**ï¼šä½¿ç”¨é˜¶æ®µ2çš„æœ€ä¼˜æ•°æ®é¢„å¤„ç†é…ç½®

**å®žéªŒåˆ†ç»„**ï¼š

#### 3.1 æ—¶é—´ç‰¹å¾å½±å“ - 6ä¸ªæ¨¡åž‹
- **æ— æ—¶é—´ç‰¹å¾**ï¼šä»…6ä¸ªè´Ÿè½½ç‰¹å¾
- **æœ‰æ—¶é—´ç‰¹å¾**ï¼šè´Ÿè½½ç‰¹å¾ + (hour, dayofweek, month, day, is_weekend)

åœ¨3ä¸ªé¢„æµ‹åœºæ™¯æµ‹è¯•ï¼š2é…ç½® Ã— 3åœºæ™¯ = 6ä¸ªæ¨¡åž‹

#### 3.2 ç‰¹å¾é€‰æ‹©å½±å“ - 6ä¸ªæ¨¡åž‹
- **å…¨éƒ¨è´Ÿè½½ç‰¹å¾**ï¼š6ä¸ª (HUFL, HULL, MUFL, MULL, LUFL, LULL)
- **ç­›é€‰ç‰¹å¾**ï¼šåŸºäºŽç›¸å…³æ€§åˆ†æžé€‰æ‹©Top3-4

åœ¨3ä¸ªé¢„æµ‹åœºæ™¯æµ‹è¯•ï¼š2é…ç½® Ã— 3åœºæ™¯ = 6ä¸ªæ¨¡åž‹

**æ¨¡åž‹æ•°é‡**ï¼š6 + 6 = **12ä¸ªæ¨¡åž‹**

---

### é˜¶æ®µ4ï¼šæ—¶é—´çª—å£é•¿åº¦å½±å“

**ç›®æ ‡**ï¼šç¡®å®šæœ€ä¼˜ seq_length

**åŸºå‡†é…ç½®**ï¼šä½¿ç”¨é˜¶æ®µ3çš„æœ€ä¼˜ç‰¹å¾é…ç½®

**æµ‹è¯•å‚æ•°**ï¼š
- seq_lengthï¼š8, 16, 32, 64

**æ¨¡åž‹æ•°é‡**ï¼š4çª—å£ Ã— 3åœºæ™¯ = **12ä¸ªæ¨¡åž‹**

**å®žéªŒIDæ ¼å¼**ï¼š`stage4_seq{length}_{scenario}`
- ç¤ºä¾‹ï¼š`stage4_seq32_h`, `stage4_seq64_d`

---

### é˜¶æ®µ5ï¼šç®—æ³•å¯¹æ¯”

**ç›®æ ‡**ï¼šæ¯”è¾ƒä¸åŒæ·±åº¦å­¦ä¹ ç®—æ³•æ€§èƒ½

**åŸºå‡†é…ç½®**ï¼šä½¿ç”¨é˜¶æ®µ4çš„æœ€ä¼˜æ—¶é—´çª—å£é…ç½®

**æµ‹è¯•ç®—æ³•**ï¼š
- Linearï¼šå¤šå±‚å…¨è¿žæŽ¥ç½‘ç»œ
- RNNï¼šå¾ªçŽ¯ç¥žç»ç½‘ç»œ
- LSTMï¼šé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ
- GRUï¼šé—¨æŽ§å¾ªçŽ¯å•å…ƒ

**æ¨¡åž‹æ•°é‡**ï¼š4ç®—æ³• Ã— 3åœºæ™¯ = **12ä¸ªæ¨¡åž‹**

**å®žéªŒIDæ ¼å¼**ï¼š`stage5_{algorithm}_{scenario}`
- ç¤ºä¾‹ï¼š`stage5_lstm_h`, `stage5_gru_w`

---

### é˜¶æ®µ6ï¼šè¶…å‚æ•°ç²¾è°ƒ

**ç›®æ ‡**ï¼šæ‰¾åˆ°æœ€ä¼˜è¶…å‚æ•°ç»„åˆ

**åŸºå‡†é…ç½®**ï¼šä½¿ç”¨é˜¶æ®µ5çš„æœ€ä¼˜ç®—æ³•

**æµ‹è¯•åœºæ™¯**ï¼šä»…åœ¨**1å°æ—¶é¢„æµ‹**æµ‹è¯•ï¼ˆå¿«é€Ÿè¿­ä»£ï¼‰ï¼Œæœ€åŽéªŒè¯å…¶ä»–åœºæ™¯

**å®žéªŒåˆ†ç»„**ï¼š

#### 6.1 å­¦ä¹ çŽ‡ - 3ä¸ªæ¨¡åž‹
æµ‹è¯•ï¼š0.0001, 0.001, 0.01

#### 6.2 Batch size - 3ä¸ªæ¨¡åž‹
æµ‹è¯•ï¼š16, 32, 64

#### 6.3 éšè—å±‚å¤§å° - 3ä¸ªæ¨¡åž‹
æµ‹è¯•ï¼š32, 64, 128

#### 6.4 DropoutçŽ‡ - 3ä¸ªæ¨¡åž‹
æµ‹è¯•ï¼š0.0, 0.2, 0.4

#### 6.5 æœ€ä¼˜è¶…å‚æ•°éªŒè¯ - 3ä¸ªæ¨¡åž‹
å°†6.1-6.4çš„æœ€ä¼˜è¶…å‚æ•°ç»„åˆåº”ç”¨åˆ°3ä¸ªé¢„æµ‹åœºæ™¯

**æ¨¡åž‹æ•°é‡**ï¼š3 + 3 + 3 + 3 + 3 = **15ä¸ªæ¨¡åž‹**
ï¼ˆä¿å®ˆä¼°ç®—ï¼›å¦‚æžœåšç½‘æ ¼æœç´¢å¯èƒ½éœ€è¦27ä¸ªï¼‰

---

### é˜¶æ®µ7ï¼šæœ€ç»ˆéªŒè¯ä¸Žæ¶ˆèžå®žéªŒ

**ç›®æ ‡**ï¼šåœ¨train1ä¸ŠéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼Œè¿›è¡Œæ¶ˆèžå®žéªŒ

**åŸºå‡†é…ç½®**ï¼šä½¿ç”¨é˜¶æ®µ6çš„æ‰€æœ‰æœ€ä¼˜é…ç½®

**å®žéªŒåˆ†ç»„**ï¼š

#### 7.1 train1æ•°æ®é›†éªŒè¯ - 3ä¸ªæ¨¡åž‹
å°†æœ€ä¼˜é…ç½®åº”ç”¨åˆ° **train1.csv**ï¼ˆä¸åŒæ•°æ®åˆ†å¸ƒï¼‰
- 1å°æ—¶é¢„æµ‹
- 1å¤©é¢„æµ‹
- 1å‘¨é¢„æµ‹

#### 7.2 æ¶ˆèžå®žéªŒ (Ablation Study) - 6ä¸ªæ¨¡åž‹
åœ¨train2ä¸Šï¼Œé€ä¸ªç§»é™¤å…³é”®ç»„ä»¶éªŒè¯å…¶è´¡çŒ®ï¼š
- ç§»é™¤æ—¶é—´ç‰¹å¾ï¼ˆå¦‚æžœé˜¶æ®µ3è¯æ˜Žæœ‰æ•ˆï¼‰
- ç§»é™¤å¼‚å¸¸å€¼å¤„ç†ï¼ˆå¦‚æžœé˜¶æ®µ2è¯æ˜Žæœ‰æ•ˆï¼‰

æ¯ä¸ªæ¶ˆèžåœ¨3ä¸ªé¢„æµ‹åœºæ™¯æµ‹è¯•ï¼š2æ¶ˆèž Ã— 3åœºæ™¯ = 6ä¸ªæ¨¡åž‹

**æ¨¡åž‹æ•°é‡**ï¼š3 + 6 = **9ä¸ªæ¨¡åž‹**

**å®žéªŒIDæ ¼å¼**ï¼š`stage7_{type}_{scenario}`
- ç¤ºä¾‹ï¼š`stage7_train1_h`, `stage7_ablation_no_time_d`

---

## æŸ¥çœ‹å’Œåˆ†æžç»“æžœ

### æ–¹æ³•1ï¼šç›´æŽ¥æŸ¥çœ‹ CSV æ–‡ä»¶

åœ¨ä»»æ„ notebook ä¸­è¿è¡Œï¼š

```python
import pandas as pd

# è¯»å–æ‰€æœ‰å®žéªŒç»“æžœ
results_df = pd.read_csv('../experiments/results.csv')

# æŸ¥çœ‹é˜¶æ®µ1ç»“æžœ
stage1_df = results_df[results_df['stage'] == 1]
print(stage1_df[['experiment_id', 'model_type', 'prediction_scenario', 'test_r2', 'test_mae']])

# æŒ‰RÂ²æŽ’åº
print("\næŒ‰RÂ²æŽ’åº / Sorted by RÂ²:")
print(stage1_df.sort_values('test_r2', ascending=False)[
    ['experiment_id', 'test_r2', 'test_mae', 'training_time_sec']
])
```

### æ–¹æ³•2ï¼šä½¿ç”¨åˆ†æžå‡½æ•°

åœ¨ `linear_regression.ipynb` ä¸­è¿è¡Œï¼š

```python
# åˆ†æžé˜¶æ®µ1ç»“æžœï¼ˆè‡ªåŠ¨ç”Ÿæˆç»Ÿè®¡å’Œå›¾è¡¨ï¼‰
summary = analyze_stage_results(1)

# ç”Ÿæˆé˜¶æ®µ1æ€»ç»“æŠ¥å‘Š
generate_stage_report(1)

# æŠ¥å‘Šä¼šè‡ªåŠ¨ä¿å­˜åˆ°ï¼š
# - experiments/stage_summaries/stage1_summary.md
# - experiments/visualizations/stage1_comparison.png
```

**è¾“å‡ºå†…å®¹**ï¼š
- å®žéªŒæ•°é‡ç»Ÿè®¡
- RÂ²ã€MAEçš„æœ€ä¼˜/æœ€å·®/å¹³å‡/ä¸­ä½æ•°
- æœ€ä¼˜æ¨¡åž‹ä¿¡æ¯
- å¯¹æ¯”æ¡å½¢å›¾ï¼ˆRÂ² å’Œ MAEï¼‰

### æ–¹æ³•3ï¼šå¯¹æ¯”ä¸åŒç®—æ³•/é…ç½®

```python
# Linear vs RNN å¯¹æ¯”
linear_results = stage1_df[stage1_df['model_type'] == 'linear']
rnn_results = stage1_df[stage1_df['model_type'] == 'rnn']

print("Linear å¹³å‡RÂ²:", linear_results['test_r2'].mean())
print("RNN å¹³å‡RÂ²:", rnn_results['test_r2'].mean())

# ä¸åŒé¢„æµ‹åœºæ™¯çš„æ€§èƒ½
for scenario in ['hour', 'day', 'week']:
    scenario_df = stage1_df[stage1_df['prediction_scenario'] == scenario]
    best_idx = scenario_df['test_r2'].idxmax()
    print(f"\n{scenario} é¢„æµ‹æœ€ä¼˜:")
    print(f"  æ¨¡åž‹: {scenario_df.loc[best_idx, 'experiment_id']}")
    print(f"  RÂ²: {scenario_df.loc[best_idx, 'test_r2']:.6f}")
    print(f"  MAE: {scenario_df.loc[best_idx, 'test_mae']:.6f}")
```

---

## ç»§ç»­åŽç»­é˜¶æ®µ

### è¿è¡Œé˜¶æ®µ2ï¼šæ•°æ®é¢„å¤„ç†å½±å“åˆ†æž

åŸºäºŽé˜¶æ®µ1çš„ç»“æžœï¼Œé€‰æ‹©æœ€ä¼˜ç®—æ³•ï¼ˆå‡è®¾æ˜¯ Linearï¼‰ï¼š

```python
# åœ¨ linear_regression.ipynb ä¸­è¿è¡Œ

# èŽ·å–é˜¶æ®µ2é…ç½®ï¼ˆ10ä¸ªå®žéªŒï¼‰
stage2_configs = get_stage_configs(2)

# ç­–ç•¥1ï¼šä¸€æ¬¡æ€§è¿è¡Œæ‰€æœ‰å®žéªŒ
results_stage2 = run_experiments_batch(stage2_configs, skip_completed=True)

# ç­–ç•¥2ï¼šåˆ†æ‰¹è¿è¡Œï¼Œé€æ­¥åˆ†æžï¼ˆæŽ¨èï¼‰
# 2.1 å…ˆè¿è¡Œå¼‚å¸¸å€¼ç›¸å…³çš„4ä¸ªå®žéªŒ
outlier_configs = [c for c in stage2_configs if 'outlier' in c['experiment_id']]
results_outlier = run_experiments_batch(outlier_configs, skip_completed=True)

# æŸ¥çœ‹åˆæ­¥ç»“æžœï¼Œç¡®å®šæœ€ä¼˜å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•
analyze_stage_results(2)

# 2.2 ç„¶åŽè¿è¡Œæ•°æ®åˆ’åˆ†ç›¸å…³çš„3ä¸ªå®žéªŒ
split_configs = [c for c in stage2_configs if 'split' in c['experiment_id']]
results_split = run_experiments_batch(split_configs, skip_completed=True)

# 2.3 æœ€åŽè¿è¡Œæœ€ä¼˜ç»„åˆéªŒè¯çš„3ä¸ªå®žéªŒ
# æ³¨æ„ï¼šéœ€è¦å…ˆæ ¹æ®ä¸Šé¢çš„ç»“æžœæ›´æ–° combo_configs ä¸­çš„å‚æ•°
# ç¼–è¾‘ experiments/experiment_configs.py ä¸­çš„ STAGE2_CONFIGS
combo_configs = [c for c in stage2_configs if 'combo' in c['experiment_id']]
results_combo = run_experiments_batch(combo_configs, skip_completed=True)

# ç”Ÿæˆé˜¶æ®µ2å®Œæ•´æŠ¥å‘Š
analyze_stage_results(2)
generate_stage_report(2)
```

### è¿è¡Œé˜¶æ®µ3-7

ä¾æ¬¡ç±»ä¼¼åœ°è¿è¡ŒåŽç»­é˜¶æ®µï¼š

```python
# é˜¶æ®µ3ï¼šç‰¹å¾å·¥ç¨‹å½±å“åˆ†æž
stage3_configs = get_stage_configs(3)
results_stage3 = run_experiments_batch(stage3_configs, skip_completed=True)
analyze_stage_results(3)
generate_stage_report(3)

# é˜¶æ®µ4ï¼šæ—¶é—´çª—å£é•¿åº¦å½±å“
stage4_configs = get_stage_configs(4)
results_stage4 = run_experiments_batch(stage4_configs, skip_completed=True)
analyze_stage_results(4)
generate_stage_report(4)

# é˜¶æ®µ5ï¼šç®—æ³•å¯¹æ¯”
stage5_configs = get_stage_configs(5)
results_stage5 = run_experiments_batch(stage5_configs, skip_completed=True)
analyze_stage_results(5)
generate_stage_report(5)

# é˜¶æ®µ6ï¼šè¶…å‚æ•°ç²¾è°ƒï¼ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
stage6_configs = get_stage_configs(6)
results_stage6 = run_experiments_batch(stage6_configs, skip_completed=True)
analyze_stage_results(6)
generate_stage_report(6)

# é˜¶æ®µ7ï¼šæœ€ç»ˆéªŒè¯ä¸Žæ¶ˆèžå®žéªŒ
stage7_configs = get_stage_configs(7)
results_stage7 = run_experiments_batch(stage7_configs, skip_completed=True)
analyze_stage_results(7)
generate_stage_report(7)
```

---

## è‡ªå®šä¹‰å®žéªŒ

### è¿è¡Œå•ä¸ªè‡ªå®šä¹‰å®žéªŒ

```python
# åœ¨ linear_regression.ipynb ä¸­

custom_config = {
    'dataset_path': '../dataset/train2.csv',
    'prediction_horizon': 'hour',
    'model_type': 'linear',
    'split_method': 'sequential',
    'time_features': ['hour', 'dayofweek', 'is_weekend'],  # æ·»åŠ æ—¶é—´ç‰¹å¾
    'remove_outliers': True,                               # å¯ç”¨å¼‚å¸¸å€¼å¤„ç†
    'outlier_method': 'zscore',
    'outlier_threshold': 3.0,
    'num_epochs': 100,
    'learning_rate': 0.001,
    'batch_size': 64,                                      # æ›´å¤§çš„ batch size
    'hidden_sizes': [128, 64, 32],                         # æ›´æ·±çš„ç½‘ç»œ
    'dropout': 0.3,
    'experiment_id': 'custom_linear_test_1',
    'stage': 0,
    'notes': 'Custom experiment: time features + outlier removal + deeper network',
}

# è®­ç»ƒæ¨¡åž‹
result = train_single_model(config=custom_config)

# ä¿å­˜ç»“æžœåˆ° CSV
save_experiment_result(result)

# æŸ¥çœ‹ç»“æžœ
print(f"RÂ²: {result['metrics']['r2']:.6f}")
print(f"MAE: {result['metrics']['mae']:.6f}")
print(f"Training time: {result.get('training_time', 0):.2f}s")
```

### ä¿®æ”¹é¢„å®šä¹‰é…ç½®

```python
# ä¿®æ”¹é˜¶æ®µ1çš„æŸä¸ªé…ç½®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
stage1_configs = get_stage_configs(1)
modified_config = stage1_configs[0].copy()  # å¤åˆ¶ç¬¬ä¸€ä¸ªé…ç½®

# ä¿®æ”¹å‚æ•°
modified_config['num_epochs'] = 50          # å‡å°‘è®­ç»ƒè½®æ¬¡ç”¨äºŽå¿«é€Ÿæµ‹è¯•
modified_config['learning_rate'] = 0.01     # æ›´å¤§çš„å­¦ä¹ çŽ‡
modified_config['experiment_id'] = 'stage1_linear_h_modified'
modified_config['notes'] = 'Modified: faster training for testing'

# è¿è¡Œä¿®æ”¹åŽçš„å®žéªŒ
result = train_single_model(config=modified_config)
save_experiment_result(result)
```

### æ‰¹é‡è¿è¡Œè‡ªå®šä¹‰é…ç½®

```python
# åˆ›å»ºä¸€ç»„è‡ªå®šä¹‰é…ç½®
custom_configs = []

for lr in [0.0001, 0.001, 0.01]:
    for bs in [16, 32, 64]:
        config = {
            'dataset_path': '../dataset/train2.csv',
            'prediction_horizon': 'hour',
            'model_type': 'linear',
            'split_method': 'sequential',
            'time_features': [],
            'num_epochs': 50,
            'learning_rate': lr,
            'batch_size': bs,
            'experiment_id': f'custom_lr{lr}_bs{bs}',
            'stage': 0,
            'notes': f'Custom: LR={lr}, BS={bs}',
        }
        custom_configs.append(config)

# æ‰¹é‡è¿è¡Œï¼ˆ9ä¸ªå®žéªŒï¼š3å­¦ä¹ çŽ‡ Ã— 3 batch sizeï¼‰
results = run_experiments_batch(custom_configs, skip_completed=True)
```

---

## å¸¸è§é—®é¢˜ / FAQ

### Q1: å®žéªŒä¸­æ–­åŽå¦‚ä½•ç»§ç»­ï¼Ÿ

**A:** ä½¿ç”¨ `skip_completed=True` å‚æ•°ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è·³è¿‡å·²å®Œæˆçš„å®žéªŒï¼š

```python
# é‡æ–°è¿è¡Œï¼Œä¼šè‡ªåŠ¨è·³è¿‡å·²åœ¨ results.csv ä¸­çš„å®žéªŒ
results = run_experiments_batch(configs, skip_completed=True)
```

æ‰€æœ‰ç»“æžœä¿å­˜åœ¨ `experiments/results.csv`ï¼Œç³»ç»Ÿé€šè¿‡ `experiment_id` åˆ¤æ–­æ˜¯å¦å·²å®Œæˆã€‚

---

### Q2: å¦‚ä½•æŸ¥çœ‹å¤±è´¥çš„å®žéªŒï¼Ÿ

**A:** æŸ¥çœ‹å¤±è´¥æ—¥å¿—æ–‡ä»¶ï¼š

```python
import os

log_path = '../experiments/failed_experiments.log'

if os.path.exists(log_path):
    with open(log_path, 'r', encoding='utf-8') as f:
        print(f.read())
else:
    print("æš‚æ— å¤±è´¥å®žéªŒ")
```

å¤±è´¥æ—¥å¿—æ ¼å¼ï¼š`æ—¶é—´æˆ³: experiment_id - é”™è¯¯ä¿¡æ¯`

---

### Q3: å¦‚ä½•åˆ é™¤æŸä¸ªå®žéªŒç»“æžœé‡æ–°è¿è¡Œï¼Ÿ

**A:** ä¸¤ç§æ–¹æ³•ï¼š

**æ–¹æ³•1ï¼šç¼–è¾‘ CSVï¼ˆæŽ¨èï¼‰**
1. æ‰“å¼€ `experiments/results.csv`
2. æ‰¾åˆ°å¹¶åˆ é™¤å¯¹åº”çš„è¡Œ
3. é‡æ–°è¿è¡Œå®žéªŒï¼ˆä¸ä¼šè¢«è·³è¿‡ï¼‰

**æ–¹æ³•2ï¼šä½¿ç”¨ pandas**
```python
import pandas as pd

# è¯»å–ç»“æžœ
df = pd.read_csv('../experiments/results.csv')

# åˆ é™¤ç‰¹å®šå®žéªŒ
df = df[df['experiment_id'] != 'stage1_linear_h']

# ä¿å­˜å›žæ–‡ä»¶
df.to_csv('../experiments/results.csv', index=False)
```

---

### Q4: å¦‚ä½•ä¿®æ”¹é¢„å®šä¹‰çš„å®žéªŒé…ç½®ï¼Ÿ

**A:** ç¼–è¾‘ `experiments/experiment_configs.py`ï¼š

1. æ‰“å¼€æ–‡ä»¶æ‰¾åˆ°å¯¹åº”é˜¶æ®µï¼ˆä¾‹å¦‚ `STAGE2_CONFIGS`ï¼‰
2. ä¿®æ”¹é…ç½®å‚æ•°
3. ä¿å­˜æ–‡ä»¶
4. é‡æ–°è¿è¡Œ notebook ä¸­å¯¼å…¥é…ç½®çš„ cell

ç¤ºä¾‹ï¼šä¿®æ”¹é˜¶æ®µ2çš„å¼‚å¸¸å€¼é˜ˆå€¼
```python
# åœ¨ experiment_configs.py ä¸­æ‰¾åˆ°
config['outlier_threshold'] = 3.0  # æ”¹ä¸º 2.5
```

---

### Q5: è®­ç»ƒå¤ªæ…¢æ€Žä¹ˆåŠžï¼Ÿ

**A:** ä¼˜åŒ–ç­–ç•¥ï¼š

1. **å‡å°‘è®­ç»ƒè½®æ¬¡**
   ```python
   config['num_epochs'] = 50  # ä»Ž100å‡åˆ°50
   ```

2. **å¢žåŠ  batch size**ï¼ˆåŠ é€Ÿä½†å¯èƒ½å½±å“æ€§èƒ½ï¼‰
   ```python
   config['batch_size'] = 64  # ä»Ž32å¢žåˆ°64
   ```

3. **å‡å°‘æ¨¡åž‹å¤æ‚åº¦**
   ```python
   # å¯¹äºŽ RNN
   config['hidden_size'] = 32        # ä»Ž64å‡åˆ°32
   config['num_layers'] = 1          # ä»Ž2å‡åˆ°1

   # å¯¹äºŽ Linear
   config['hidden_sizes'] = [32]     # ä»Ž[64, 32]å‡åˆ°[32]
   ```

4. **ä½¿ç”¨ GPU**ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
   ```python
   # åœ¨ notebooks/utils.py ä¸­ä¿®æ”¹
   DEFAULT_CONFIG['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'
   ```

---

### Q6: å¦‚ä½•åªè¿è¡Œéƒ¨åˆ†å®žéªŒï¼Ÿ

**A:** ä½¿ç”¨åˆ—è¡¨åˆ‡ç‰‡æˆ–è¿‡æ»¤ï¼š

```python
# æ–¹æ³•1ï¼šåªè¿è¡Œå‰3ä¸ªå®žéªŒ
configs = get_stage_configs(2)[:3]
results = run_experiments_batch(configs)

# æ–¹æ³•2ï¼šè¿‡æ»¤ç‰¹å®šå®žéªŒ
configs = get_stage_configs(2)
outlier_configs = [c for c in configs if 'outlier' in c['experiment_id']]
results = run_experiments_batch(outlier_configs)

# æ–¹æ³•3ï¼šæŒ‰ç´¢å¼•é€‰æ‹©
configs = get_stage_configs(3)
selected_configs = [configs[0], configs[3], configs[6]]  # é€‰æ‹©ç‰¹å®šç´¢å¼•
results = run_experiments_batch(selected_configs)

# æ–¹æ³•4ï¼šæŒ‰æ¡ä»¶è¿‡æ»¤
configs = get_stage_configs(5)
lstm_gru_configs = [c for c in configs if c['model_type'] in ['lstm', 'gru']]
results = run_experiments_batch(lstm_gru_configs)
```

---

### Q7: å¦‚ä½•å¯¹æ¯”ä¸¤ä¸ªé˜¶æ®µçš„ç»“æžœï¼Ÿ

**A:** ä½¿ç”¨ pandas è¿›è¡Œå¯¹æ¯”åˆ†æžï¼š

```python
import pandas as pd
import matplotlib.pyplot as plt

# è¯»å–ç»“æžœ
df = pd.read_csv('../experiments/results.csv')

# æå–ä¸¤ä¸ªé˜¶æ®µ
stage1_df = df[df['stage'] == 1]
stage2_df = df[df['stage'] == 2]

# å¯¹æ¯”å¹³å‡æ€§èƒ½
print("é˜¶æ®µ1å¹³å‡RÂ²:", stage1_df['test_r2'].mean())
print("é˜¶æ®µ2å¹³å‡RÂ²:", stage2_df['test_r2'].mean())

# ç»˜åˆ¶å¯¹æ¯”å›¾
plt.figure(figsize=(10, 5))
plt.bar(['Stage 1', 'Stage 2'],
        [stage1_df['test_r2'].mean(), stage2_df['test_r2'].mean()])
plt.ylabel('Average Test RÂ²')
plt.title('Performance Comparison')
plt.show()
```

---

### Q8: å®žéªŒç»“æžœçš„ RÂ² å¾ˆä½Žæ€Žä¹ˆåŠžï¼Ÿ

**A:** æŽ’æŸ¥æ¸…å•ï¼š

1. **æ£€æŸ¥æ•°æ®å½’ä¸€åŒ–**
   ```python
   # ç¡®è®¤ StandardScaler æ­£ç¡®åº”ç”¨
   print("X_train èŒƒå›´:", X_train_scaled.min(), X_train_scaled.max())
   print("y_train èŒƒå›´:", y_train_scaled.min(), y_train_scaled.max())
   ```

2. **æ£€æŸ¥æ•°æ®æ³„éœ²**
   ```python
   # ä½¿ç”¨ sequential åˆ’åˆ†é¿å…æ³„éœ²
   config['split_method'] = 'sequential'
   ```

3. **æ£€æŸ¥åºåˆ—åˆ›å»º**
   ```python
   # ç¡®è®¤ offset æ­£ç¡®è®¾ç½®
   print("é¢„æµ‹åœºæ™¯:", config['prediction_horizon'])
   print("Offset:", HORIZON_CONFIGS[config['prediction_horizon']]['offset'])
   ```

4. **å°è¯•ä¸åŒè¶…å‚æ•°**
   - å¢žåŠ  `num_epochs`
   - è°ƒæ•´ `learning_rate`
   - æ”¹å˜æ¨¡åž‹æž¶æž„ï¼ˆå¢žåŠ å±‚æ•°/hidden sizeï¼‰

5. **æ·»åŠ ç‰¹å¾**
   ```python
   config['time_features'] = ['hour', 'dayofweek', 'month']
   ```

---

## results.csv å­—æ®µè¯´æ˜Ž

æ‰€æœ‰å®žéªŒç»“æžœç»Ÿä¸€ä¿å­˜åœ¨ `experiments/results.csv`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

### åŸºæœ¬ä¿¡æ¯

| å­—æ®µ | ç±»åž‹ | è¯´æ˜Ž | ç¤ºä¾‹å€¼ |
|------|------|------|--------|
| experiment_id | str | å®žéªŒå”¯ä¸€æ ‡è¯†ç¬¦ | stage1_linear_h |
| stage | int | å®žéªŒé˜¶æ®µç¼–å· | 1, 2, 3, ..., 7 |
| dataset | str | ä½¿ç”¨çš„æ•°æ®é›†æ–‡ä»¶å | train1.csv, train2.csv |
| notes | str | å®žéªŒå¤‡æ³¨è¯´æ˜Ž | "Baseline - LINEAR - hour" |

### æ¨¡åž‹é…ç½®

| å­—æ®µ | ç±»åž‹ | è¯´æ˜Ž | ç¤ºä¾‹å€¼ |
|------|------|------|--------|
| model_type | str | æ¨¡åž‹ç±»åž‹ | linear, rnn, lstm, gru |
| prediction_scenario | str | é¢„æµ‹åœºæ™¯ | hour, day, week |
| offset | int | é¢„æµ‹æ—¶é—´åç§»é‡ï¼ˆ15åˆ†é’Ÿä¸ºå•ä½ï¼‰ | 4, 96, 672 |
| seq_length | int | è¾“å…¥åºåˆ—é•¿åº¦ | 8, 16, 32, 64 |

### æ•°æ®é¢„å¤„ç†

| å­—æ®µ | ç±»åž‹ | è¯´æ˜Ž | ç¤ºä¾‹å€¼ |
|------|------|------|--------|
| outlier_removal | str | å¼‚å¸¸å€¼å¤„ç†æ–¹æ³• | none, zscore, iqr |
| split_method | str | æ•°æ®åˆ’åˆ†æ–¹å¼ | sequential, random, label_random |
| use_time_features | bool | æ˜¯å¦ä½¿ç”¨æ—¶é—´ç‰¹å¾ | True, False |
| num_features | int | æ€»ç‰¹å¾æ•°é‡ | 6, 11 (6è´Ÿè½½+5æ—¶é—´) |
| feature_list | str | ä½¿ç”¨çš„è´Ÿè½½ç‰¹å¾åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰ | "HUFL,HULL,MUFL,MULL,LUFL,LULL" |

### è¶…å‚æ•°

| å­—æ®µ | ç±»åž‹ | è¯´æ˜Ž | ç¤ºä¾‹å€¼ |
|------|------|------|--------|
| learning_rate | float | å­¦ä¹ çŽ‡ | 0.0001, 0.001, 0.01 |
| batch_size | int | æ‰¹æ¬¡å¤§å° | 16, 32, 64, 128 |
| hidden_size | int | éšè—å±‚å¤§å°ï¼ˆRNNç³»åˆ—ï¼‰ | 32, 64, 128, 256 |
| num_layers | int | RNNå±‚æ•° | 1, 2, 3 |
| dropout | float | DropoutçŽ‡ | 0.0, 0.2, 0.4 |
| bidirectional | bool | æ˜¯å¦åŒå‘RNN | True, False |
| epochs | int | è®­ç»ƒè½®æ¬¡ï¼ˆé…ç½®å€¼ï¼‰ | 100 |
| early_stopping_patience | int | æ—©åœè€å¿ƒå€¼ | 10 |

### æ€§èƒ½æŒ‡æ ‡

| å­—æ®µ | ç±»åž‹ | è¯´æ˜Ž | æ„ä¹‰ |
|------|------|------|------|
| train_r2 | float | è®­ç»ƒé›†RÂ²åˆ†æ•° | æ‹Ÿåˆä¼˜åº¦ï¼Œè¶ŠæŽ¥è¿‘1è¶Šå¥½ |
| test_r2 | float | **æµ‹è¯•é›†RÂ²åˆ†æ•°ï¼ˆä¸»æŒ‡æ ‡ï¼‰** | æ³›åŒ–èƒ½åŠ›ï¼Œè¶ŠæŽ¥è¿‘1è¶Šå¥½ |
| train_mse | float | è®­ç»ƒé›†å‡æ–¹è¯¯å·® | è¶Šå°è¶Šå¥½ |
| test_mse | float | æµ‹è¯•é›†å‡æ–¹è¯¯å·® | è¶Šå°è¶Šå¥½ |
| train_mae | float | è®­ç»ƒé›†å¹³å‡ç»å¯¹è¯¯å·® | å¯è§£é‡Šè¯¯å·®ï¼ˆâ„ƒï¼‰ï¼Œè¶Šå°è¶Šå¥½ |
| test_mae | float | æµ‹è¯•é›†å¹³å‡ç»å¯¹è¯¯å·® | å¯è§£é‡Šè¯¯å·®ï¼ˆâ„ƒï¼‰ï¼Œè¶Šå°è¶Šå¥½ |
| training_time_sec | float | è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ | æ•ˆçŽ‡æŒ‡æ ‡ |

### å­—æ®µä½¿ç”¨ç¤ºä¾‹

```python
import pandas as pd

# è¯»å–ç»“æžœ
df = pd.read_csv('../experiments/results.csv')

# æŸ¥æ‰¾æœ€ä¼˜æ¨¡åž‹ï¼ˆæŒ‰test_r2æŽ’åºï¼‰
best_model = df.loc[df['test_r2'].idxmax()]
print("æœ€ä¼˜æ¨¡åž‹:", best_model['experiment_id'])
print("Test RÂ²:", best_model['test_r2'])

# å¯¹æ¯”ä¸åŒè¶…å‚æ•°
lr_comparison = df[df['stage'] == 6].groupby('learning_rate')['test_r2'].mean()
print("ä¸åŒå­¦ä¹ çŽ‡çš„å¹³å‡RÂ²:")
print(lr_comparison)

# ç­›é€‰ç‰¹å®šé…ç½®
high_performance = df[(df['test_r2'] > 0.8) & (df['training_time_sec'] < 300)]
print(f"é«˜æ€§èƒ½ä¸”å¿«é€Ÿçš„æ¨¡åž‹: {len(high_performance)} ä¸ª")
```

---

## æ³¨æ„äº‹é¡¹

### 1. æ•°æ®é›†é€‰æ‹©ç­–ç•¥

- **é˜¶æ®µ1-6**ï¼šä¸»è¦åœ¨ `train2.csv` ä¸Šè¿›è¡Œ
  - åŽŸå› ï¼štrain2 æ•°æ®èŒƒå›´æ›´å¤§ï¼Œæ›´å®¹æ˜“è®­ç»ƒ
- **é˜¶æ®µ7**ï¼šåœ¨ `train1.csv` ä¸ŠéªŒè¯
  - ç›®çš„ï¼šæµ‹è¯•æ¨¡åž‹æ³›åŒ–èƒ½åŠ›

### 2. æ¨¡åž‹ä¿å­˜è§„åˆ™

- **è‡ªåŠ¨ä¿å­˜**ï¼šæ¯ä¸ªå®žéªŒçš„æ¨¡åž‹è‡ªåŠ¨ä¿å­˜åˆ° `models/{experiment_id}.pth`
- **æœ€ä¼˜æ¨¡åž‹**ï¼šæ¯ä¸ªé˜¶æ®µç»“æŸåŽï¼Œæ‰‹åŠ¨å¤‡ä»½æœ€ä¼˜æ¨¡åž‹ä¸º `models/stage{N}_best.pth`
- **ç£ç›˜ç©ºé—´**ï¼š88ä¸ªæ¨¡åž‹çº¦å 500MB-1GBç©ºé—´

### 3. ç»“æžœè¿½åŠ æœºåˆ¶

- æ‰€æœ‰å®žéªŒç»“æžœ**è¿½åŠ **åˆ° `results.csv`ï¼Œä¸è¦†ç›–
- é€šè¿‡ `experiment_id` åŽ»é‡ï¼Œé¿å…é‡å¤è¿è¡Œ
- å¦‚éœ€é‡æ–°è¿è¡Œï¼Œéœ€æ‰‹åŠ¨åˆ é™¤ CSV ä¸­çš„å¯¹åº”è¡Œ

### 4. å¯é‡çŽ°æ€§ä¿è¯

- æ‰€æœ‰å®žéªŒä½¿ç”¨å›ºå®šéšæœºç§å­ï¼š`seed=42`
- åœ¨ `notebooks/utils.py` ä¸­è®¾ç½®ï¼š
  ```python
  np.random.seed(42)
  torch.manual_seed(42)
  ```
- ç›¸åŒé…ç½®åº”äº§ç”Ÿç›¸åŒç»“æžœï¼ˆCPUæ¨¡å¼ä¸‹ï¼‰

### 5. æ—©åœæœºåˆ¶

- æ‰€æœ‰æ¨¡åž‹ä½¿ç”¨ Early Stoppingï¼ˆpatience=10ï¼‰
- å½“æµ‹è¯•é›†lossè¿žç»­10ä¸ªepochä¸ä¸‹é™æ—¶åœæ­¢è®­ç»ƒ
- è‡ªåŠ¨åŠ è½½æœ€ä½³æ¨¡åž‹æƒé‡ï¼ˆtest lossæœ€ä½Žçš„epochï¼‰

### 6. å­¦ä¹ çŽ‡è°ƒåº¦

- ä½¿ç”¨ `ReduceLROnPlateau`ï¼š
  - å½“æµ‹è¯•é›†lossè¿žç»­5ä¸ªepochä¸ä¸‹é™
  - å­¦ä¹ çŽ‡è¡°å‡ï¼š`lr = lr * 0.5`
- å¸®åŠ©æ¨¡åž‹è·³å‡ºå±€éƒ¨æœ€ä¼˜

### 7. æ—¶é—´é¢„ç®—å»ºè®®

- **é˜¶æ®µ1**ï¼šå¿…é¡»å®Œæˆï¼Œæ˜¯åŽç»­é˜¶æ®µçš„åŸºç¡€
- **é˜¶æ®µ2-4**ï¼šå¼ºçƒˆå»ºè®®å®Œæˆï¼Œå½±å“æœ€å¤§
- **é˜¶æ®µ5**ï¼šå¯é€‰ï¼Œå¦‚æžœé˜¶æ®µ1å·²ç¡®å®šæœ€ä¼˜ç®—æ³•å¯è·³è¿‡
- **é˜¶æ®µ6**ï¼šå¯é€‰ï¼Œå¦‚æžœæ—¶é—´ä¸è¶³å¯ä½¿ç”¨é»˜è®¤è¶…å‚æ•°
- **é˜¶æ®µ7**ï¼šå»ºè®®å®Œæˆï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›

---

## æŠ€æœ¯æ”¯æŒ / Support

### ç›¸å…³æ–‡æ¡£

- **é¡¹ç›®æ€»ä½“è¯´æ˜Ž**ï¼š`../CLAUDE.md`
- **å®žéªŒé…ç½®ä»£ç **ï¼š`experiments/experiment_configs.py`
- **Linear æ¨¡åž‹å®žçŽ°**ï¼š`notebooks/linear_regression.ipynb`
- **RNN æ¨¡åž‹å®žçŽ°**ï¼š`notebooks/rnn.ipynb`
- **å…±äº«å·¥å…·å‡½æ•°**ï¼š`notebooks/utils.py`

### å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```python
# èŽ·å–é˜¶æ®µé…ç½®
configs = get_stage_configs(stage_number)

# æ‰¹é‡è¿è¡Œå®žéªŒ
results = run_experiments_batch(configs, skip_completed=True)

# åˆ†æžç»“æžœ
summary = analyze_stage_results(stage_number)

# ç”ŸæˆæŠ¥å‘Š
generate_stage_report(stage_number)

# æŸ¥çœ‹å·²å®Œæˆå®žéªŒ
completed = load_completed_experiments()
print(f"å·²å®Œæˆ {len(completed)} ä¸ªå®žéªŒ")
```

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’

1. âœ… è¿è¡Œé˜¶æ®µ1å®žéªŒï¼ˆ6ä¸ªæ¨¡åž‹ï¼‰ï¼Œç¡®å®šæœ€ä¼˜ç®—æ³•
2. âœ… åˆ†æžé˜¶æ®µ1ç»“æžœï¼Œé€‰æ‹©åŽç»­å®žéªŒçš„åŸºå‡†ç®—æ³•
3. âœ… è¿è¡Œé˜¶æ®µ2å®žéªŒï¼ˆ10ä¸ªæ¨¡åž‹ï¼‰ï¼Œä¼˜åŒ–æ•°æ®é¢„å¤„ç†
4. âœ… è¿è¡Œé˜¶æ®µ3-4å®žéªŒï¼ˆ24ä¸ªæ¨¡åž‹ï¼‰ï¼Œä¼˜åŒ–ç‰¹å¾å’Œçª—å£
5. âœ… è¿è¡Œé˜¶æ®µ5å®žéªŒï¼ˆ12ä¸ªæ¨¡åž‹ï¼‰ï¼Œå¯¹æ¯”ç®—æ³•æ€§èƒ½
6. âœ… è¿è¡Œé˜¶æ®µ6å®žéªŒï¼ˆ15-27ä¸ªæ¨¡åž‹ï¼‰ï¼Œç²¾è°ƒè¶…å‚æ•°
7. âœ… è¿è¡Œé˜¶æ®µ7å®žéªŒï¼ˆ9ä¸ªæ¨¡åž‹ï¼‰ï¼Œæœ€ç»ˆéªŒè¯
8. âœ… ç”Ÿæˆæœ€ç»ˆå®žéªŒæŠ¥å‘Šï¼Œæ€»ç»“å„å› ç´ å½±å“
9. âœ… æ’°å†™è®ºæ–‡/æŠ¥å‘Š

---

**ç¥å®žéªŒé¡ºåˆ©ï¼ / Happy experimenting!** ðŸŽ‰

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ[å¸¸è§é—®é¢˜ FAQ](#å¸¸è§é—®é¢˜-faq)ç« èŠ‚ã€‚
