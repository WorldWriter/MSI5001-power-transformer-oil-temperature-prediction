{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 电力变压器油温预测 - 线性回归模型\n",
    "# Power Transformer Oil Temperature Prediction - Linear Regression\n",
    "\n",
    "本notebook使用线性回归模型预测变压器油温。\n",
    "\n",
    "**主要特性 / Key Features:**\n",
    "- 使用共享 `utils.py` 模块，代码简洁\n",
    "- 一次训练一个模型，参数可配置\n",
    "- 支持三种数据分割方式（sequential/random/label_random）\n",
    "- 支持特征选择（负载特征 + 时间特征）\n",
    "- 可选的异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需库 / Import Required Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 导入共享工具模块 / Import shared utilities\n",
    "from utils import *\n",
    "\n",
    "# 设置随机种子 / Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DEFAULT_CONFIG = {\n",
    "    # 数据配置 / Data Configuration\n",
    "    'dataset_path': '../dataset/train1.csv',\n",
    "    'prediction_horizon': 'hour',  # 'hour' (4 offsets) / 'day' (96 offsets) / 'week' (672 offsets)\n",
    "\n",
    "    # 分割方式 / Split Method\n",
    "    'split_method': 'sequential',  # 'sequential' / 'random' / 'label_random'\n",
    "    'train_ratio': 0.8,\n",
    "    'n_groups': 20,  # 仅用于 random 方式 / Only for 'random' method\n",
    "\n",
    "    # 特征选择 / Feature Selection\n",
    "    'load_features': ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL'],  # 可选任意组合\n",
    "    'time_features': [],  # 可选: ['hour', 'day', 'month', 'dayofweek', 'is_weekend', 'minute']\n",
    "\n",
    "    # 异常值处理 / Outlier Handling\n",
    "    'remove_outliers': False,  # 默认不剔除\n",
    "    'outlier_method': 'iqr',   # 'iqr' or 'zscore'\n",
    "    'outlier_threshold': 3.0,  # IQR倍数或Z-score阈值\n",
    "\n",
    "    # 模型超参数 / Model Hyperparameters\n",
    "    'seq_length': 16,\n",
    "    'hidden_sizes': [64, 32],  # For Linear Regression\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience': 10,  # Early stopping patience\n",
    "\n",
    "    # 其他 / Others\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"默认设备 / Default device: {DEFAULT_CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性回归模型定义 / Linear Regression Model Definition\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    多层线性回归模型 / Multi-layer Linear Regression Model\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, seq_length, hidden_sizes=[64, 32], dropout=0.2):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        # 展平输入\n",
    "        flattened_size = seq_length * input_size\n",
    "\n",
    "        # 构建网络层\n",
    "        layers = []\n",
    "        prev_size = flattened_size\n",
    "\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        # 输出层\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_length, input_size)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)  # 展平\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"LinearRegressionModel 已定义 / LinearRegressionModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数 / Training Function\n",
    "\n",
    "def train_model(train_loader, test_loader, input_size, seq_length,\n",
    "                hidden_sizes=[64, 32], dropout=0.2, num_epochs=100,\n",
    "                lr=0.001, patience=10, device='cpu'):\n",
    "    \"\"\"\n",
    "    训练线性回归模型 / Train Linear Regression Model\n",
    "\n",
    "    注意：每个epoch都会打印训练进度 / Note: Prints progress every epoch\n",
    "    \"\"\"\n",
    "    # 初始化模型\n",
    "    model = LinearRegressionModel(input_size, seq_length, hidden_sizes, dropout).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "\n",
    "    # 训练历史\n",
    "    history = {'train_loss': [], 'test_loss': [], 'train_mae': [], 'test_mae': []}\n",
    "    best_test_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模式\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_maes = []\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_maes.append(torch.mean(torch.abs(outputs - y_batch)).item())\n",
    "\n",
    "        # 评估模式\n",
    "        model.eval()\n",
    "        test_losses = []\n",
    "        test_maes = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "\n",
    "                test_losses.append(loss.item())\n",
    "                test_maes.append(torch.mean(torch.abs(outputs - y_batch)).item())\n",
    "\n",
    "        # 计算平均指标\n",
    "        train_loss = np.mean(train_losses)\n",
    "        test_loss = np.mean(test_losses)\n",
    "        train_mae = np.mean(train_maes)\n",
    "        test_mae = np.mean(test_maes)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_mae'].append(train_mae)\n",
    "        history['test_mae'].append(test_mae)\n",
    "\n",
    "        # 每个epoch打印 / Print every epoch\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.6f} | Test Loss: {test_loss:.6f}')\n",
    "\n",
    "        # 学习率调度\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping触发，在epoch {epoch+1} / Early stopping at epoch {epoch+1}')\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    return model, history\n",
    "\n",
    "print(\"训练函数已定义 / Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主训练函数 / Main Training Function\n",
    "\n",
    "def train_single_model(config=None, **kwargs):\n",
    "    \"\"\"\n",
    "    训练单个模型 / Train a single model\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    config : dict (配置字典，None时使用DEFAULT_CONFIG)\n",
    "    **kwargs : 可覆盖config中的任意参数\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict 包含模型、历史、评估指标等\n",
    "    \"\"\"\n",
    "    # 合并配置\n",
    "    if config is None:\n",
    "        config = DEFAULT_CONFIG.copy()\n",
    "    else:\n",
    "        config = config.copy()\n",
    "    config.update(kwargs)\n",
    "\n",
    "    # 获取预测时间范围配置\n",
    "    horizon = config['prediction_horizon']\n",
    "    horizon_cfg = HORIZON_CONFIGS[horizon]\n",
    "    offset = horizon_cfg['offset']\n",
    "    seq_length = config.get('seq_length', horizon_cfg['seq_length'])\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"训练配置 / Training Configuration:\")\n",
    "    print(f\"  数据集 / Dataset: {config['dataset_path']}\")\n",
    "    print(f\"  预测范围 / Horizon: {horizon} ({horizon_cfg['description']})\")\n",
    "    print(f\"  分割方式 / Split: {config['split_method']}\")\n",
    "    print(f\"  特征数 / Features: {len(config['load_features']) + len(config['time_features'])}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # 1. 加载数据\n",
    "    df = load_data(config['dataset_path'])\n",
    "    print(f\"数据加载完成 / Data loaded: {df.shape}\")\n",
    "\n",
    "    # 2. 异常值处理（可选）\n",
    "    if config['remove_outliers']:\n",
    "        df, n_removed = remove_outliers(\n",
    "            df,\n",
    "            method=config['outlier_method'],\n",
    "            threshold=config['outlier_threshold']\n",
    "        )\n",
    "        print(f\"移除异常值 / Removed outliers: {n_removed} 行\")\n",
    "\n",
    "    # 3. 特征选择\n",
    "    # 3a. 负载特征\n",
    "    load_cols = config['load_features']\n",
    "    X_load = df[load_cols].values\n",
    "\n",
    "    # 3b. 时间特征（可选）\n",
    "    if config['time_features']:\n",
    "        time_features_df = extract_time_features(df, config['time_features'])\n",
    "        X_time = time_features_df.values\n",
    "        X = np.concatenate([X_load, X_time], axis=1)\n",
    "        print(f\"特征组合 / Features: {len(load_cols)} 负载 + {len(config['time_features'])} 时间\")\n",
    "    else:\n",
    "        X = X_load\n",
    "        print(f\"使用负载特征 / Load features: {len(load_cols)}\")\n",
    "\n",
    "    # 目标变量\n",
    "    y = df['OT'].values\n",
    "\n",
    "    # 4. 创建序列\n",
    "    X_seq, y_seq = create_sequences_with_offset(X, y, seq_length, offset)\n",
    "    print(f\"序列创建完成 / Sequences created: {X_seq.shape}\")\n",
    "\n",
    "    # 5. 分割训练/测试集\n",
    "    split_method = config['split_method']\n",
    "    if split_method == 'sequential':\n",
    "        X_train, X_test, y_train, y_test = split_sequential(\n",
    "            X_seq, y_seq, config['train_ratio']\n",
    "        )\n",
    "    elif split_method == 'random':\n",
    "        X_train, X_test, y_train, y_test = split_random_groups(\n",
    "            X_seq, y_seq, config['n_groups'], config['train_ratio']\n",
    "        )\n",
    "    elif split_method == 'label_random':\n",
    "        X_train, X_test, y_train, y_test = split_label_random(\n",
    "            X_seq, y_seq, config['train_ratio']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"未知的分割方式: {split_method}\")\n",
    "\n",
    "    print(f\"数据分割完成 / Data split: Train {len(X_train)}, Test {len(X_test)}\")\n",
    "\n",
    "    # 6. 归一化（先分割后归一化，避免数据泄露）\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    # 展平进行归一化\n",
    "    n_train, seq_len, n_feat = X_train.shape\n",
    "    n_test = X_test.shape[0]\n",
    "\n",
    "    X_train_flat = X_train.reshape(-1, n_feat)\n",
    "    X_test_flat = X_test.reshape(-1, n_feat)\n",
    "\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train_flat).reshape(n_train, seq_len, n_feat)\n",
    "    X_test_scaled = scaler_X.transform(X_test_flat).reshape(n_test, seq_len, n_feat)\n",
    "\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "    print(\"归一化完成 / Normalization done\")\n",
    "\n",
    "    # 7. 创建DataLoader\n",
    "    train_loader, test_loader = create_dataloaders(\n",
    "        X_train_scaled, y_train_scaled,\n",
    "        X_test_scaled, y_test_scaled,\n",
    "        config['batch_size']\n",
    "    )\n",
    "\n",
    "    # 8. 训练模型\n",
    "    print(f\"\\n开始训练 / Start training...\\n\")\n",
    "    model, history = train_model(\n",
    "        train_loader, test_loader,\n",
    "        input_size=n_feat,\n",
    "        seq_length=seq_length,\n",
    "        hidden_sizes=config['hidden_sizes'],\n",
    "        dropout=config['dropout'],\n",
    "        num_epochs=config['num_epochs'],\n",
    "        lr=config['learning_rate'],\n",
    "        patience=config['patience'],\n",
    "        device=config['device']\n",
    "    )\n",
    "\n",
    "    # 9. 评估模型\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_t = torch.FloatTensor(X_test_scaled).to(config['device'])\n",
    "        y_pred_scaled = model(X_test_t).cpu().numpy()\n",
    "\n",
    "    # 反归一化\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled).ravel()\n",
    "\n",
    "    # 计算指标\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"最终评估结果 / Final Evaluation:\")\n",
    "    print(f\"  R² Score: {r2:.6f}\")\n",
    "    print(f\"  MSE: {mse:.6f}\")\n",
    "    print(f\"  MAE: {mae:.6f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # 返回结果\n",
    "    results = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'scalers': {'X': scaler_X, 'y': scaler_y},\n",
    "        'metrics': {'r2': r2, 'mse': mse, 'mae': mae},\n",
    "        'data': {\n",
    "            'X_train': X_train, 'X_test': X_test,\n",
    "            'y_train': y_train, 'y_test': y_test,\n",
    "            'y_pred': y_pred\n",
    "        },\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"主训练函数已定义 / Main training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用示例 / Usage Examples\n",
    "\n",
    "### 示例1：使用默认配置训练\n",
    "```python\n",
    "results = train_single_model()\n",
    "```\n",
    "\n",
    "### 示例2：自定义数据集和预测范围\n",
    "```python\n",
    "results = train_single_model(\n",
    "    dataset_path='../dataset/train2.csv',\n",
    "    prediction_horizon='day'\n",
    ")\n",
    "```\n",
    "\n",
    "### 示例3：使用label_random分割\n",
    "```python\n",
    "results = train_single_model(split_method='label_random')\n",
    "```\n",
    "\n",
    "### 示例4：启用异常值处理\n",
    "```python\n",
    "results = train_single_model(\n",
    "    remove_outliers=True,\n",
    "    outlier_threshold=3.0\n",
    ")\n",
    "```\n",
    "\n",
    "### 示例5：添加时间特征\n",
    "```python\n",
    "results = train_single_model(\n",
    "    time_features=['hour', 'dayofweek', 'is_weekend']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：使用默认配置训练 / Example: Train with default config\n",
    "results_default = train_single_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练历史 / Visualize Training History\n",
    "plot_training_history(results_default['history'], 'Linear Regression - Default Config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化预测结果 / Visualize Predictions\n",
    "plot_predictions(\n",
    "    results_default['data']['y_test'],\n",
    "    results_default['data']['y_pred'],\n",
    "    f\"Linear Regression - {results_default['config']['prediction_horizon'].upper()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比实验：三种分割方式 / Comparison: Three Split Methods\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"对比实验：三种数据分割方式对模型性能的影响\")\n",
    "print(\"Comparison: Impact of three data split methods on model performance\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# 简化配置用于快速对比\n",
    "quick_config = DEFAULT_CONFIG.copy()\n",
    "quick_config['num_epochs'] = 30  # 减少epochs用于快速测试\n",
    "\n",
    "split_methods = ['sequential', 'random', 'label_random']\n",
    "comparison_results = {}\n",
    "\n",
    "for method in split_methods:\n",
    "    print(f\"\\n{'*'*60}\")\n",
    "    print(f\"测试分割方式 / Testing split method: {method}\")\n",
    "    print(f\"{'*'*60}\")\n",
    "\n",
    "    results = train_single_model(\n",
    "        config=quick_config,\n",
    "        split_method=method\n",
    "    )\n",
    "    comparison_results[method] = results\n",
    "\n",
    "# 使用utils中的对比函数\n",
    "plot_comparison_summary(comparison_results)\n",
    "\n",
    "print(\"\\n注意 / Note:\")\n",
    "print(\"- sequential: 无数据泄露，最接近真实场景\")\n",
    "print(\"- random: 低数据泄露风险（组内连续）\")\n",
    "print(\"- label_random: 可能存在数据泄露（窗口重叠），R²可能虚高\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
