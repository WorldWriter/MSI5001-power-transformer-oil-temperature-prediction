{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rnn-intro",
   "metadata": {},
   "source": [
    "# Power Transformer Oil Temperature Prediction using RNN\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook implements a Recurrent Neural Network (RNN) model for predicting the oil temperature (OT) of power transformers. \n",
    "\n",
    "**Dataset**: ETDataset (Electricity Transformer Temperature)\n",
    "- Source: https://github.com/zhouhaoyi/ETDataset\n",
    "- From AAAI 2021 Best Paper (Informer model)\n",
    "\n",
    "**Features**:\n",
    "- HUFL: High UseFul Load\n",
    "- HULL: High UseLess Load  \n",
    "- MUFL: Middle UseFul Load\n",
    "- MULL: Middle UseLess Load\n",
    "- LUFL: Low UseFul Load\n",
    "- LULL: Low UseLess Load\n",
    "\n",
    "**Target**: OT (Oil Temperature)\n",
    "\n",
    "**Goal**: Build an RNN model to predict oil temperature based on historical load data and demonstrate:\n",
    "- Time series data preprocessing\n",
    "- RNN architecture for sequence prediction\n",
    "- Model training and evaluation\n",
    "- Performance metrics and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libs",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "We'll use:\n",
    "- pandas/numpy for data manipulation\n",
    "- sklearn for preprocessing and metrics\n",
    "- tensorflow/keras for building the RNN model\n",
    "- matplotlib for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore Data\n",
    "\n",
    "We'll load the transformer temperature dataset and perform initial exploration to understand:\n",
    "- Data shape and structure\n",
    "- Missing values\n",
    "- Statistical properties\n",
    "- Time series characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": "def load_data(filepath):\n    \"\"\"\n    Load the ETT dataset\n    \n    Parameters:\n    -----------\n    filepath : str\n        Path to the CSV file\n    \n    Returns:\n    --------\n    df : pd.DataFrame\n        Loaded dataframe with date as index\n    \"\"\"\n    df = pd.read_csv(filepath)\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n    return df\n\n# Load pre-split training and test data\ntrain_filepath = '../dataset/processed_data/train.csv'\ntest_filepath = '../dataset/processed_data/test.csv'\n\ndf_train_full = load_data(train_filepath)\ndf_test_full = load_data(test_filepath)\n\n# For initial exploration and model training, we'll use the training data\n# The test data will be used only for final evaluation\ndf = df_train_full\n\nprint(\"Dataset loaded from pre-split files:\")\nprint(f\"  Training data: {train_filepath}\")\nprint(f\"  Test data: {test_filepath}\")\nprint(f\"\\nTraining set shape: {df_train_full.shape}\")\nprint(f\"Test set shape: {df_test_full.shape}\")\nprint(f\"\\nFirst few rows of training data:\")\nprint(df.head())\nprint(\"\\nDataset Info:\")\nprint(df.info())\nprint(\"\\nBasic Statistics:\")\nprint(df.describe())\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())"
  },
  {
   "cell_type": "markdown",
   "id": "visualize-header",
   "metadata": {},
   "source": [
    "## Step 3: Data Visualization\n",
    "\n",
    "Visualize the time series to understand patterns and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all features over time\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 12))\n",
    "fig.suptitle('Time Series of All Features', fontsize=16)\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.plot(df.index[:2000], df[col][:2000])  # Plot first 2000 points for clarity\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, fmt='.2f')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-header",
   "metadata": {},
   "source": [
    "## Step 4: Data Preprocessing\n",
    "\n",
    "### 4.1 Feature and Target Separation\n",
    "\n",
    "We'll separate features (load data) from target (OT - Oil Temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_target(df):\n",
    "    \"\"\"\n",
    "    Separate features and target variable\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : np.ndarray\n",
    "        Features (all columns except OT)\n",
    "    y : np.ndarray\n",
    "        Target (OT column)\n",
    "    \"\"\"\n",
    "    # Features: all columns except OT\n",
    "    X = df.drop('OT', axis=1).values\n",
    "    # Target: OT (Oil Temperature)\n",
    "    y = df['OT'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = prepare_features_target(df)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names: {df.drop('OT', axis=1).columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normalize-header",
   "metadata": {},
   "source": [
    "### 4.2 Data Normalization\n",
    "\n",
    "Normalize features and target to improve RNN training stability and convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X, y):\n",
    "    \"\"\"\n",
    "    Normalize features and target using StandardScaler\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Features\n",
    "    y : np.ndarray\n",
    "        Target\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_scaled : np.ndarray\n",
    "        Normalized features\n",
    "    y_scaled : np.ndarray\n",
    "        Normalized target\n",
    "    scaler_X : StandardScaler\n",
    "        Fitted scaler for features\n",
    "    scaler_y : StandardScaler\n",
    "        Fitted scaler for target\n",
    "    \"\"\"\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    \n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return X_scaled, y_scaled, scaler_X, scaler_y\n",
    "\n",
    "X_scaled, y_scaled, scaler_X, scaler_y = normalize_data(X, y)\n",
    "print(\"Data normalized successfully!\")\n",
    "print(f\"\\nFeatures - Mean: {X_scaled.mean():.4f}, Std: {X_scaled.std():.4f}\")\n",
    "print(f\"Target - Mean: {y_scaled.mean():.4f}, Std: {y_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sequence-header",
   "metadata": {},
   "source": [
    "### 4.3 Create Time Series Sequences\n",
    "\n",
    "Transform data into sequences for RNN input. We use a sliding window approach:\n",
    "- Input: Past `seq_length` time steps\n",
    "- Output: Next time step's oil temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-sequences",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, seq_length=24):\n",
    "    \"\"\"\n",
    "    Create sequences for time series prediction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Features array\n",
    "    y : np.ndarray\n",
    "        Target array\n",
    "    seq_length : int\n",
    "        Number of time steps to look back (default: 24 = 6 hours with 15-min intervals)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_seq : np.ndarray\n",
    "        Sequences of features (samples, seq_length, n_features)\n",
    "    y_seq : np.ndarray\n",
    "        Target values for each sequence\n",
    "    \"\"\"\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create sequences with lookback window of 24 time steps (6 hours)\n",
    "seq_length = 24\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "print(f\"Sequence length (lookback window): {seq_length}\")\n",
    "print(f\"X_seq shape: {X_seq.shape} (samples, time_steps, features)\")\n",
    "print(f\"y_seq shape: {y_seq.shape}\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"- Input: {seq_length} time steps of {X_seq.shape[2]} features\")\n",
    "print(f\"- Output: 1 time step oil temperature prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-header",
   "metadata": {},
   "source": [
    "### 4.4 Train/Test Split\n",
    "\n",
    "Split data into training and testing sets. For time series, we use temporal split (not random)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": "# Since data is already pre-split into train and test sets,\n# we process them separately and create sequences for each\n\n# Process training data\nX_train_full, y_train_full = prepare_features_target(df_train_full)\nX_train_scaled, y_train_scaled, scaler_X, scaler_y = normalize_data(X_train_full, y_train_full)\nX_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n\n# Further split training data for validation (80% train, 20% validation)\nval_split_idx = int(len(X_train_seq) * 0.8)\nX_train = X_train_seq[:val_split_idx]\ny_train = y_train_seq[:val_split_idx]\nX_val = X_train_seq[val_split_idx:]\ny_val = y_train_seq[val_split_idx:]\n\n# Process test data (using fitted scalers from training)\nX_test_full, y_test_full = prepare_features_target(df_test_full)\nX_test_scaled = scaler_X.transform(X_test_full)\ny_test_scaled = scaler_y.transform(y_test_full.reshape(-1, 1)).flatten()\nX_test, y_test = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n\nprint(\"Data prepared from pre-split files!\")\nprint(f\"\\nTraining set (for model fitting):\")\nprint(f\"  X_train shape: {X_train.shape}\")\nprint(f\"  y_train shape: {y_train.shape}\")\nprint(f\"\\nValidation set (from training data):\")\nprint(f\"  X_val shape: {X_val.shape}\")\nprint(f\"  y_val shape: {y_val.shape}\")\nprint(f\"\\nTest set (held-out data):\")\nprint(f\"  X_test shape: {X_test.shape}\")\nprint(f\"  y_test shape: {y_test.shape}\")\nprint(f\"\\nNote: Scalers fitted on training data and applied to test data\")"
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Step 5: Build RNN Model\n",
    "\n",
    "We'll build a Simple RNN model with:\n",
    "- Input layer: sequences of features\n",
    "- RNN layers: to capture temporal dependencies\n",
    "- Dropout layers: for regularization\n",
    "- Dense output layer: for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model(input_shape, units=[64, 32]):\n",
    "    \"\"\"\n",
    "    Build a Simple RNN model for time series prediction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_shape : tuple\n",
    "        Shape of input (time_steps, n_features)\n",
    "    units : list\n",
    "        Number of units in each RNN layer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Compiled RNN model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First RNN layer - returns sequences for next layer\n",
    "        SimpleRNN(units[0], return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Second RNN layer - returns only last output\n",
    "        SimpleRNN(units[1], return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Dense layers for final prediction\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        \n",
    "        # Output layer (single value - oil temperature)\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (seq_length, n_features)\n",
    "model = build_rnn_model(input_shape, units=[64, 32])\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model\n",
    "\n",
    "Train the RNN with callbacks for:\n",
    "- Early stopping: prevent overfitting\n",
    "- Learning rate reduction: improve convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": "# Define callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True,\n    verbose=1\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    min_lr=1e-7,\n    verbose=1\n)\n\n# Train model using separate validation set\nprint(\"Training the RNN model...\\n\")\nhistory = model.fit(\n    X_train, y_train,\n    epochs=100,\n    batch_size=32,\n    validation_data=(X_val, y_val),  # Use separate validation set\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\nprint(\"\\nTraining completed!\")"
  },
  {
   "cell_type": "markdown",
   "id": "history-header",
   "metadata": {},
   "source": [
    "### 6.1 Training History Visualization\n",
    "\n",
    "Plot training and validation loss curves to check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0].set_title('Model Loss During Training')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss (MSE)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE\n",
    "    axes[1].plot(history.history['mae'], label='Training MAE')\n",
    "    axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "    axes[1].set_title('Model MAE During Training')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-header",
   "metadata": {},
   "source": [
    "## Step 7: Model Evaluation\n",
    "\n",
    "### 7.1 Make Predictions\n",
    "\n",
    "Generate predictions on test set and inverse transform to original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "y_train_actual = scaler_y.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_train_pred_inv = scaler_y.inverse_transform(y_train_pred).flatten()\n",
    "\n",
    "y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "y_test_pred_inv = scaler_y.inverse_transform(y_test_pred).flatten()\n",
    "\n",
    "print(\"Predictions generated successfully!\")\n",
    "print(f\"\\nSample predictions (first 5):\")\n",
    "print(f\"Actual:    {y_test_actual[:5]}\")\n",
    "print(f\"Predicted: {y_test_pred_inv[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics-header",
   "metadata": {},
   "source": [
    "### 7.2 Calculate Evaluation Metrics\n",
    "\n",
    "Compute standard regression metrics to assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, set_name='Test'):\n",
    "    \"\"\"\n",
    "    Calculate and display regression metrics\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"\\n{set_name} Set Performance Metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"MSE (Mean Squared Error):        {mse:.4f}\")\n",
    "    print(f\"RMSE (Root Mean Squared Error):  {rmse:.4f}\")\n",
    "    print(f\"MAE (Mean Absolute Error):       {mae:.4f}\")\n",
    "    print(f\"R² Score:                        {r2:.4f}\")\n",
    "    print(f\"MAPE (Mean Absolute % Error):    {mape:.2f}%\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "# Calculate metrics for both sets\n",
    "train_metrics = calculate_metrics(y_train_actual, y_train_pred_inv, 'Training')\n",
    "test_metrics = calculate_metrics(y_test_actual, y_test_pred_inv, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-results-header",
   "metadata": {},
   "source": [
    "## Step 8: Results Visualization\n",
    "\n",
    "### 8.1 Actual vs Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Test set - full view\n",
    "axes[0].plot(y_test_actual, label='Actual', alpha=0.7, linewidth=1.5)\n",
    "axes[0].plot(y_test_pred_inv, label='Predicted', alpha=0.7, linewidth=1.5)\n",
    "axes[0].set_title('Oil Temperature Prediction - Test Set (Full View)', fontsize=14)\n",
    "axes[0].set_xlabel('Time Step')\n",
    "axes[0].set_ylabel('Oil Temperature (°C)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test set - zoomed view (first 500 points)\n",
    "zoom_range = 500\n",
    "axes[1].plot(y_test_actual[:zoom_range], label='Actual', alpha=0.7, linewidth=1.5)\n",
    "axes[1].plot(y_test_pred_inv[:zoom_range], label='Predicted', alpha=0.7, linewidth=1.5)\n",
    "axes[1].set_title(f'Oil Temperature Prediction - Test Set (First {zoom_range} Points)', fontsize=14)\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_ylabel('Oil Temperature (°C)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scatter-header",
   "metadata": {},
   "source": [
    "### 8.2 Scatter Plot: Predicted vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scatter-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test_actual, y_test_pred_inv, alpha=0.5, s=20)\n",
    "plt.plot([y_test_actual.min(), y_test_actual.max()], \n",
    "         [y_test_actual.min(), y_test_actual.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Oil Temperature (°C)', fontsize=12)\n",
    "plt.ylabel('Predicted Oil Temperature (°C)', fontsize=12)\n",
    "plt.title('Predicted vs Actual Oil Temperature (Test Set)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residuals-header",
   "metadata": {},
   "source": [
    "### 8.3 Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residuals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test_actual - y_test_pred_inv\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Residual plot\n",
    "axes[0].scatter(y_test_pred_inv, residuals, alpha=0.5, s=20)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted Oil Temperature (°C)')\n",
    "axes[0].set_ylabel('Residuals (°C)')\n",
    "axes[0].set_title('Residual Plot')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residuals (°C)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Residuals')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual Statistics:\")\n",
    "print(f\"Mean: {residuals.mean():.4f}°C\")\n",
    "print(f\"Std: {residuals.std():.4f}°C\")\n",
    "print(f\"Min: {residuals.min():.4f}°C\")\n",
    "print(f\"Max: {residuals.max():.4f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-header",
   "metadata": {},
   "source": [
    "## Step 9: Conclusion and Summary\n",
    "\n",
    "### Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary comparison\n",
    "summary_df = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'RMSE', 'MAE', 'R²', 'MAPE (%)'],\n",
    "    'Training': [\n",
    "        train_metrics['MSE'],\n",
    "        train_metrics['RMSE'],\n",
    "        train_metrics['MAE'],\n",
    "        train_metrics['R2'],\n",
    "        train_metrics['MAPE']\n",
    "    ],\n",
    "    'Test': [\n",
    "        test_metrics['MSE'],\n",
    "        test_metrics['RMSE'],\n",
    "        test_metrics['MAE'],\n",
    "        test_metrics['R2'],\n",
    "        test_metrics['MAPE']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RNN MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n### Key Observations:\")\n",
    "print(f\"1. The model achieves R² score of {test_metrics['R2']:.4f} on test set\")\n",
    "print(f\"2. Average prediction error (MAE): {test_metrics['MAE']:.4f}°C\")\n",
    "print(f\"3. MAPE: {test_metrics['MAPE']:.2f}%\")\n",
    "\n",
    "if abs(train_metrics['R2'] - test_metrics['R2']) < 0.05:\n",
    "    print(\"4. Model shows good generalization (minimal overfitting)\")\n",
    "else:\n",
    "    print(\"4. Consider regularization or more data to reduce overfitting\")\n",
    "\n",
    "print(\"\\n### Model Architecture:\")\n",
    "print(f\"- Sequence Length: {seq_length} time steps (6 hours)\")\n",
    "print(f\"- RNN Units: {[64, 32]}\")\n",
    "print(f\"- Total Parameters: {model.count_params():,}\")\n",
    "\n",
    "print(\"\\n### Next Steps:\")\n",
    "print(\"1. Compare with other models (Linear Regression, Random Forest, MLP)\")\n",
    "print(\"2. Try advanced architectures (LSTM, GRU)\")\n",
    "print(\"3. Experiment with different sequence lengths\")\n",
    "print(\"4. Feature engineering to improve performance\")\n",
    "print(\"5. Compare with SOTA model (Informer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model-header",
   "metadata": {},
   "source": [
    "### Optional: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save the model\n",
    "# model.save('../models/rnn_model.h5')\n",
    "# print(\"Model saved to ../models/rnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}