{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rnn-intro",
   "metadata": {},
   "source": [
    "# 使用 RNN 预测电力变压器油温 / Power Transformer Oil Temperature Prediction using RNN\n",
    "\n",
    "## 简介 / Introduction\n",
    "\n",
    "本 notebook 实现了一个循环神经网络（RNN）模型来预测电力变压器的油温（OT）。\n",
    "\n",
    "This notebook implements a Recurrent Neural Network (RNN) model for predicting the oil temperature (OT) of power transformers.\n",
    "\n",
    "**数据集 / Dataset**: ETDataset (电力变压器温度数据集 / Electricity Transformer Temperature)\n",
    "- 来源 / Source: https://github.com/zhouhaoyi/ETDataset\n",
    "- 出处 / From: AAAI 2021 最佳论文（Informer 模型）/ AAAI 2021 Best Paper (Informer model)\n",
    "\n",
    "**特征 / Features**:\n",
    "- HUFL: 高压有功负载 / High UseFul Load\n",
    "- HULL: 高压无功负载 / High UseLess Load  \n",
    "- MUFL: 中压有功负载 / Medium UseFul Load\n",
    "- MULL: 中压无功负载 / Medium UseLess Load\n",
    "- LUFL: 低压有功负载 / Low UseFul Load\n",
    "- LULL: 低压无功负载 / Low UseLess Load\n",
    "\n",
    "**目标变量 / Target**: OT (油温 / Oil Temperature)\n",
    "\n",
    "**目标 / Goal**: 基于历史负载数据构建 RNN 模型预测油温，并展示：\n",
    "- 时间序列数据预处理 / Time series data preprocessing\n",
    "- 用于序列预测的 RNN 架构 / RNN architecture for sequence prediction\n",
    "- 模型训练与评估 / Model training and evaluation\n",
    "- 性能指标与可视化 / Performance metrics and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libs",
   "metadata": {},
   "source": [
    "## 步骤 1: 导入所需库 / Step 1: Import Required Libraries\n",
    "\n",
    "我们将使用 / We'll use:\n",
    "- pandas/numpy: 数据处理 / data manipulation\n",
    "- sklearn: 预处理和评估指标 / preprocessing and metrics\n",
    "- **PyTorch**: 构建 RNN 模型 / building the RNN model\n",
    "- matplotlib: 可视化 / visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理 / Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 预处理 / Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 深度学习 / Deep Learning - PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 可视化 / Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 工具 / Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子以保证可复现性 / Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# 设备配置 / Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch 版本 / PyTorch version: {torch.__version__}\")\n",
    "print(f\"设备 / Device: {device}\")\n",
    "print(f\"CUDA 可用 / CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## 步骤 2: 加载和探索数据 / Step 2: Load and Explore Data\n",
    "\n",
    "我们将加载变压器温度数据集并进行初步探索以了解：\n",
    "\n",
    "We'll load the transformer temperature dataset and perform initial exploration to understand:\n",
    "- 数据形状和结构 / Data shape and structure\n",
    "- 缺失值 / Missing values\n",
    "- 统计属性 / Statistical properties\n",
    "- 时间序列特征 / Time series characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Load the ETT dataset\n",
    "    加载 ETT 数据集\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df : pd.DataFrame\n",
    "        Loaded dataframe with date as index\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('date')\n",
    "    return df\n",
    "\n",
    "# Load pre-split training and test data\n",
    "# 加载预先切分的训练集和测试集\n",
    "train_filepath = '../dataset/processed_data/train.csv'\n",
    "test_filepath = '../dataset/processed_data/test.csv'\n",
    "\n",
    "df_train_full = load_data(train_filepath)\n",
    "df_test_full = load_data(test_filepath)\n",
    "\n",
    "# For initial exploration and model training, we'll use the training data\n",
    "# The test data will be used only for final evaluation\n",
    "# 初步探索和模型训练使用训练数据，测试数据仅用于最终评估\n",
    "df = df_train_full\n",
    "\n",
    "print(\"Dataset loaded from pre-split files:\")\n",
    "print(f\"  Training data: {train_filepath}\")\n",
    "print(f\"  Test data: {test_filepath}\")\n",
    "print(f\"\\nTraining set shape: {df_train_full.shape}\")\n",
    "print(f\"Test set shape: {df_test_full.shape}\")\n",
    "print(f\"\\nFirst few rows of training data:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-header",
   "metadata": {},
   "source": [
    "## 步骤 3: 数据可视化 / Step 3: Data Visualization\n",
    "\n",
    "可视化时间序列以理解模式和关系\n",
    "\n",
    "Visualize the time series to understand patterns and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all features over time\n",
    "# 绘制所有特征随时间的变化\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 12))\n",
    "fig.suptitle('Time Series of All Features / 所有特征的时间序列', fontsize=16)\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.plot(df.index[:2000], df[col][:2000])  # Plot first 2000 points for clarity\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Time / 时间')\n",
    "    ax.set_ylabel('Value / 值')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "# 相关性热力图\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, fmt='.2f')\n",
    "plt.title('Feature Correlation Heatmap / 特征相关性热力图')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-header",
   "metadata": {},
   "source": [
    "## 步骤 4: 数据预处理 / Step 4: Data Preprocessing\n",
    "\n",
    "### 4.1 特征和目标分离 / Feature and Target Separation\n",
    "\n",
    "我们将特征（负载数据）与目标（OT - 油温）分离\n",
    "\n",
    "We'll separate features (load data) from target (OT - Oil Temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_target(df):\n",
    "    \"\"\"\n",
    "    Separate features and target variable\n",
    "    分离特征和目标变量\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : np.ndarray\n",
    "        Features (all columns except OT)\n",
    "    y : np.ndarray\n",
    "        Target (OT column)\n",
    "    \"\"\"\n",
    "    # Features: all columns except OT\n",
    "    # 特征：除 OT 外的所有列\n",
    "    X = df.drop('OT', axis=1).values\n",
    "    # Target: OT (Oil Temperature)\n",
    "    # 目标：OT（油温）\n",
    "    y = df['OT'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = prepare_features_target(df)\n",
    "print(f\"Features shape / 特征形状: {X.shape}\")\n",
    "print(f\"Target shape / 目标形状: {y.shape}\")\n",
    "print(f\"\\nFeature names / 特征名称: {df.drop('OT', axis=1).columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normalize-header",
   "metadata": {},
   "source": [
    "### 4.2 数据标准化 / Data Normalization\n",
    "\n",
    "标准化特征和目标以提高 RNN 训练稳定性和收敛性\n",
    "\n",
    "Normalize features and target to improve RNN training stability and convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X, y):\n",
    "    \"\"\"\n",
    "    Normalize features and target using StandardScaler\n",
    "    使用 StandardScaler 标准化特征和目标\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Features\n",
    "    y : np.ndarray\n",
    "        Target\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_scaled : np.ndarray\n",
    "        Normalized features\n",
    "    y_scaled : np.ndarray\n",
    "        Normalized target\n",
    "    scaler_X : StandardScaler\n",
    "        Fitted scaler for features\n",
    "    scaler_y : StandardScaler\n",
    "        Fitted scaler for target\n",
    "    \"\"\"\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    \n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return X_scaled, y_scaled, scaler_X, scaler_y\n",
    "\n",
    "X_scaled, y_scaled, scaler_X, scaler_y = normalize_data(X, y)\n",
    "print(\"Data normalized successfully! / 数据标准化成功！\")\n",
    "print(f\"\\nFeatures - Mean: {X_scaled.mean():.4f}, Std: {X_scaled.std():.4f}\")\n",
    "print(f\"Target - Mean: {y_scaled.mean():.4f}, Std: {y_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sequence-header",
   "metadata": {},
   "source": [
    "### 4.3 创建时间序列序列 / Create Time Series Sequences\n",
    "\n",
    "将数据转换为 RNN 输入序列。我们使用滑动窗口方法：\n",
    "\n",
    "Transform data into sequences for RNN input. We use a sliding window approach:\n",
    "- 输入：过去 `seq_length` 个时间步 / Input: Past `seq_length` time steps\n",
    "- 输出：下一个时间步的油温 / Output: Next time step's oil temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-sequences",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, seq_length=24):\n",
    "    \"\"\"\n",
    "    Create sequences for time series prediction\n",
    "    创建时间序列预测的序列\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Features array\n",
    "    y : np.ndarray\n",
    "        Target array\n",
    "    seq_length : int\n",
    "        Number of time steps to look back (default: 24 = 6 hours with 15-min intervals)\n",
    "        回溯的时间步数（默认：24 = 15分钟间隔下的6小时）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_seq : np.ndarray\n",
    "        Sequences of features (samples, seq_length, n_features)\n",
    "    y_seq : np.ndarray\n",
    "        Target values for each sequence\n",
    "    \"\"\"\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create sequences with lookback window of 24 time steps (6 hours)\n",
    "# 创建回溯窗口为24个时间步（6小时）的序列\n",
    "seq_length = 24\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "print(f\"Sequence length (lookback window) / 序列长度（回溯窗口）: {seq_length}\")\n",
    "print(f\"X_seq shape: {X_seq.shape} (samples, time_steps, features)\")\n",
    "print(f\"y_seq shape: {y_seq.shape}\")\n",
    "print(f\"\\nExample / 示例:\")\n",
    "print(f\"- Input / 输入: {seq_length} time steps of {X_seq.shape[2]} features\")\n",
    "print(f\"- Output / 输出: 1 time step oil temperature prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-header",
   "metadata": {},
   "source": [
    "### 4.4 训练集/测试集分割 / Train/Test Split\n",
    "\n",
    "将数据分割为训练集和测试集。对于时间序列，我们使用时间分割（非随机）。\n",
    "\n",
    "Split data into training and testing sets. For time series, we use temporal split (not random)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since data is already pre-split into train and test sets,\n",
    "# we process them separately and create sequences for each\n",
    "# 由于数据已经预先分割为训练集和测试集，我们分别处理它们并为每个创建序列\n",
    "\n",
    "# Process training data / 处理训练数据\n",
    "X_train_full, y_train_full = prepare_features_target(df_train_full)\n",
    "X_train_scaled, y_train_scaled, scaler_X, scaler_y = normalize_data(X_train_full, y_train_full)\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "\n",
    "# Further split training data for validation (80% train, 20% validation)\n",
    "# 进一步分割训练数据用于验证（80% 训练，20% 验证）\n",
    "val_split_idx = int(len(X_train_seq) * 0.8)\n",
    "X_train = X_train_seq[:val_split_idx]\n",
    "y_train = y_train_seq[:val_split_idx]\n",
    "X_val = X_train_seq[val_split_idx:]\n",
    "y_val = y_train_seq[val_split_idx:]\n",
    "\n",
    "# Process test data (using fitted scalers from training)\n",
    "# 处理测试数据（使用从训练集拟合的缩放器）\n",
    "X_test_full, y_test_full = prepare_features_target(df_test_full)\n",
    "X_test_scaled = scaler_X.transform(X_test_full)\n",
    "y_test_scaled = scaler_y.transform(y_test_full.reshape(-1, 1)).flatten()\n",
    "X_test, y_test = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "print(\"Data prepared from pre-split files! / 从预分割文件准备数据完成！\")\n",
    "print(f\"\\nTraining set (for model fitting) / 训练集（用于模型拟合）:\")\n",
    "print(f\"  X_train shape: {X_train.shape}\")\n",
    "print(f\"  y_train shape: {y_train.shape}\")\n",
    "print(f\"\\nValidation set (from training data) / 验证集（来自训练数据）:\")\n",
    "print(f\"  X_val shape: {X_val.shape}\")\n",
    "print(f\"  y_val shape: {y_val.shape}\")\n",
    "print(f\"\\nTest set (held-out data) / 测试集（保留数据）:\")\n",
    "print(f\"  X_test shape: {X_test.shape}\")\n",
    "print(f\"  y_test shape: {y_test.shape}\")\n",
    "print(f\"\\nNote: Scalers fitted on training data and applied to test data\")\n",
    "print(f\"注意：缩放器在训练数据上拟合并应用于测试数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 步骤 5: 构建 RNN 模型 / Step 5: Build RNN Model\n",
    "\n",
    "我们将构建一个简单的 RNN 模型，包含：\n",
    "\n",
    "We'll build a Simple RNN model with:\n",
    "- 输入层：特征序列 / Input layer: sequences of features\n",
    "- RNN 层：捕获时间依赖关系 / RNN layers: to capture temporal dependencies\n",
    "- Dropout 层：用于正则化 / Dropout layers: for regularization\n",
    "- 全连接输出层：用于回归 / Dense output layer: for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple RNN model for time series prediction\n",
    "    用于时间序列预测的简单 RNN 模型\n",
    "    \n",
    "    Architecture / 架构:\n",
    "    - RNN Layer 1: input_size -> hidden_size[0]\n",
    "    - Dropout\n",
    "    - RNN Layer 2: hidden_size[0] -> hidden_size[1]\n",
    "    - Dropout\n",
    "    - Fully Connected Layer 1: hidden_size[1] -> 16\n",
    "    - ReLU activation\n",
    "    - Dropout\n",
    "    - Output Layer: 16 -> 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes=[64, 32], dropout=0.2):\n",
    "        super(SimpleRNNModel, self).__init__()\n",
    "        \n",
    "        # First RNN layer\n",
    "        self.rnn1 = nn.RNN(input_size, hidden_sizes[0], batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Second RNN layer\n",
    "        self.rnn2 = nn.RNN(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_sizes[1], 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(dropout * 0.5)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_length, input_size)\n",
    "        \n",
    "        # RNN layer 1\n",
    "        out, _ = self.rnn1(x)  # out shape: (batch_size, seq_length, hidden_sizes[0])\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        # RNN layer 2 (only use last output)\n",
    "        out, _ = self.rnn2(out)  # out shape: (batch_size, seq_length, hidden_sizes[1])\n",
    "        out = self.dropout2(out)\n",
    "        out = out[:, -1, :]  # Take only last time step: (batch_size, hidden_sizes[1])\n",
    "        \n",
    "        # Fully connected layers\n",
    "        out = self.fc1(out)  # (batch_size, 16)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout3(out)\n",
    "        out = self.fc2(out)  # (batch_size, 1)\n",
    "        \n",
    "        return out.squeeze()  # (batch_size,)\n",
    "\n",
    "# Model parameters / 模型参数\n",
    "input_size = X_train.shape[2]  # Number of features / 特征数量\n",
    "hidden_sizes = [64, 32]  # RNN hidden units / RNN 隐藏单元\n",
    "dropout = 0.2  # Dropout rate / Dropout 率\n",
    "\n",
    "# Initialize model / 初始化模型\n",
    "model = SimpleRNNModel(input_size, hidden_sizes, dropout).to(device)\n",
    "\n",
    "print(\"Model Architecture / 模型架构:\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count parameters / 统计参数\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal Parameters / 总参数数: {total_params:,}\")\n",
    "print(f\"Trainable Parameters / 可训练参数数: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 步骤 6: 训练模型 / Step 6: Train the Model\n",
    "\n",
    "使用以下方法训练 RNN：\n",
    "\n",
    "Train the RNN with:\n",
    "- Adam 优化器 / Adam optimizer\n",
    "- MSE 损失函数 / MSE loss function\n",
    "- 学习率调度器：提高收敛性 / Learning rate scheduler: improve convergence\n",
    "- 早停：防止过拟合 / Early stopping: prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-dataloaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "# 将 numpy 数组转换为 PyTorch 张量\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# Create TensorDatasets\n",
    "# 创建 TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "# 创建 DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Batch size / 批次大小: {batch_size}\")\n",
    "print(f\"Number of training batches / 训练批次数: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches / 验证批次数: {len(val_loader)}\")\n",
    "print(f\"Number of test batches / 测试批次数: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration / 训练配置\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss / 均方误差损失\n",
    "optimizer = Adam(model.parameters(), lr=0.001)  # Adam optimizer / Adam 优化器\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, \n",
    "                              min_lr=1e-7, verbose=True)\n",
    "\n",
    "# Early stopping parameters / 早停参数\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop / 训练循环\n",
    "num_epochs = 100\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_mae': [],\n",
    "    'val_mae': []\n",
    "}\n",
    "\n",
    "print(\"Training the RNN model... / 训练 RNN 模型...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase / 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_mae = 0.0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_mae += torch.mean(torch.abs(outputs - batch_y)).item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_mae /= len(train_loader)\n",
    "    \n",
    "    # Validation phase / 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_mae = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_mae += torch.mean(torch.abs(outputs - batch_y)).item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_mae /= len(val_loader)\n",
    "    \n",
    "    # Store history / 存储历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    \n",
    "    # Learning rate scheduling / 学习率调度\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping / 早停\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    # Print progress / 打印进度\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  Train Loss: {train_loss:.6f}, Train MAE: {train_mae:.6f}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.6f}, Val MAE:   {val_mae:.6f}\")\n",
    "        print(f\"  Best Val Loss: {best_val_loss:.6f}\")\n",
    "    \n",
    "    # Check early stopping / 检查早停\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"\\nEarly stopping triggered after epoch {epoch+1}\")\n",
    "        print(f\"提前停止在第 {epoch+1} 轮后触发\")\n",
    "        break\n",
    "\n",
    "# Restore best model / 恢复最佳模型\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\nRestored best model with validation loss: {best_val_loss:.6f}\")\n",
    "    print(f\"恢复验证损失为 {best_val_loss:.6f} 的最佳模型\")\n",
    "\n",
    "print(\"\\nTraining completed! / 训练完成！\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "history-header",
   "metadata": {},
   "source": [
    "### 6.1 训练历史可视化 / Training History Visualization\n",
    "\n",
    "绘制训练和验证损失曲线以检查过拟合\n",
    "\n",
    "Plot training and validation loss curves to check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics\n",
    "    绘制训练和验证指标\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Training Loss / 训练损失')\n",
    "    axes[0].plot(history['val_loss'], label='Validation Loss / 验证损失')\n",
    "    axes[0].set_title('Model Loss During Training / 训练期间的模型损失')\n",
    "    axes[0].set_xlabel('Epoch / 轮次')\n",
    "    axes[0].set_ylabel('Loss (MSE) / 损失 (MSE)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE\n",
    "    axes[1].plot(history['train_mae'], label='Training MAE / 训练 MAE')\n",
    "    axes[1].plot(history['val_mae'], label='Validation MAE / 验证 MAE')\n",
    "    axes[1].set_title('Model MAE During Training / 训练期间的模型 MAE')\n",
    "    axes[1].set_xlabel('Epoch / 轮次')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-header",
   "metadata": {},
   "source": [
    "## 步骤 7: 模型评估 / Step 7: Model Evaluation\n",
    "\n",
    "### 7.1 生成预测 / Make Predictions\n",
    "\n",
    "在测试集上生成预测并反向转换到原始尺度\n",
    "\n",
    "Generate predictions on test set and inverse transform to original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions / 生成预测\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Training set predictions / 训练集预测\n",
    "    y_train_pred = []\n",
    "    for batch_X, _ in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        y_train_pred.append(outputs.cpu().numpy())\n",
    "    y_train_pred = np.concatenate(y_train_pred)\n",
    "    \n",
    "    # Test set predictions / 测试集预测\n",
    "    y_test_pred = []\n",
    "    for batch_X, _ in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        y_test_pred.append(outputs.cpu().numpy())\n",
    "    y_test_pred = np.concatenate(y_test_pred)\n",
    "\n",
    "# Inverse transform to original scale / 反向转换到原始尺度\n",
    "y_train_actual = scaler_y.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_train_pred_inv = scaler_y.inverse_transform(y_train_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "y_test_pred_inv = scaler_y.inverse_transform(y_test_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"Predictions generated successfully! / 预测生成成功！\")\n",
    "print(f\"\\nSample predictions (first 5) / 预测样本（前5个）:\")\n",
    "print(f\"Actual / 实际:    {y_test_actual[:5]}\")\n",
    "print(f\"Predicted / 预测: {y_test_pred_inv[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics-header",
   "metadata": {},
   "source": [
    "### 7.2 计算评估指标 / Calculate Evaluation Metrics\n",
    "\n",
    "计算标准回归指标以评估模型性能\n",
    "\n",
    "Compute standard regression metrics to assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, set_name='Test'):\n",
    "    \"\"\"\n",
    "    Calculate and display regression metrics\n",
    "    计算并显示回归指标\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"\\n{set_name} Set Performance Metrics / {set_name}集性能指标:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"MSE (Mean Squared Error):        {mse:.4f}\")\n",
    "    print(f\"RMSE (Root Mean Squared Error):  {rmse:.4f}\")\n",
    "    print(f\"MAE (Mean Absolute Error):       {mae:.4f}\")\n",
    "    print(f\"R² Score:                        {r2:.4f}\")\n",
    "    print(f\"MAPE (Mean Absolute % Error):    {mape:.2f}%\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "# Calculate metrics for both sets / 计算两个集合的指标\n",
    "train_metrics = calculate_metrics(y_train_actual, y_train_pred_inv, 'Training / 训练')\n",
    "test_metrics = calculate_metrics(y_test_actual, y_test_pred_inv, 'Test / 测试')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-results-header",
   "metadata": {},
   "source": [
    "## 步骤 8: 结果可视化 / Step 8: Results Visualization\n",
    "\n",
    "### 8.1 实际值 vs 预测值 / Actual vs Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual / 绘制预测 vs 实际\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Test set - full view / 测试集 - 完整视图\n",
    "axes[0].plot(y_test_actual, label='Actual / 实际', alpha=0.7, linewidth=1.5)\n",
    "axes[0].plot(y_test_pred_inv, label='Predicted / 预测', alpha=0.7, linewidth=1.5)\n",
    "axes[0].set_title('Oil Temperature Prediction - Test Set (Full View) / 油温预测 - 测试集（完整视图）', fontsize=14)\n",
    "axes[0].set_xlabel('Time Step / 时间步')\n",
    "axes[0].set_ylabel('Oil Temperature (°C) / 油温 (°C)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test set - zoomed view (first 500 points) / 测试集 - 放大视图（前500个点）\n",
    "zoom_range = 500\n",
    "axes[1].plot(y_test_actual[:zoom_range], label='Actual / 实际', alpha=0.7, linewidth=1.5)\n",
    "axes[1].plot(y_test_pred_inv[:zoom_range], label='Predicted / 预测', alpha=0.7, linewidth=1.5)\n",
    "axes[1].set_title(f'Oil Temperature Prediction - Test Set (First {zoom_range} Points) / 油温预测 - 测试集（前{zoom_range}个点）', fontsize=14)\n",
    "axes[1].set_xlabel('Time Step / 时间步')\n",
    "axes[1].set_ylabel('Oil Temperature (°C) / 油温 (°C)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scatter-header",
   "metadata": {},
   "source": [
    "### 8.2 散点图：预测值 vs 实际值 / Scatter Plot: Predicted vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scatter-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot / 散点图\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test_actual, y_test_pred_inv, alpha=0.5, s=20)\n",
    "plt.plot([y_test_actual.min(), y_test_actual.max()], \n",
    "         [y_test_actual.min(), y_test_actual.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction / 完美预测')\n",
    "plt.xlabel('Actual Oil Temperature (°C) / 实际油温 (°C)', fontsize=12)\n",
    "plt.ylabel('Predicted Oil Temperature (°C) / 预测油温 (°C)', fontsize=12)\n",
    "plt.title('Predicted vs Actual Oil Temperature (Test Set) / 预测 vs 实际油温（测试集）', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residuals-header",
   "metadata": {},
   "source": [
    "### 8.3 残差分析 / Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residuals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals / 计算残差\n",
    "residuals = y_test_actual - y_test_pred_inv\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Residual plot / 残差图\n",
    "axes[0].scatter(y_test_pred_inv, residuals, alpha=0.5, s=20)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted Oil Temperature (°C) / 预测油温 (°C)')\n",
    "axes[0].set_ylabel('Residuals (°C) / 残差 (°C)')\n",
    "axes[0].set_title('Residual Plot / 残差图')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution / 残差分布\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residuals (°C) / 残差 (°C)')\n",
    "axes[1].set_ylabel('Frequency / 频率')\n",
    "axes[1].set_title('Distribution of Residuals / 残差分布')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual Statistics / 残差统计:\")\n",
    "print(f\"Mean / 均值: {residuals.mean():.4f}°C\")\n",
    "print(f\"Std / 标准差: {residuals.std():.4f}°C\")\n",
    "print(f\"Min / 最小值: {residuals.min():.4f}°C\")\n",
    "print(f\"Max / 最大值: {residuals.max():.4f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-header",
   "metadata": {},
   "source": [
    "## 步骤 9: 结论和总结 / Step 9: Conclusion and Summary\n",
    "\n",
    "### 模型性能总结 / Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary comparison / 创建总结对比\n",
    "summary_df = pd.DataFrame({\n",
    "    'Metric / 指标': ['MSE', 'RMSE', 'MAE', 'R²', 'MAPE (%)'],\n",
    "    'Training / 训练': [\n",
    "        train_metrics['MSE'],\n",
    "        train_metrics['RMSE'],\n",
    "        train_metrics['MAE'],\n",
    "        train_metrics['R2'],\n",
    "        train_metrics['MAPE']\n",
    "    ],\n",
    "    'Test / 测试': [\n",
    "        test_metrics['MSE'],\n",
    "        test_metrics['RMSE'],\n",
    "        test_metrics['MAE'],\n",
    "        test_metrics['R2'],\n",
    "        test_metrics['MAPE']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RNN MODEL PERFORMANCE SUMMARY / RNN 模型性能总结\")\n",
    "print(\"=\" * 60)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n### Key Observations / 关键观察:\")\n",
    "print(f\"1. The model achieves R² score of {test_metrics['R2']:.4f} on test set\")\n",
    "print(f\"   模型在测试集上达到 R² 分数 {test_metrics['R2']:.4f}\")\n",
    "print(f\"2. Average prediction error (MAE): {test_metrics['MAE']:.4f}°C\")\n",
    "print(f\"   平均预测误差 (MAE): {test_metrics['MAE']:.4f}°C\")\n",
    "print(f\"3. MAPE: {test_metrics['MAPE']:.2f}%\")\n",
    "\n",
    "if abs(train_metrics['R2'] - test_metrics['R2']) < 0.05:\n",
    "    print(\"4. Model shows good generalization (minimal overfitting)\")\n",
    "    print(\"   模型显示良好的泛化能力（过拟合最小）\")\n",
    "else:\n",
    "    print(\"4. Consider regularization or more data to reduce overfitting\")\n",
    "    print(\"   考虑正则化或更多数据以减少过拟合\")\n",
    "\n",
    "print(\"\\n### Model Architecture / 模型架构:\")\n",
    "print(f\"- Sequence Length / 序列长度: {seq_length} time steps (6 hours / 6小时)\")\n",
    "print(f\"- RNN Units / RNN 单元: {hidden_sizes}\")\n",
    "print(f\"- Total Parameters / 总参数数: {total_params:,}\")\n",
    "\n",
    "print(\"\\n### Next Steps / 下一步:\")\n",
    "print(\"1. Compare with other models (Linear Regression, Random Forest, MLP)\")\n",
    "print(\"   与其他模型比较（线性回归、随机森林、MLP）\")\n",
    "print(\"2. Try advanced architectures (LSTM, GRU)\")\n",
    "print(\"   尝试先进架构（LSTM、GRU）\")\n",
    "print(\"3. Experiment with different sequence lengths\")\n",
    "print(\"   尝试不同的序列长度\")\n",
    "print(\"4. Feature engineering to improve performance\")\n",
    "print(\"   特征工程以提高性能\")\n",
    "print(\"5. Compare with SOTA model (Informer)\")\n",
    "print(\"   与 SOTA 模型（Informer）比较\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model-header",
   "metadata": {},
   "source": [
    "### 可选：保存模型 / Optional: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save the model / 取消注释以保存模型\n",
    "# import os\n",
    "# os.makedirs('../models', exist_ok=True)\n",
    "# torch.save(model.state_dict(), '../models/rnn_model.pth')\n",
    "# print(\"Model saved to ../models/rnn_model.pth\")\n",
    "# print(\"模型已保存到 ../models/rnn_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
