# ETTæ•°æ®é›†è¯¦ç»†è°ƒç ”æŠ¥å‘Š
# ETT Dataset Research Report

---

**æŠ¥å‘Šæ—¥æœŸ / Report Date**: 2025å¹´10æœˆ / October 2025
**æŠ¥å‘Šç›®çš„ / Purpose**: ä¸ºMSI5001è¯¾ç¨‹é¡¹ç›®æä¾›æ•°æ®é›†èƒŒæ™¯å’ŒæŠ€æœ¯æ”¯æŒ
**ä½œè€… / Author**: MSI5001 Group Project Team

---

## ç›®å½• / Table of Contents

1. [æ•°æ®é›†æ¦‚è¿° / Dataset Overview](#1-æ•°æ®é›†æ¦‚è¿°--dataset-overview)
2. [æœ¬åœ°æ•°æ®é›†å¯¹æ¯”åˆ†æ / Local Dataset Comparison](#2-æœ¬åœ°æ•°æ®é›†å¯¹æ¯”åˆ†æ--local-dataset-comparison)
3. [å˜å‹å™¨ä¸šåŠ¡èƒŒæ™¯ / Transformer Business Context](#3-å˜å‹å™¨ä¸šåŠ¡èƒŒæ™¯--transformer-business-context)
4. [ç‰©ç†åŸç†ï¼šè´Ÿè½½-æ¸©åº¦å…³ç³» / Physics: Load-Temperature Relationship](#4-ç‰©ç†åŸç†è´Ÿè½½-æ¸©åº¦å…³ç³»--physics-load-temperature-relationship)
5. [æ•°æ®é›†è¯¦ç»†ä¿¡æ¯ / Dataset Details](#5-æ•°æ®é›†è¯¦ç»†ä¿¡æ¯--dataset-details)
6. [æŠ€æœ¯æ–¹æ³•æ¼”è¿› / Technical Methods Evolution](#6-æŠ€æœ¯æ–¹æ³•æ¼”è¿›--technical-methods-evolution)
7. [SOTAæ¨¡å‹ä¸åŸºå‡†ç»“æœ / SOTA Models & Benchmarks](#7-sotaæ¨¡å‹ä¸åŸºå‡†ç»“æœ--sota-models--benchmarks)
8. [è¯„ä¼°æŒ‡æ ‡ / Evaluation Metrics](#8-è¯„ä¼°æŒ‡æ ‡--evaluation-metrics)
9. [å‚è€ƒæ–‡çŒ® / References](#9-å‚è€ƒæ–‡çŒ®--references)

---

## 1. æ•°æ®é›†æ¦‚è¿° / Dataset Overview

### 1.1 ä»€ä¹ˆæ˜¯ETTæ•°æ®é›†ï¼Ÿ

**ETTï¼ˆElectricity Transformer Temperatureï¼Œç”µåŠ›å˜å‹å™¨æ¸©åº¦ï¼‰æ•°æ®é›†**æ˜¯ç”¨äºæ”¯æŒé•¿åºåˆ—æ—¶é—´åºåˆ—é¢„æµ‹ç ”ç©¶çš„æ ‡å‡†åŸºå‡†æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ç”±ä¸­å›½ä¸¤ä¸ªä¸åŒåœ°åŒºçš„å˜ç”µç«™é‡‡é›†ï¼Œæ¶µç›–2016å¹´7æœˆè‡³2018å¹´7æœˆçš„2å¹´æ•°æ®ã€‚

ETTæ•°æ®é›†æœ€åˆç”±Zhouç­‰äººåœ¨**AAAI 2021ä¼šè®®**ä¸Šå‘è¡¨çš„**Informerè®ºæ–‡**ä¸­å¼•å…¥ï¼Œè¯¥è®ºæ–‡è·å¾—äº†**AAAI 2021æœ€ä½³è®ºæ–‡å¥–**ã€‚æ­¤åï¼ŒETTæ•°æ®é›†å·²æˆä¸ºæ—¶é—´åºåˆ—é¢„æµ‹é¢†åŸŸæœ€å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ä¹‹ä¸€ï¼Œè¢«è¶…è¿‡**50ç¯‡ç ”ç©¶è®ºæ–‡**å¼•ç”¨ã€‚

### 1.1 What is the ETT Dataset?

The **ETT (Electricity Transformer Temperature) dataset** is a standard benchmark dataset collected to support the investigation of long sequence time-series forecasting problems. The dataset was collected from transformer substations in two different regions of China, covering 2 years of data from July 2016 to July 2018.

The ETT dataset was first introduced in the **Informer paper** published at **AAAI 2021** by Zhou et al., which received the **AAAI 2021 Best Paper Award**. Since then, the ETT dataset has become one of the most widely used benchmarks in time series forecasting, being cited in over **50 research papers**.

### 1.2 æ•°æ®é›†é‡è¦æ€§

- **å­¦æœ¯å½±å“åŠ›**: Informerè®ºæ–‡è·å¾—AAAI 2021æœ€ä½³è®ºæ–‡å¥–ï¼Œå¼•é¢†é•¿åºåˆ—æ—¶é—´åºåˆ—é¢„æµ‹ç ”ç©¶æ–¹å‘
- **å·¥ä¸šåº”ç”¨**: å˜å‹å™¨æ²¹æ¸©é¢„æµ‹å¯¹ç”µåŠ›ç³»ç»Ÿè¿ç»´è‡³å…³é‡è¦ï¼Œå¯é¢„é˜²è®¾å¤‡æŸåã€ä¼˜åŒ–ç»´æŠ¤è®¡åˆ’
- **ç ”ç©¶ä»·å€¼**: æ•°æ®åŒ…å«å¤šç§æ—¶é—´æ¨¡å¼ï¼ˆæ—¥å‘¨æœŸã€å‘¨å‘¨æœŸã€é•¿æœŸè¶‹åŠ¿ã€ä¸è§„åˆ™æ³¢åŠ¨ï¼‰ï¼Œéå¸¸é€‚åˆæµ‹è¯•æ¨¡å‹çš„é•¿æœŸä¾èµ–æ•è·èƒ½åŠ›

### 1.2 Dataset Importance

- **Academic Impact**: The Informer paper won the AAAI 2021 Best Paper Award, leading research in long sequence time-series forecasting
- **Industrial Application**: Transformer oil temperature prediction is critical for power system operations, preventing equipment damage and optimizing maintenance schedules
- **Research Value**: The data contains multiple temporal patterns (daily cycles, weekly cycles, long-term trends, irregular fluctuations), making it ideal for testing models' long-term dependency capture capabilities

### 1.3 æ•°æ®è·å–æ¸ é“

ETTæ•°æ®é›†åœ¨å¤šä¸ªå¹³å°å…¬å¼€å¯ç”¨ï¼š

| å¹³å° / Platform | é“¾æ¥ / URL | è¯´æ˜ / Description |
|----------------|------------|-------------------|
| **GitHub** | https://github.com/zhouhaoyi/ETDataset | åŸå§‹æ•°æ®æºï¼Œç”±ä½œè€…ç»´æŠ¤ / Original source, maintained by authors |
| **Hugging Face** | https://huggingface.co/datasets/ett | ä¾¿äºé›†æˆåˆ°MLæµç¨‹ / Easy integration into ML pipelines |
| **Kaggle** | Search "Electricity Transformer Dataset" | ç¤¾åŒºè®¨è®ºå’Œä»£ç ç¤ºä¾‹ / Community discussions and code examples |
| **Papers with Code** | https://paperswithcode.com/dataset/ett | åŸºå‡†ç»“æœå¯¹æ¯” / Benchmark results comparison |

---

## 2. æœ¬åœ°æ•°æ®é›†å¯¹æ¯”åˆ†æ / Local Dataset Comparison

### 2.1 æœ¬åœ°æ•°æ®é›†ç»Ÿè®¡

æˆ‘ä»¬çš„é¡¹ç›®ä½¿ç”¨äº†ä¸¤ä¸ªå˜å‹å™¨çš„æ•°æ®æ–‡ä»¶ï¼š

| æ–‡ä»¶å / File | æ•°æ®ç‚¹æ•°é‡ / Data Points | èµ·å§‹æ—¥æœŸ / Start Date | ç»“æŸæ—¥æœŸ / End Date | æ—¶é—´è·¨åº¦ / Duration |
|--------------|--------------------------|---------------------|-------------------|-------------------|
| `trans_1.csv` | 69,680 | 2018-07-01 00:00 | 2020-06-26 19:45 | çº¦2å¹´ / ~2 years |
| `trans_2.csv` | 69,680 | 2018-07-01 00:00 | 2020-06-26 19:45 | çº¦2å¹´ / ~2 years |

**é‡‡æ ·é¢‘ç‡ / Sampling Frequency**: 15åˆ†é’Ÿé—´éš” / 15-minute intervals
**ç‰¹å¾æ•°é‡ / Features**: 6ä¸ªåŠŸç‡è´Ÿè½½ç‰¹å¾ + 1ä¸ªæ²¹æ¸©ç›®æ ‡ / 6 power load features + 1 oil temperature target

### 2.1 Local Dataset Statistics

Our project uses data from two transformers:

The datasets contain **69,680 data points** each, spanning approximately 2 years with **15-minute sampling intervals**.

### 2.2 ä¸ETTæ ‡å‡†æ•°æ®é›†çš„å¯¹æ¯”

#### 2.2.1 ETTæ•°æ®é›†å˜ä½“

ETTæ•°æ®é›†æœ‰å¤šä¸ªç‰ˆæœ¬ï¼Œä¸»è¦åŒºåˆ«åœ¨äºé‡‡æ ·é¢‘ç‡ï¼š

| å˜ä½“ / Variant | é‡‡æ ·é¢‘ç‡ / Sampling | æ•°æ®ç‚¹æ•°é‡ / Data Points | è¯´æ˜ / Description |
|----------------|-------------------|------------------------|-------------------|
| **ETTh1, ETTh2** | 1å°æ—¶ / 1 hour | 17,520 | h = hourly (å°æ—¶çº§) |
| **ETTm1, ETTm2** | 15åˆ†é’Ÿ / 15 min | 70,080 | m = minute (åˆ†é’Ÿçº§) |

**è®¡ç®—éªŒè¯ / Calculation Verification**:
- ETTmæ ‡å‡†: 2å¹´ Ã— 365å¤© Ã— 24å°æ—¶ Ã— 4ï¼ˆæ¯å°æ—¶4ä¸ª15åˆ†é’Ÿï¼‰ = **70,080ä¸ªæ•°æ®ç‚¹**
- æœ¬åœ°æ•°æ®: **69,680ä¸ªæ•°æ®ç‚¹**
- å·®å¼‚: 400ä¸ªæ•°æ®ç‚¹ï¼ˆçº¦å 0.6%ï¼‰

#### 2.2.1 ETT Dataset Variants

The ETT dataset comes in multiple versions based on sampling frequency. The standard ETTm variant contains 70,080 data points, while our local dataset has 69,680 points.

#### 2.2.2 å¯¹æ¯”ç»“è®º

| å¯¹æ¯”é¡¹ / Comparison Item | ETTm1/m2 æ ‡å‡† / Standard | æœ¬åœ°æ•°æ®é›† / Local Dataset | åŒ¹é…åº¦ / Match |
|--------------------------|--------------------------|---------------------------|----------------|
| é‡‡æ ·é¢‘ç‡ / Sampling | 15åˆ†é’Ÿ / 15 min | 15åˆ†é’Ÿ / 15 min | âœ… å®Œå…¨åŒ¹é… / Perfect match |
| æ—¶é—´è·¨åº¦ / Duration | 2å¹´ / 2 years | çº¦2å¹´ / ~2 years | âœ… åŒ¹é… / Match |
| æ•°æ®ç‚¹æ•°é‡ / Data Points | 70,080 | 69,680 | âš ï¸ æ¥è¿‘ä½†ç•¥å°‘ / Close but slightly fewer |
| ç‰¹å¾ç»“æ„ / Features | 6 + 1 (OT) | 6 + 1 (OT) | âœ… å®Œå…¨åŒ¹é… / Perfect match |
| ç‰¹å¾åç§° / Feature Names | HUFL, HULL, MUFL, MULL, LUFL, LULL, OT | ç›¸åŒ / Same | âœ… å®Œå…¨åŒ¹é… / Perfect match |

**ç»“è®º / Conclusion**: æœ¬åœ°æ•°æ®é›†**ç±»ä¼¼äºETTmå˜ä½“**ï¼ˆ15åˆ†é’Ÿé‡‡æ ·ï¼‰ï¼Œè€Œ**ä¸æ˜¯ETThå˜ä½“**ï¼ˆ1å°æ—¶é‡‡æ ·ï¼‰ã€‚æ•°æ®ç‚¹æ•°é‡æ¥è¿‘æ ‡å‡†ETTmæ•°æ®é›†ï¼ˆå·®å¼‚<1%ï¼‰ï¼Œå¯èƒ½æ˜¯åŒæºæ•°æ®çš„å˜ä½“ç‰ˆæœ¬æˆ–ç»è¿‡è½»å¾®é¢„å¤„ç†çš„ç‰ˆæœ¬ã€‚

**Conclusion**: The local dataset is **similar to the ETTm variant** (15-minute sampling), not the ETTh variant (1-hour sampling). The data point count is close to the standard ETTm dataset (difference <1%), suggesting it may be a variant or lightly preprocessed version of the same source data.

### 2.3 æ•°æ®ç‰¹å¾å¯¹æ¯”

é€šè¿‡å¯¹æ¯”ä¸¤ä¸ªå˜å‹å™¨çš„æ•°å€¼èŒƒå›´ï¼Œæˆ‘ä»¬å‘ç°ï¼š

| ç‰¹å¾ / Feature | trans_1 èŒƒå›´ / Range | trans_2 èŒƒå›´ / Range | è¯´æ˜ / Notes |
|----------------|---------------------|---------------------|--------------|
| **HUFL** | 4.3 ~ 13.0 | 32.8 ~ 43.2 | trans_2æ•°å€¼çº¦ä¸ºtrans_1çš„3-4å€ |
| **OT (æ²¹æ¸©)** | 9.8 ~ 30.5Â°C | 27.2 ~ 45.3Â°C | trans_2è¿è¡Œæ¸©åº¦æ˜æ˜¾æ›´é«˜ |

è¿™ç§å·®å¼‚è¡¨æ˜ï¼š
- **trans_1** ç±»ä¼¼ETTm1ï¼Œå¯èƒ½æ˜¯è¾ƒå°å‹æˆ–è½»è½½å˜å‹å™¨
- **trans_2** ç±»ä¼¼ETTm2ï¼Œå¯èƒ½æ˜¯å¤§å‹æˆ–é‡è½½å˜å‹å™¨

### 2.3 Data Feature Comparison

Comparing the value ranges of the two transformers:

The differences suggest **trans_1** is similar to ETTm1 (smaller or lightly loaded transformer), while **trans_2** resembles ETTm2 (larger or heavily loaded transformer).

---

## 3. å˜å‹å™¨ä¸šåŠ¡èƒŒæ™¯ / Transformer Business Context

### 3.1 å˜å‹å™¨åœ¨ç”µåŠ›ç³»ç»Ÿä¸­çš„ä½œç”¨

**ç”µåŠ›å˜å‹å™¨ï¼ˆPower Transformerï¼‰**æ˜¯ç”µåŠ›ç³»ç»Ÿçš„æ ¸å¿ƒè®¾å¤‡ï¼Œè´Ÿè´£åœ¨ä¸åŒç”µå‹ç­‰çº§ä¹‹é—´è½¬æ¢ç”µèƒ½ï¼Œå®ç°ç”µèƒ½çš„é«˜æ•ˆä¼ è¾“å’Œåˆ†é…ã€‚

### 3.1 Role of Transformers in Power Systems

**Power Transformers** are core components of electrical power systems, responsible for converting electrical energy between different voltage levels to enable efficient transmission and distribution.

### 3.2 ç”µå‹ç­‰çº§ä½“ç³»

ç”µåŠ›ç³»ç»Ÿé‡‡ç”¨å¤šçº§ç”µå‹æ¶æ„ä»¥ä¼˜åŒ–é•¿è·ç¦»è¾“ç”µæ•ˆç‡ï¼š

#### 3.2.1 é«˜å‹ï¼ˆHigh Voltage, HVï¼‰

- **ç”µå‹èŒƒå›´**: >36 kVï¼ˆåƒä¼ï¼‰
- **åº”ç”¨åœºæ™¯**: é•¿è·ç¦»ç”µåŠ›ä¼ è¾“ï¼ˆå‘ç”µå‚ â†’ å˜ç”µç«™ï¼‰
- **ä¼˜ç‚¹**: é«˜å‹ä¼ è¾“å¯å‡å°‘çº¿è·¯æŸè€—ï¼ˆåŠŸç‡æŸè€— âˆ IÂ²Rï¼Œç”µå‹è¶Šé«˜åˆ™ç”µæµè¶Šå°ï¼‰
- **æ•°æ®é›†å¯¹åº”**: **HUFL**ï¼ˆé«˜å‹æœ‰ç”¨è´Ÿè½½ï¼‰ï¼Œ**HULL**ï¼ˆé«˜å‹æ— ç”¨è´Ÿè½½ï¼‰

#### 3.2.2 ä¸­å‹ï¼ˆMedium Voltage, MVï¼‰

- **ç”µå‹èŒƒå›´**: 5 kV ~ 35 kV
- **åº”ç”¨åœºæ™¯**: åŸå¸‚åŒºåŸŸé…ç”µç½‘ç»œ
- **åŠŸèƒ½**: ä»å˜ç”µç«™å‘å·¥ä¸šç”¨æˆ·æˆ–åŒºåŸŸé…ç”µç«™ä¼ è¾“ç”µåŠ›
- **æ•°æ®é›†å¯¹åº”**: **MUFL**ï¼ˆä¸­å‹æœ‰ç”¨è´Ÿè½½ï¼‰ï¼Œ**MULL**ï¼ˆä¸­å‹æ— ç”¨è´Ÿè½½ï¼‰

#### 3.2.3 ä½å‹ï¼ˆLow Voltage, LVï¼‰

- **ç”µå‹èŒƒå›´**: <1 kV
- **åº”ç”¨åœºæ™¯**: ç»ˆç«¯ç”¨æˆ·ï¼ˆå®¶åº­ã€å•†ä¸šå»ºç­‘ï¼‰
- **åŠŸèƒ½**: å°†ç”µå‹é™è‡³è®¾å¤‡å¯ç”¨çš„å®‰å…¨æ°´å¹³ï¼ˆå¦‚220Væˆ–110Vï¼‰
- **æ•°æ®é›†å¯¹åº”**: **LUFL**ï¼ˆä½å‹æœ‰ç”¨è´Ÿè½½ï¼‰ï¼Œ**LULL**ï¼ˆä½å‹æ— ç”¨è´Ÿè½½ï¼‰

### 3.2 Voltage Level Hierarchy

The power system uses a multi-level voltage architecture to optimize long-distance transmission efficiency:

| ç”µå‹ç­‰çº§ / Level | èŒƒå›´ / Range | ç”¨é€” / Purpose | ç¤ºä¾‹ / Example |
|-----------------|--------------|---------------|----------------|
| **é«˜å‹ / High Voltage** | >36 kV | é•¿è·ç¦»è¾“ç”µ / Long-distance transmission | 500 kV, 220 kV transmission lines |
| **ä¸­å‹ / Medium Voltage** | 5-35 kV | åŒºåŸŸé…ç”µ / Regional distribution | 10 kV, 35 kV urban networks |
| **ä½å‹ / Low Voltage** | <1 kV | ç»ˆç«¯ç”¨ç”µ / End-user consumption | 220V, 380V household/commercial |

**ç”µåŠ›æµå‘ / Power Flow**: å‘ç”µå‚ï¼ˆé«˜å‹ï¼‰â†’ å˜ç”µç«™ï¼ˆé™å‹ï¼‰â†’ é…ç”µç½‘ï¼ˆä¸­å‹ï¼‰â†’ ç”¨æˆ·å˜å‹å™¨ï¼ˆé™è‡³ä½å‹ï¼‰â†’ ç»ˆç«¯ç”¨æˆ·

### 3.3 åŠŸç‡è´Ÿè½½ç±»å‹ï¼šæœ‰åŠŸåŠŸç‡ vs æ— åŠŸåŠŸç‡

#### 3.3.1 æœ‰ç”¨è´Ÿè½½ï¼ˆUseful Load = Active Power = æœ‰åŠŸåŠŸç‡ï¼‰

**å®šä¹‰**: å®é™…è½¬æ¢ä¸ºæœ‰ç”¨åŠŸçš„ç”µåŠŸç‡ï¼ˆå¦‚æœºæ¢°åŠŸã€å…‰èƒ½ã€çƒ­èƒ½ç­‰ï¼‰

**ç¬¦å·**: Pï¼Œå•ä½ä¸ºç“¦ç‰¹ï¼ˆWï¼‰æˆ–å…†ç“¦ï¼ˆMWï¼‰

**æ•°æ®é›†ä¸­çš„ç‰¹å¾**:
- **HUFL** (High Useful Load): é«˜å‹ä¾§æœ‰åŠŸåŠŸç‡
- **MUFL** (Medium Useful Load): ä¸­å‹ä¾§æœ‰åŠŸåŠŸç‡
- **LUFL** (Low Useful Load): ä½å‹ä¾§æœ‰åŠŸåŠŸç‡

**ç‰©ç†æ„ä¹‰**: è¿™éƒ¨åˆ†åŠŸç‡çœŸæ­£åšåŠŸï¼Œæ˜¯ç”¨æˆ·å®é™…æ¶ˆè€—çš„ç”µèƒ½ã€‚

#### 3.3.2 æ— ç”¨è´Ÿè½½ï¼ˆUseless Load = Reactive Power = æ— åŠŸåŠŸç‡ï¼‰

**å®šä¹‰**: ç”¨äºå»ºç«‹å’Œç»´æŒç”µç£åœºçš„åŠŸç‡ï¼Œä¸è½¬æ¢ä¸ºå…¶ä»–å½¢å¼çš„èƒ½é‡ï¼Œä½†åœ¨äº¤æµç³»ç»Ÿä¸­å¿…ä¸å¯å°‘ã€‚

**ç¬¦å·**: Qï¼Œå•ä½ä¸ºä¹ï¼ˆVARï¼‰æˆ–å…†ä¹ï¼ˆMVARï¼‰

**æ•°æ®é›†ä¸­çš„ç‰¹å¾**:
- **HULL** (High Useless Load): é«˜å‹ä¾§æ— åŠŸåŠŸç‡
- **MULL** (Medium Useless Load): ä¸­å‹ä¾§æ— åŠŸåŠŸç‡
- **LULL** (Low Useless Load): ä½å‹ä¾§æ— åŠŸåŠŸç‡

**ä¸ºä»€ä¹ˆå«"æ— ç”¨"ä½†åˆå¿…éœ€ï¼Ÿ**

è™½ç„¶æ— åŠŸåŠŸç‡æœ¬èº«ä¸åšåŠŸï¼Œä½†å®ƒå¯¹ç”µåŠ›ç³»ç»Ÿè‡³å…³é‡è¦ï¼š

1. **ç»´æŒç£åœº**: å˜å‹å™¨ã€ç”µæœºç­‰æ„Ÿæ€§è®¾å¤‡éœ€è¦æ— åŠŸåŠŸç‡æ¥å»ºç«‹ç£åœº
2. **ç”µå‹ç¨³å®š**: æ— åŠŸåŠŸç‡å½±å“ç³»ç»Ÿç”µå‹æ°´å¹³ï¼Œç¼ºä¹æ— åŠŸä¼šå¯¼è‡´ç”µå‹ä¸‹é™
3. **åŠŸç‡å› æ•°**: è¿‡å¤šæ— åŠŸåŠŸç‡ä¼šé™ä½åŠŸç‡å› æ•°ï¼Œå¢åŠ çº¿è·¯æŸè€—

**ç±»æ¯”ç†è§£**:
- æœ‰åŠŸåŠŸç‡ = å•¤é…’ï¼ˆçœŸæ­£å–åˆ°çš„éƒ¨åˆ†ï¼‰
- æ— åŠŸåŠŸç‡ = å•¤é…’æ³¡æ²«ï¼ˆçœ‹èµ·æ¥å ç©ºé—´ä½†ä¸å–ï¼Œä½†å•¤é…’æ²¡æœ‰æ³¡æ²«ä¸å®Œæ•´ï¼‰

### 3.3 Power Load Types: Active Power vs Reactive Power

#### Active Power (Useful Load)

**Definition**: The electrical power actually converted into useful work (mechanical work, light, heat, etc.)

**Symbol**: P, unit: Watt (W) or Megawatt (MW)

**In Dataset**: HUFL, MUFL, LUFL represent active power at high, medium, and low voltage sides

**Physical Meaning**: This is the power that truly does work and is what users actually consume.

#### Reactive Power (Useless Load)

**Definition**: Power used to establish and maintain electromagnetic fields, not converted into other forms of energy, but essential in AC systems.

**Symbol**: Q, unit: VAR (Volt-Ampere Reactive) or MVAR

**In Dataset**: HULL, MULL, LULL represent reactive power at high, medium, and low voltage sides

**Why "Useless" but Necessary?**

Though reactive power doesn't do work, it's crucial for power systems:

1. **Maintain Magnetic Fields**: Inductive devices (transformers, motors) need reactive power to establish magnetic fields
2. **Voltage Stability**: Reactive power affects system voltage levels; lack of it causes voltage drops
3. **Power Factor**: Excessive reactive power lowers power factor and increases line losses

**Analogy**:
- Active Power = Beer (the part you actually drink)
- Reactive Power = Foam (seems to take space without drinking, but beer without foam is incomplete)

---

## 4. ç‰©ç†åŸç†ï¼šè´Ÿè½½-æ¸©åº¦å…³ç³» / Physics: Load-Temperature Relationship

### 4.1 ä¸ºä»€ä¹ˆåŠŸç‡è´Ÿè½½ä¼šå½±å“æ²¹æ¸©ï¼Ÿ

å˜å‹å™¨æ²¹æ¸©çš„å‡é«˜ä¸»è¦æºäºå˜å‹å™¨è¿è¡Œæ—¶äº§ç”Ÿçš„**å†…éƒ¨æŸè€—**ï¼Œè¿™äº›æŸè€—è½¬åŒ–ä¸ºçƒ­é‡ã€‚è´Ÿè½½è¶Šå¤§ï¼ŒæŸè€—è¶Šå¤§ï¼Œå‘çƒ­è¶Šå¤šï¼Œæ²¹æ¸©è¶Šé«˜ã€‚

### 4.1 Why Does Power Load Affect Oil Temperature?

Transformer oil temperature rise primarily stems from **internal losses** during transformer operation, which convert into heat. Greater load â†’ greater losses â†’ more heat â†’ higher oil temperature.

### 4.2 å˜å‹å™¨æŸè€—çš„æ¥æº

å˜å‹å™¨çš„ä¸»è¦æŸè€—åŒ…æ‹¬ï¼š

#### 4.2.1 é“œæŸï¼ˆCopper Losses / Winding Lossesï¼‰

**å…¬å¼ / Formula**: P<sub>copper</sub> = IÂ² Ã— R

- **I**: ç»•ç»„ç”µæµï¼ˆä¸è´Ÿè½½æˆæ­£æ¯”ï¼‰/ Winding current (proportional to load)
- **R**: ç»•ç»„ç”µé˜» / Winding resistance

**ç‰¹ç‚¹**:
- **è´Ÿè½½ç›¸å…³**: è´Ÿè½½è¶Šå¤§ï¼Œç”µæµè¶Šå¤§ï¼Œé“œæŸæŒ‰ç”µæµçš„å¹³æ–¹å¢é•¿
- **ä¸»è¦çƒ­æº**: åœ¨é¢å®šè´Ÿè½½ä¸‹ï¼Œé“œæŸé€šå¸¸å æ€»æŸè€—çš„60-70%
- **ç›´æ¥å½±å“**: ç»•ç»„å‘çƒ­ç›´æ¥ä¼ å¯¼ç»™å‘¨å›´çš„å˜å‹å™¨æ²¹

#### 4.2.2 é“æŸï¼ˆIron Losses / Core Lossesï¼‰

åŒ…æ‹¬ï¼š
- **ç£æ»æŸè€—ï¼ˆHysteresis Lossï¼‰**: é“èŠ¯ç£åŒ–è¿‡ç¨‹ä¸­çš„èƒ½é‡æŸå¤±
- **æ¶¡æµæŸè€—ï¼ˆEddy Current Lossï¼‰**: é“èŠ¯ä¸­æ„Ÿåº”ç”µæµäº§ç”Ÿçš„æŸè€—

**ç‰¹ç‚¹**:
- **è´Ÿè½½æ— å…³**: åªè¦å˜å‹å™¨é€šç”µï¼Œæ— è®ºè´Ÿè½½å¤§å°ï¼Œé“æŸåŸºæœ¬æ’å®š
- **å æ¯”**: çº¦å æ€»æŸè€—çš„30-40%

#### 4.2.3 æ‚æ•£æŸè€—ï¼ˆStray Lossesï¼‰

- ç»•ç»„æ¶¡æµæŸè€—
- ç»“æ„éƒ¨ä»¶ï¼ˆæ²¹ç®±å£ã€èºæ “ç­‰ï¼‰çš„æ¶¡æµæŸè€—
- é€šå¸¸å æ€»æŸè€—çš„5-10%

### 4.2 Sources of Transformer Losses

#### Copper Losses (Winding Losses)

**Formula**: P<sub>copper</sub> = IÂ² Ã— R

**Characteristics**:
- **Load-dependent**: Higher load â†’ higher current â†’ copper loss increases quadratically
- **Main heat source**: At rated load, copper losses typically account for 60-70% of total losses
- **Direct impact**: Winding heat directly conducts to surrounding transformer oil

#### Iron Losses (Core Losses)

Includes:
- **Hysteresis Loss**: Energy loss during core magnetization
- **Eddy Current Loss**: Losses from induced currents in the core

**Characteristics**:
- **Load-independent**: Constant as long as transformer is energized
- **Proportion**: ~30-40% of total losses

#### Stray Losses

- Winding eddy current losses
- Structural component losses (tank walls, bolts, etc.)
- Typically 5-10% of total losses

### 4.3 çƒ­ä¼ å¯¼è¿‡ç¨‹

å˜å‹å™¨çš„çƒ­é‡ä¼ é€’éµå¾ªä»¥ä¸‹è·¯å¾„ï¼š

```
ç»•ç»„å‘çƒ­ â†’ çƒ­é‡ä¼ é€’ç»™æ²¹æ¶² â†’ æ²¹æ¶²å¯¹æµå¾ªç¯ â†’ æ•£çƒ­å™¨/æ²¹ç®±å£æ•£çƒ­åˆ°ç¯å¢ƒ
Winding Heat â†’ Heat Transfer to Oil â†’ Oil Convection â†’ Radiator/Tank Wall Heat Dissipation
```

#### 4.3.1 çƒ­ä¼ å¯¼é˜¶æ®µ

- **ç»•ç»„ â†’ æ²¹æ¶²**: ç»•ç»„æ¸©åº¦é«˜äºæ²¹æ¸©ï¼Œçƒ­é‡é€šè¿‡çƒ­ä¼ å¯¼ä¼ é€’ç»™å‘¨å›´æ²¹æ¶²
- **æ²¹æ¶²æ€§è´¨å½±å“**: æ²¹çš„çƒ­å¯¼ç‡ï¼ˆThermal Conductivityï¼‰å†³å®šä¼ çƒ­æ•ˆç‡

#### 4.3.2 å¯¹æµå¾ªç¯é˜¶æ®µ

- **è‡ªç„¶å¯¹æµ**: çƒ­æ²¹å¯†åº¦é™ä½ï¼Œå‘ä¸ŠæµåŠ¨ï¼›å†·æ²¹ä¸‹æ²‰ï¼Œå½¢æˆå¾ªç¯
- **å¼ºåˆ¶å¾ªç¯**: å¤§å‹å˜å‹å™¨ä½¿ç”¨æ²¹æ³µå¼ºåˆ¶å¾ªç¯ä»¥æé«˜æ•£çƒ­æ•ˆç‡
- **æ²¹æ¶²æ€§è´¨å½±å“**: ç²˜åº¦ï¼ˆViscosityï¼‰å½±å“æµåŠ¨æ€§ï¼Œæ¯”çƒ­å®¹ï¼ˆSpecific Heat Capacityï¼‰å½±å“å¸çƒ­èƒ½åŠ›

#### 4.3.3 æ•£çƒ­é˜¶æ®µ

- **æ•£çƒ­å™¨**: å¢å¤§ä¸ç©ºæ°”æ¥è§¦é¢ç§¯
- **æ²¹ç®±å£**: çƒ­é‡é€šè¿‡æ²¹ç®±å£è¾å°„å’Œå¯¹æµæ•£çƒ­åˆ°ç¯å¢ƒ
- **ç¯å¢ƒå½±å“**: ç¯å¢ƒæ¸©åº¦è¶Šé«˜ï¼Œæ•£çƒ­è¶Šå›°éš¾

### 4.3 Heat Transfer Process

Heat transfer in transformers follows this pathway:

```
Winding Heat â†’ Heat Transfer to Oil â†’ Oil Convection â†’ Radiator/Tank Wall Dissipation to Environment
```

The process includes:
1. **Conduction**: Winding â†’ Oil (thermal conductivity matters)
2. **Convection**: Hot oil rises, cold oil sinks (viscosity and specific heat capacity matter)
3. **Dissipation**: Radiator/tank wall â†’ Environment (ambient temperature matters)

### 4.4 è´Ÿè½½-æ¸©åº¦æ•°å­¦å…³ç³»

æ ¹æ®**IEEE C57.91**å’Œ**IEC 60076-7**æ ‡å‡†ï¼Œå˜å‹å™¨æ²¹æ¸©å¯ç”¨å¾®åˆ†æ–¹ç¨‹å»ºæ¨¡ï¼š

**ç®€åŒ–æ¨¡å‹ / Simplified Model**:

```
Î”T_oil = Î”T_oil_rated Ã— [(KÂ² Ã— R + 1) / (R + 1)]^n
```

å…¶ä¸­ / Where:
- **Î”T_oil**: æ²¹æ¸©å‡é«˜ / Oil temperature rise
- **K**: è´Ÿè½½ç³»æ•°ï¼ˆå®é™…è´Ÿè½½/é¢å®šè´Ÿè½½ï¼‰/ Load factor (actual load / rated load)
- **R**: è´Ÿè½½æŸè€—ä¸ç©ºè½½æŸè€—çš„æ¯”ç‡ / Ratio of load loss to no-load loss
- **n**: ç»éªŒæŒ‡æ•°ï¼ˆé€šå¸¸ä¸º0.8-1.0ï¼‰/ Empirical exponent (typically 0.8-1.0)

**å…³é”®æ´å¯Ÿ / Key Insights**:

1. **éçº¿æ€§å…³ç³»**: æ²¹æ¸©ä¸ä¸è´Ÿè½½çº¿æ€§ç›¸å…³ï¼Œè€Œæ˜¯æŒ‰æŒ‡æ•°å¢é•¿
2. **è´Ÿè½½å¹³æ–¹é¡¹**: ç”±äºé“œæŸ âˆ IÂ²ï¼Œè´Ÿè½½ç¿»å€å¯èƒ½å¯¼è‡´æ²¹æ¸©å¢åŠ è¶…è¿‡2å€
3. **æ—¶é—´å»¶è¿Ÿ**: æ²¹æ¸©å˜åŒ–å…·æœ‰çƒ­æƒ¯æ€§ï¼ˆæ—¶é—´å¸¸æ•°çº¦ä¸ºæ•°å°æ—¶ï¼‰ï¼Œè¿™ä½¿å¾—é¢„æµ‹æ›´å…·æŒ‘æˆ˜æ€§

### 4.4 Load-Temperature Mathematical Relationship

According to **IEEE C57.91** and **IEC 60076-7** standards, transformer oil temperature can be modeled using differential equations.

**Key Insights**:

1. **Nonlinear Relationship**: Oil temperature doesn't scale linearly with load but grows exponentially
2. **Quadratic Load Term**: Due to copper losses âˆ IÂ², doubling the load may increase oil temperature by more than 2Ã—
3. **Time Delay**: Oil temperature changes have thermal inertia (time constant ~hours), making prediction challenging

### 4.5 ä¸ºä»€ä¹ˆéœ€è¦é¢„æµ‹æ²¹æ¸©ï¼Ÿ

#### 4.5.1 è®¾å¤‡ä¿æŠ¤

- **è¿‡çƒ­æŸå**: æ²¹æ¸©è¿‡é«˜ï¼ˆ>100Â°Cï¼‰ä¼šåŠ é€Ÿç»ç¼˜è€åŒ–ï¼Œç¼©çŸ­å˜å‹å™¨å¯¿å‘½
- **çƒ­ç‚¹æ¸©åº¦**: æ²¹æ¸©æ˜¯ä¼°ç®—ç»•ç»„çƒ­ç‚¹æ¸©åº¦çš„å…³é”®å‚æ•°

#### 4.5.2 è¿ç»´ä¼˜åŒ–

- **è´Ÿè½½ä¼˜åŒ–**: é¢„æµ‹æ²¹æ¸©å¯æŒ‡å¯¼è°ƒåº¦å‘˜åˆç†åˆ†é…è´Ÿè½½
- **ç»´æŠ¤è®¡åˆ’**: æå‰è¯†åˆ«å¼‚å¸¸æ¸©å‡ï¼Œå®‰æ’é¢„é˜²æ€§ç»´æŠ¤
- **ç»æµæ•ˆç›Š**: é¿å…ä¿å®ˆä¼°è®¡å¯¼è‡´çš„å®¹é‡æµªè´¹ï¼ŒåŒæ—¶é˜²æ­¢è¿‡è½½æŸå

### 4.5 Why Predict Oil Temperature?

#### Equipment Protection
- **Overheating Damage**: High oil temperature (>100Â°C) accelerates insulation aging, shortening transformer lifespan
- **Hot-spot Temperature**: Oil temperature is a key parameter for estimating winding hot-spot temperature

#### Operations Optimization
- **Load Optimization**: Predicting oil temperature guides dispatchers in load allocation
- **Maintenance Planning**: Early identification of abnormal temperature rises enables preventive maintenance
- **Economic Benefits**: Avoids capacity waste from conservative estimates while preventing overload damage

---

## 5. æ•°æ®é›†è¯¦ç»†ä¿¡æ¯ / Dataset Details

### 5.1 ç‰¹å¾è¯´æ˜

æ¯ä¸ªæ•°æ®ç‚¹åŒ…å«ä»¥ä¸‹7ä¸ªå­—æ®µï¼š

| ç‰¹å¾å / Feature | å…¨ç§° / Full Name | ä¸­æ–‡å«ä¹‰ / Chinese Meaning | å•ä½ / Unit | ç±»å‹ / Type |
|-----------------|------------------|---------------------------|------------|------------|
| **date** | Date and Time | æ—¶é—´æˆ³ | YYYY-MM-DD HH:MM:SS | ç´¢å¼• / Index |
| **HUFL** | High Useful Load | é«˜å‹ä¾§æœ‰åŠŸåŠŸç‡ | kW or MW | è¾“å…¥ / Input |
| **HULL** | High Useless Load | é«˜å‹ä¾§æ— åŠŸåŠŸç‡ | kVAR or MVAR | è¾“å…¥ / Input |
| **MUFL** | Medium Useful Load | ä¸­å‹ä¾§æœ‰åŠŸåŠŸç‡ | kW or MW | è¾“å…¥ / Input |
| **MULL** | Medium Useless Load | ä¸­å‹ä¾§æ— åŠŸåŠŸç‡ | kVAR or MVAR | è¾“å…¥ / Input |
| **LUFL** | Low Useful Load | ä½å‹ä¾§æœ‰åŠŸåŠŸç‡ | kW or MW | è¾“å…¥ / Input |
| **LULL** | Low Useless Load | ä½å‹ä¾§æ— åŠŸåŠŸç‡ | kVAR or MVAR | è¾“å…¥ / Input |
| **OT** | Oil Temperature | æ²¹æ¸©ï¼ˆç›®æ ‡å˜é‡ï¼‰ | Â°C | ç›®æ ‡ / Target |

### 5.2 æ•°æ®ç‰¹ç‚¹

#### 5.2.1 æ—¶é—´æ¨¡å¼

ETTæ•°æ®é›†åŒ…å«å¤šç§æ—¶é—´æ¨¡å¼ï¼š

- **çŸ­æœŸå‘¨æœŸæ€§**: æ¯æ—¥å‘¨æœŸï¼ˆ24å°æ—¶ï¼‰ï¼Œåæ˜ æ—¥å¸¸ç”¨ç”µæ¨¡å¼ï¼ˆç™½å¤©é«˜è´Ÿè½½ï¼Œå¤œé—´ä½è´Ÿè½½ï¼‰
- **ä¸­æœŸå‘¨æœŸæ€§**: æ¯å‘¨å‘¨æœŸï¼ˆ7å¤©ï¼‰ï¼Œå·¥ä½œæ—¥ä¸å‘¨æœ«çš„è´Ÿè½½å·®å¼‚
- **é•¿æœŸè¶‹åŠ¿**: å­£èŠ‚æ€§å˜åŒ–ï¼ˆå¤å­£ç©ºè°ƒè´Ÿè½½å¢åŠ ï¼Œå†¬å­£ä¾›æš–è´Ÿè½½å¢åŠ ï¼‰
- **ä¸è§„åˆ™æ³¢åŠ¨**: çªå‘äº‹ä»¶ã€å¤©æ°”å˜åŒ–ç­‰å¯¼è‡´çš„éšæœºæ³¢åŠ¨

#### 5.2.2 æ•°æ®è´¨é‡

- **å®Œæ•´æ€§**: æ•°æ®å‡ ä¹æ— ç¼ºå¤±å€¼
- **é‡‡æ ·é¢‘ç‡**: ETTm1/m2æ¯15åˆ†é’Ÿé‡‡æ ·ä¸€æ¬¡ï¼ŒETTh1/h2æ¯å°æ—¶é‡‡æ ·ä¸€æ¬¡
- **æ—¶é—´è·¨åº¦**: 2å¹´æ•°æ®è¶³ä»¥è¦†ç›–å¤šä¸ªå­£èŠ‚å‘¨æœŸ

### 5.2 Data Characteristics

#### Temporal Patterns

The ETT dataset contains multiple temporal patterns:

- **Short-term Periodicity**: Daily cycles (24 hours), reflecting daily electricity usage patterns
- **Medium-term Periodicity**: Weekly cycles (7 days), weekday vs. weekend load differences
- **Long-term Trends**: Seasonal variations (summer AC load increase, winter heating load increase)
- **Irregular Fluctuations**: Random variations due to sudden events, weather changes, etc.

#### Data Quality

- **Completeness**: Nearly no missing values
- **Sampling Frequency**: ETTm1/m2 sampled every 15 minutes, ETTh1/h2 every hour
- **Time Span**: 2 years of data sufficient to cover multiple seasonal cycles

### 5.3 æ•°æ®é¢„å¤„ç†å»ºè®®

æ ¹æ®è¯¾ç¨‹è¦æ±‚å’Œæœ€ä½³å®è·µï¼š

1. **æ•°æ®åˆ†å‰²**:
   - è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›† = 12/4/4ä¸ªæœˆï¼ˆETTæ ‡å‡†ï¼‰
   - æˆ– 80%/20% æ—¶é—´ç»„åˆ†å‰²ï¼ˆè¯¾ç¨‹å»ºè®®ï¼‰
   - **é‡è¦**: æ—¶é—´åºåˆ—æ•°æ®åº”æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²ï¼Œä¸èƒ½éšæœºæ‰“ä¹±

2. **å½’ä¸€åŒ–**:
   - æ¨èä½¿ç”¨æ ‡å‡†åŒ–ï¼ˆZ-score normalizationï¼‰: `(x - Î¼) / Ïƒ`
   - æ¯ä¸ªç‰¹å¾å•ç‹¬å½’ä¸€åŒ–
   - **æ³¨æ„**: ä½¿ç”¨è®­ç»ƒé›†ç»Ÿè®¡é‡å½’ä¸€åŒ–æµ‹è¯•é›†

3. **åºåˆ—ç”Ÿæˆ**:
   - **æ»‘åŠ¨çª—å£**: ä½¿ç”¨è¿‡å»Nä¸ªæ—¶é—´æ­¥é¢„æµ‹æœªæ¥1æ­¥æˆ–å¤šæ­¥
   - **é¢„æµ‹ä»»åŠ¡**:
     - 1å°æ—¶é¢„æµ‹: ä½¿ç”¨å‰Næ­¥é¢„æµ‹ç¬¬4æ­¥åçš„æ²¹æ¸©
     - 1å¤©é¢„æµ‹: é¢„æµ‹ç¬¬96æ­¥åçš„æ²¹æ¸©
     - 1å‘¨é¢„æµ‹: é¢„æµ‹ç¬¬672æ­¥åçš„æ²¹æ¸©

### 5.3 Data Preprocessing Recommendations

Based on course requirements and best practices:

1. **Data Splitting**:
   - Train/Val/Test = 12/4/4 months (ETT standard) or 80%/20% time-based split
   - **Important**: Time series data should be split chronologically, not randomly shuffled

2. **Normalization**:
   - Recommend Z-score normalization: `(x - Î¼) / Ïƒ`
   - Normalize each feature independently
   - **Note**: Use training set statistics to normalize test set

3. **Sequence Generation**:
   - **Sliding Window**: Use past N time steps to predict 1 or more future steps
   - **Prediction Tasks**:
     - 1-hour: Predict oil temperature 4 steps ahead
     - 1-day: Predict 96 steps ahead
     - 1-week: Predict 672 steps ahead

---

## 6. æŠ€æœ¯æ–¹æ³•æ¼”è¿› / Technical Methods Evolution

### 6.1 ä¼ ç»Ÿæ–¹æ³•ï¼ˆç‰©ç†æ¨¡å‹ï¼‰

#### 6.1.1 çƒ­å›è·¯æ¨¡å‹ï¼ˆThermal Circuit Modelï¼‰

åŸºäº**IEEE C57.91**å’Œ**IEC 60076-7**æ ‡å‡†ï¼Œä½¿ç”¨å¾®åˆ†æ–¹ç¨‹å»ºæ¨¡æ²¹æ¸©åŠ¨æ€ï¼š

**ä¼˜ç‚¹**:
- ç‰©ç†å¯è§£é‡Šæ€§å¼º
- ä¸éœ€è¦å¤§é‡å†å²æ•°æ®
- é€‚ç”¨äºå®æ—¶ç›‘æ§

**ç¼ºç‚¹**:
- éœ€è¦å‡†ç¡®çš„ç‰©ç†å‚æ•°ï¼ˆçƒ­æ—¶é—´å¸¸æ•°ã€ç»•ç»„ç”µé˜»ç­‰ï¼‰
- å¯¹éçº¿æ€§ã€ä¸è§„åˆ™æ¨¡å¼çš„æ‹Ÿåˆèƒ½åŠ›å¼±
- éš¾ä»¥æ•æ‰å¤æ‚çš„ç¯å¢ƒå½±å“

### 6.1 Traditional Methods (Physical Models)

#### Thermal Circuit Models

Based on **IEEE C57.91** and **IEC 60076-7** standards, using differential equations to model oil temperature dynamics.

**Pros**: Strong physical interpretability, no need for large historical data, suitable for real-time monitoring
**Cons**: Requires accurate physical parameters, weak fitting for nonlinear/irregular patterns, difficult to capture complex environmental influences

### 6.2 ç»å…¸æœºå™¨å­¦ä¹ æ–¹æ³•

#### 6.2.1 éšæœºæ£®æ—ï¼ˆRandom Forestï¼‰

- **åŸç†**: é›†æˆå¤šæ£µå†³ç­–æ ‘ï¼ŒæŠ•ç¥¨æˆ–å¹³å‡é¢„æµ‹ç»“æœ
- **ä¼˜ç‚¹**: å¯¹éçº¿æ€§å…³ç³»å»ºæ¨¡èƒ½åŠ›å¼ºï¼Œé²æ£’æ€§å¥½ï¼Œå¯è§£é‡Šæ€§è¾ƒå¥½
- **ç¼ºç‚¹**: æ—¶é—´åºåˆ—ä¾èµ–å»ºæ¨¡è¾ƒå¼±ï¼Œéœ€è¦æ‰‹å·¥æå–æ—¶é—´ç‰¹å¾

#### 6.2.2 æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰

- **åŸç†**: å¯»æ‰¾æœ€ä¼˜è¶…å¹³é¢è¿›è¡Œå›å½’
- **ä¼˜ç‚¹**: å°æ ·æœ¬å­¦ä¹ èƒ½åŠ›å¼º
- **ç¼ºç‚¹**: è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥å¤„ç†é•¿åºåˆ—

**æ€§èƒ½**: åœ¨ETTæ•°æ®é›†ä¸Šï¼ŒRandom Foresté€šå¸¸å¯è¾¾åˆ°RÂ² â‰ˆ 0.55-0.65ï¼ˆ1å°æ—¶é¢„æµ‹ä»»åŠ¡ï¼‰

### 6.2 Classical Machine Learning Methods

#### Random Forest
- **Principle**: Ensemble of multiple decision trees, voting or averaging predictions
- **Pros**: Strong nonlinear modeling, good robustness, decent interpretability
- **Cons**: Weak time series dependency modeling, requires manual time feature extraction

**Performance**: On ETT dataset, Random Forest typically achieves RÂ² â‰ˆ 0.55-0.65 (1-hour prediction task)

### 6.3 æ·±åº¦å­¦ä¹ æ–¹æ³•

#### 6.3.1 RNNç³»åˆ—ï¼ˆå¾ªç¯ç¥ç»ç½‘ç»œï¼‰

**LSTM (Long Short-Term Memory)**:
- **åŸç†**: é€šè¿‡é—¨æ§æœºåˆ¶ï¼ˆé—å¿˜é—¨ã€è¾“å…¥é—¨ã€è¾“å‡ºé—¨ï¼‰è®°å¿†é•¿æœŸä¾èµ–
- **ä¼˜ç‚¹**: èƒ½æœ‰æ•ˆæ•æ‰æ—¶é—´åºåˆ—çš„é•¿æœŸæ¨¡å¼
- **ç¼ºç‚¹**: è®­ç»ƒè¾ƒæ…¢ï¼Œå‚æ•°é‡è¾ƒå¤§

**GRU (Gated Recurrent Unit)**:
- **åŸç†**: LSTMçš„ç®€åŒ–ç‰ˆï¼Œåªæœ‰æ›´æ–°é—¨å’Œé‡ç½®é—¨
- **ä¼˜ç‚¹**: å‚æ•°æ›´å°‘ï¼Œè®­ç»ƒæ›´å¿«ï¼Œæ€§èƒ½æ¥è¿‘LSTM
- **é€‚ç”¨åœºæ™¯**: è®¡ç®—èµ„æºæœ‰é™æ—¶çš„é¦–é€‰

**BiLSTM/BiGRU (åŒå‘)**:
- **åŸç†**: åŒæ—¶è€ƒè™‘å‰å‘å’Œåå‘æ—¶é—´ä¾èµ–
- **ä¼˜ç‚¹**: æ•æ‰æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- **æ³¨æ„**: ä»…é€‚ç”¨äºç¦»çº¿é¢„æµ‹ï¼ˆéœ€è¦æœªæ¥æ•°æ®ï¼‰

#### 6.3.2 Transformerç³»åˆ—

**Informer (AAAI 2021 Best Paper)**:
- **åˆ›æ–°ç‚¹**:
  1. **ProbSparseè‡ªæ³¨æ„åŠ›**: é™ä½è®¡ç®—å¤æ‚åº¦ä»O(LÂ²)åˆ°O(L log L)
  2. **è‡ªæ³¨æ„åŠ›è’¸é¦**: é€å±‚å‡å°‘åºåˆ—é•¿åº¦ï¼Œèšç„¦å…³é”®ä¿¡æ¯
  3. **ç”Ÿæˆå¼è§£ç å™¨**: ä¸€æ¬¡æ€§é¢„æµ‹é•¿åºåˆ—ï¼Œè€Œéé€æ­¥é¢„æµ‹
- **æ€§èƒ½**: åœ¨ETTæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºRNNå’Œä¼ ç»ŸTransformer
- **å½±å“**: å¼€åˆ›äº†é•¿åºåˆ—æ—¶é—´åºåˆ—é¢„æµ‹ç ”ç©¶æ–¹å‘

**PatchTST**:
- **åˆ›æ–°**: å°†æ—¶é—´åºåˆ—åˆ†å—ï¼ˆpatchï¼‰ï¼Œç±»ä¼¼ViTå¤„ç†å›¾åƒ
- **ä¼˜ç‚¹**: æ•æ‰å±€éƒ¨æ¨¡å¼ï¼Œå‡å°‘è®¡ç®—é‡

**xPatch (AAAI 2025 - Current SOTA)**:
- **åˆ›æ–°**: åŒæµæ¶æ„ + æŒ‡æ•°å­£èŠ‚-è¶‹åŠ¿åˆ†è§£
- **æ€§èƒ½**: åœ¨60%çš„æ•°æ®é›†ä¸Šè¾¾åˆ°SOTAï¼ˆMSEæŒ‡æ ‡ï¼‰

#### 6.3.3 æ··åˆæ¶æ„

**RNN-ResNet (æœ¬é¡¹ç›®å®ç°)**:
- **æ¶æ„**: RNNæå–æ—¶é—´ç‰¹å¾ â†’ ResNetæ·±åº¦å­¦ä¹ éçº¿æ€§æ˜ å°„
- **ä¼˜ç‚¹**: ç»“åˆRNNçš„æ—¶åºå»ºæ¨¡èƒ½åŠ›å’ŒResNetçš„æ·±åº¦è¡¨ç¤ºèƒ½åŠ›
- **é¢„æœŸæ€§èƒ½**: RÂ² â‰ˆ 0.62-0.72ï¼ˆ1å°æ—¶é¢„æµ‹ï¼‰

**CNN-BiGRU**:
- **æ¶æ„**: CNNæå–å±€éƒ¨æ¨¡å¼ â†’ BiGRUå»ºæ¨¡é•¿æœŸä¾èµ–
- **ä¼˜ç‚¹**: CNNåŠ é€Ÿç‰¹å¾æå–ï¼ŒBiGRUæ•æ‰å…¨å±€ä¾èµ–

### 6.3 Deep Learning Methods

#### RNN Series

**LSTM (Long Short-Term Memory)**:
- **Principle**: Remembers long-term dependencies via gating mechanisms (forget, input, output gates)
- **Pros**: Effectively captures long-term patterns in time series
- **Cons**: Slower training, more parameters

**GRU (Gated Recurrent Unit)**:
- **Principle**: Simplified LSTM with only update and reset gates
- **Pros**: Fewer parameters, faster training, performance close to LSTM

**BiLSTM/BiGRU (Bidirectional)**:
- **Principle**: Considers both forward and backward time dependencies
- **Note**: Only suitable for offline prediction (requires future data)

#### Transformer Series

**Informer (AAAI 2021 Best Paper)**:
- **Innovations**:
  1. **ProbSparse Self-Attention**: Reduces complexity from O(LÂ²) to O(L log L)
  2. **Self-Attention Distilling**: Layer-wise sequence length reduction, focusing on key information
  3. **Generative Decoder**: Predicts long sequences in one shot
- **Impact**: Pioneered long sequence time-series forecasting research

**xPatch (AAAI 2025 - Current SOTA)**:
- **Innovation**: Dual-stream architecture + exponential seasonal-trend decomposition
- **Performance**: Achieves SOTA on 60% of datasets (MSE metric)

#### Hybrid Architectures

**RNN-ResNet (Our Implementation)**:
- **Architecture**: RNN extracts temporal features â†’ ResNet deep nonlinear mapping
- **Pros**: Combines RNN's temporal modeling with ResNet's deep representation
- **Expected Performance**: RÂ² â‰ˆ 0.62-0.72 (1-hour prediction)

---

## 7. SOTAæ¨¡å‹ä¸åŸºå‡†ç»“æœ / SOTA Models & Benchmarks

### 7.1 å½“å‰SOTAæ¨¡å‹ï¼ˆ2024-2025ï¼‰

| æ¨¡å‹ / Model | ä¼šè®®/æœŸåˆŠ / Venue | å¹´ä»½ / Year | ä¸»è¦åˆ›æ–° / Key Innovation |
|--------------|------------------|------------|--------------------------|
| **xPatch** | AAAI | 2025 | åŒæµæ¶æ„ + æŒ‡æ•°å­£èŠ‚-è¶‹åŠ¿åˆ†è§£ / Dual-stream + exponential decomposition |
| **T3Time** | - | 2025 | ä¸‰æ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹ / Tri-modal time series forecasting |
| **TEMPO** | ICLR | 2024 | æ”¹è¿›çš„Patchæœºåˆ¶ / Improved patching mechanism |
| **Informer** | AAAI (Best Paper) | 2021 | ProbSparseæ³¨æ„åŠ› / ProbSparse attention |

### 7.2 ETTæ•°æ®é›†åŸºå‡†ç»“æœ

#### 7.2.1 ETTh1ï¼ˆ1å°æ—¶é‡‡æ ·ï¼‰- é¢„æµ‹çª—å£96æ­¥

| æ¨¡å‹ / Model | MSE | MAE | è¯´æ˜ / Notes |
|--------------|-----|-----|-------------|
| **xPatch** | 0.378 | 0.394 | å½“å‰æœ€ä½³ / Current best |
| **LiNo** | 0.379 | 0.395 | æ¥è¿‘SOTA / Close to SOTA |
| **Informer** | 0.388 | 0.419 | åŸºå‡†æ¨¡å‹ / Baseline |
| **DLinear** | 0.386 | 0.400 | ç®€å•ä½†æœ‰æ•ˆ / Simple but effective |

#### 7.2.2 ETTm1ï¼ˆ15åˆ†é’Ÿé‡‡æ ·ï¼‰- é¢„æµ‹çª—å£96æ­¥

| æ¨¡å‹ / Model | MSE | MAE | è¯´æ˜ / Notes |
|--------------|-----|-----|-------------|
| **TEMPO** | ~0.30 | ~0.35 | ç›¸æ¯”å‰ä½œæå‡19.1% / 19.1% improvement |
| **PatchTST** | ~0.33 | ~0.37 | Patchæœºåˆ¶ / Patching mechanism |
| **Informer** | ~0.38 | ~0.42 | å¼€åˆ›æ€§å·¥ä½œ / Pioneering work |

**æ³¨**: MSEå’ŒMAEçš„å…·ä½“æ•°å€¼ä¾èµ–äºæ•°æ®é¢„å¤„ç†å’Œå®éªŒè®¾ç½®ï¼Œä¸Šè¡¨ä¸ºæ–‡çŒ®ä¸­å…¸å‹ç»“æœçš„è¿‘ä¼¼å€¼ã€‚

### 7.2 ETT Dataset Benchmark Results

The table shows results for **ETTh1 (1-hour sampling)** with prediction window of 96 steps. Current SOTA is **xPatch** with MSE 0.378 and MAE 0.394.

**Note**: Specific MSE and MAE values depend on data preprocessing and experimental setup. The table shows approximate typical results from literature.

### 7.3 ä¸åŒé¢„æµ‹çª—å£çš„æ€§èƒ½å¯¹æ¯”

é¢„æµ‹çª—å£è¶Šé•¿ï¼Œä»»åŠ¡è¶Šå›°éš¾ï¼š

| é¢„æµ‹çª—å£ / Horizon | æ—¶é—´è·¨åº¦ / Duration (ETTh1) | å…¸å‹MSEèŒƒå›´ / Typical MSE Range |
|-------------------|---------------------------|-------------------------------|
| **96** | 4å¤© / 4 days | 0.38 - 0.50 |
| **192** | 8å¤© / 8 days | 0.42 - 0.60 |
| **336** | 14å¤© / 14 days | 0.45 - 0.70 |
| **720** | 30å¤© / 30 days | 0.48 - 0.85 |

**æ´å¯Ÿ / Insight**:
- é•¿åºåˆ—é¢„æµ‹ï¼ˆ720æ­¥ï¼‰æ¯”çŸ­åºåˆ—ï¼ˆ96æ­¥ï¼‰å›°éš¾çº¦50-70%ï¼ˆMSEå¢åŠ ï¼‰
- Transformerç³»åˆ—åœ¨é•¿åºåˆ—ä¸Šä¼˜åŠ¿æ›´æ˜æ˜¾

### 7.3 Performance Comparison Across Prediction Horizons

Longer prediction horizons are more challenging:

**Insight**:
- Long sequence prediction (720 steps) is ~50-70% harder than short sequence (96 steps) in terms of MSE increase
- Transformer-based models show greater advantage on long sequences

### 7.4 æœ¬é¡¹ç›®é¢„æœŸæ€§èƒ½

æ ¹æ®å®ç°çš„RNN-ResNetæ··åˆæ¨¡å‹ï¼š

| ä»»åŠ¡ / Task | é¢„æœŸRÂ² / Expected RÂ² | é¢„æœŸRMSE / Expected RMSE | è¯´æ˜ / Notes |
|-------------|---------------------|--------------------------|-------------|
| **1å°æ—¶é¢„æµ‹** | 0.62 - 0.72 | 4.0 - 5.0Â°C | ä¼˜äºRandom Forest (0.60) / Better than RF |
| **1å¤©é¢„æµ‹** | 0.40 - 0.55 | 5.0 - 6.0Â°C | ä¸­ç­‰éš¾åº¦ / Medium difficulty |
| **1å‘¨é¢„æµ‹** | 0.25 - 0.40 | 5.5 - 6.5Â°C | é«˜éš¾åº¦ / High difficulty |

**å¯¹æ¯”åŸºå‡†**:
- Random Forest: RÂ² â‰ˆ 0.60 (1å°æ—¶é¢„æµ‹)
- Pure ResNet: RÂ² â‰ˆ 0.55-0.65 (1å°æ—¶é¢„æµ‹)
- **RNN-ResNet**: RÂ² â‰ˆ 0.62-0.72 (é¢„æœŸ)

### 7.4 Expected Performance for Our Project

Based on the implemented RNN-ResNet hybrid model:

Our expected performance is **better than Random Forest (0.60)** and comparable to or better than pure ResNet, demonstrating the advantage of the hybrid architecture.

---

## 8. è¯„ä¼°æŒ‡æ ‡ / Evaluation Metrics

### 8.1 å¸¸ç”¨æŒ‡æ ‡å®šä¹‰

#### 8.1.1 å‡æ–¹è¯¯å·®ï¼ˆMSE - Mean Squared Errorï¼‰

**å…¬å¼ / Formula**:

```
MSE = (1/n) Ã— Î£(y_true - y_pred)Â²
```

**ç‰¹ç‚¹ / Characteristics**:
- **ä¼˜ç‚¹**: å¯¹å¤§è¯¯å·®æ•æ„Ÿï¼ˆè¯¯å·®å¹³æ–¹ï¼‰ï¼Œæ•°å­¦ä¸Šä¾¿äºä¼˜åŒ–
- **ç¼ºç‚¹**: å•ä½æ˜¯åŸå§‹å•ä½çš„å¹³æ–¹ï¼ˆå¦‚Â°CÂ²ï¼‰ï¼Œä¸ç›´è§‚
- **é€‚ç”¨**: å¸Œæœ›æƒ©ç½šå¤§è¯¯å·®æ—¶ä½¿ç”¨

#### 8.1.2 å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSE - Root Mean Squared Errorï¼‰

**å…¬å¼ / Formula**:

```
RMSE = âˆšMSE = âˆš[(1/n) Ã— Î£(y_true - y_pred)Â²]
```

**ç‰¹ç‚¹ / Characteristics**:
- **ä¼˜ç‚¹**: å•ä½ä¸åŸå§‹æ•°æ®ç›¸åŒï¼ˆå¦‚Â°Cï¼‰ï¼Œæ›´æ˜“ç†è§£
- **ç¼ºç‚¹**: ä»å¯¹å¤§è¯¯å·®æ•æ„Ÿ
- **é€‚ç”¨**: æŠ¥å‘Šé¢„æµ‹ç²¾åº¦ï¼Œæ–¹ä¾¿ä¸å®é™…æ¸©åº¦å¯¹æ¯”

#### 8.1.3 å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAE - Mean Absolute Errorï¼‰

**å…¬å¼ / Formula**:

```
MAE = (1/n) Ã— Î£|y_true - y_pred|
```

**ç‰¹ç‚¹ / Characteristics**:
- **ä¼˜ç‚¹**: å¯¹å¼‚å¸¸å€¼é²æ£’ï¼Œæ‰€æœ‰è¯¯å·®ç­‰æƒé‡
- **ç¼ºç‚¹**: æ•°å­¦ä¸Šä¸å¦‚MSEæ˜“äºä¼˜åŒ–
- **é€‚ç”¨**: éœ€è¦å‡è¡¡è¯„ä¼°æ‰€æœ‰æ ·æœ¬æ—¶ä½¿ç”¨

#### 8.1.4 å†³å®šç³»æ•°ï¼ˆRÂ² - R-squared / Coefficient of Determinationï¼‰

**å…¬å¼ / Formula**:

```
RÂ² = 1 - (SS_res / SS_tot)
  = 1 - [Î£(y_true - y_pred)Â² / Î£(y_true - È³)Â²]
```

**ç‰¹ç‚¹ / Characteristics**:
- **å–å€¼èŒƒå›´**: (-âˆ, 1]ï¼Œå…¶ä¸­1è¡¨ç¤ºå®Œç¾é¢„æµ‹
- **ä¼˜ç‚¹**: æ— é‡çº²ï¼Œä¾¿äºè·¨æ•°æ®é›†æ¯”è¾ƒ
- **è§£é‡Š**: è¡¨ç¤ºæ¨¡å‹è§£é‡Šäº†å¤šå°‘ç›®æ ‡å˜é‡çš„æ–¹å·®
- **é€‚ç”¨**: è¯„ä¼°æ¨¡å‹æ•´ä½“æ‹Ÿåˆåº¦

### 8.1 Common Metrics Definitions

#### MSE (Mean Squared Error)
- **Pros**: Sensitive to large errors, mathematically convenient for optimization
- **Cons**: Unit is squared (e.g., Â°CÂ²), not intuitive

#### RMSE (Root Mean Squared Error)
- **Pros**: Same unit as original data, easier to understand
- **Cons**: Still sensitive to large errors

#### MAE (Mean Absolute Error)
- **Pros**: Robust to outliers, equal weight to all errors
- **Cons**: Mathematically less convenient than MSE for optimization

#### RÂ² (R-squared)
- **Range**: (-âˆ, 1], where 1 indicates perfect prediction
- **Pros**: Dimensionless, easy to compare across datasets
- **Interpretation**: Proportion of target variable variance explained by the model

### 8.2 æŒ‡æ ‡å¯¹æ¯”ä¸é€‰æ‹©

| æŒ‡æ ‡ / Metric | å¯¹å¼‚å¸¸å€¼æ•æ„Ÿåº¦ / Outlier Sensitivity | å¯è§£é‡Šæ€§ / Interpretability | ä¼˜åŒ–éš¾åº¦ / Optimization Difficulty | æ¨èåœºæ™¯ / Recommended Use Case |
|--------------|-------------------------------------|----------------------------|----------------------------------|-------------------------------|
| **MSE** | é«˜ / High | ä½ / Low | ä½ / Low | è®­ç»ƒæ—¶ä½œä¸ºæŸå¤±å‡½æ•° / Loss function during training |
| **RMSE** | é«˜ / High | é«˜ / High | ä½ / Low | æŠ¥å‘Šé¢„æµ‹ç²¾åº¦ / Reporting prediction accuracy |
| **MAE** | ä½ / Low | é«˜ / High | ä¸­ / Medium | å¼‚å¸¸å€¼è¾ƒå¤šæ—¶ / When outliers are present |
| **RÂ²** | ä¸­ / Medium | é«˜ / High | N/A | è¯„ä¼°æ•´ä½“æ‹Ÿåˆåº¦ / Evaluating overall fit |

### 8.2 Metric Comparison and Selection

**Recommendation**: Use **multiple metrics** together for comprehensive evaluation:
- **MSE** for training (loss function)
- **RMSE** for reporting (same unit as temperature)
- **RÂ²** for overall model quality assessment

### 8.3 ä¸ºä»€ä¹ˆä½¿ç”¨å¤šä¸ªæŒ‡æ ‡ï¼Ÿ

å•ä¸€æŒ‡æ ‡å¯èƒ½äº§ç”Ÿè¯¯å¯¼ï¼š

**æ¡ˆä¾‹ / Example**:
- æ¨¡å‹A: 99ä¸ªé¢„æµ‹è¯¯å·®ä¸º0.5Â°Cï¼Œ1ä¸ªè¯¯å·®ä¸º10Â°C
  - MSE â‰ˆ 1.23, RMSE â‰ˆ 1.11Â°C, MAE â‰ˆ 0.59Â°C
- æ¨¡å‹B: æ‰€æœ‰100ä¸ªé¢„æµ‹è¯¯å·®å‡ä¸º1Â°C
  - MSE = 1.00, RMSE = 1.00Â°C, MAE = 1.00Â°C

**åˆ†æ / Analysis**:
- ä»…çœ‹RMSEï¼Œæ¨¡å‹Bæ›´å¥½
- ä½†æ¨¡å‹Aåœ¨99%çš„æƒ…å†µä¸‹æ›´å‡†ç¡®
- **ç»“è®º**: éœ€ç»“åˆå¤šä¸ªæŒ‡æ ‡å’Œå®é™…åº”ç”¨åœºæ™¯åˆ¤æ–­

### 8.3 Why Use Multiple Metrics?

A single metric can be misleading. For example:
- Model A: 99 predictions with 0.5Â°C error, 1 with 10Â°C error â†’ RMSE â‰ˆ 1.11Â°C, MAE â‰ˆ 0.59Â°C
- Model B: All 100 predictions with 1Â°C error â†’ RMSE = 1.00Â°C, MAE = 1.00Â°C

**Conclusion**: Need to combine multiple metrics and consider real application scenarios.

---

## 9. å‚è€ƒæ–‡çŒ® / References

### 9.1 æ ¸å¿ƒè®ºæ–‡ / Core Papers

1. **Zhou, H., Zhang, S., Peng, J., Zhang, S., Li, J., Xiong, H., & Zhang, W. (2021)**.
   *Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting*.
   Proceedings of the AAAI Conference on Artificial Intelligence, 35(12), 11106-11115.
   **ğŸ† AAAI 2021 Best Paper Award**

2. **xPatch (2025)**.
   *xPatch: Dual-Stream Time Series Forecasting with Exponential Seasonal-Trend Decomposition*.
   Proceedings of the AAAI Conference on Artificial Intelligence, 2025.

3. **Nie, Y., et al. (2023)**.
   *A Time Series is Worth 64 Words: Long-term Forecasting with Transformers*.
   ICLR 2023. (PatchTST)

### 9.2 æ ‡å‡†æ–‡æ¡£ / Standard Documents

4. **IEEE C57.91-2011**.
   *IEEE Guide for Loading Mineral-Oil-Immersed Transformers and Step-Voltage Regulators*.
   Institute of Electrical and Electronics Engineers.

5. **IEC 60076-7:2018**.
   *Power transformers - Part 7: Loading guide for mineral-oil-immersed power transformers*.
   International Electrotechnical Commission.

### 9.3 æœ€æ–°ç ”ç©¶ / Recent Research (2024-2025)

6. **Boujamza, A., et al. (2025)**.
   *Predicting Oil Temperature in Electrical Transformers Using Neural Hierarchical Interpolation*.
   Journal of Engineering, 2025.

7. **Li, X., et al. (2024)**.
   *A New Deep Learning Architecture with Inductive Bias Balance for Transformer Oil Temperature Forecasting*.
   Journal of Big Data, 2023.

8. **Zhang, Y., et al. (2024)**.
   *Prediction of Transformer Oil Temperature Based on Feature Selection and Deep Neural Network*.
   IEEE Conference Publication, 2024.

### 9.4 æ•°æ®é›†èµ„æº / Dataset Resources

9. **ETT Dataset - GitHub**:
   https://github.com/zhouhaoyi/ETDataset

10. **ETT Dataset - Hugging Face**:
    https://huggingface.co/datasets/ett

11. **ETT Dataset - Papers with Code**:
    https://paperswithcode.com/dataset/ett

### 9.5 ç»¼è¿°ä¸æ•™ç¨‹ / Surveys and Tutorials

12. **Lim, B., & Zohren, S. (2021)**.
    *Time-series forecasting with deep learning: a survey*.
    Philosophical Transactions of the Royal Society A, 379(2194), 20200209.

13. **Torres, J. F., et al. (2021)**.
    *Deep learning for time series forecasting: a survey*.
    Big Data, 9(1), 3-21.

---

## é™„å½• / Appendix

### A. æœ¯è¯­å¯¹ç…§è¡¨ / Glossary

| ä¸­æ–‡ / Chinese | è‹±æ–‡ / English | ç¼©å†™ / Abbr. |
|---------------|----------------|--------------|
| ç”µåŠ›å˜å‹å™¨ | Power Transformer | - |
| æ²¹æ¸© | Oil Temperature | OT |
| æœ‰åŠŸåŠŸç‡ | Active Power / Real Power | P |
| æ— åŠŸåŠŸç‡ | Reactive Power | Q |
| è§†åœ¨åŠŸç‡ | Apparent Power | S |
| åŠŸç‡å› æ•° | Power Factor | PF |
| é«˜å‹ | High Voltage | HV |
| ä¸­å‹ | Medium Voltage | MV |
| ä½å‹ | Low Voltage | LV |
| é•¿åºåˆ—æ—¶é—´åºåˆ—é¢„æµ‹ | Long Sequence Time-Series Forecasting | LSTF |
| è‡ªæ³¨æ„åŠ›æœºåˆ¶ | Self-Attention Mechanism | - |
| å¾ªç¯ç¥ç»ç½‘ç»œ | Recurrent Neural Network | RNN |
| é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ | Long Short-Term Memory | LSTM |
| é—¨æ§å¾ªç¯å•å…ƒ | Gated Recurrent Unit | GRU |

### B. å¸¸è§é—®é¢˜ / FAQ

**Q1: ETThå’ŒETTmæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**
A: ETThæ˜¯1å°æ—¶é‡‡æ ·ï¼ˆ17,520ä¸ªæ•°æ®ç‚¹ï¼‰ï¼ŒETTmæ˜¯15åˆ†é’Ÿé‡‡æ ·ï¼ˆ70,080ä¸ªæ•°æ®ç‚¹ï¼‰ã€‚ETTmæ•°æ®æ›´ç»†ç²’åº¦ï¼Œæ›´é€‚åˆæ•æ‰çŸ­æœŸæ³¢åŠ¨ã€‚

**Q2: ä¸ºä»€ä¹ˆè¦é¢„æµ‹æ²¹æ¸©è€Œä¸æ˜¯ç»•ç»„æ¸©åº¦ï¼Ÿ**
A: æ²¹æ¸©æ›´å®¹æ˜“ç›´æ¥æµ‹é‡ï¼ˆé€šè¿‡æ¸©åº¦ä¼ æ„Ÿå™¨ï¼‰ï¼Œè€Œç»•ç»„æ¸©åº¦é€šå¸¸éœ€è¦é€šè¿‡æ²¹æ¸©é—´æ¥ä¼°ç®—ã€‚æ²¹æ¸©é¢„æµ‹å¯ä½œä¸ºç»•ç»„çƒ­ç‚¹æ¸©åº¦ä¼°ç®—çš„åŸºç¡€ã€‚

**Q3: æœ¬åœ°æ•°æ®é›†æ˜¯ETTm1è¿˜æ˜¯ETTm2ï¼Ÿ**
A: ä»æ•°å€¼èŒƒå›´çœ‹ï¼Œtrans_1ç±»ä¼¼ETTm1ï¼ˆæ•°å€¼è¾ƒå°ï¼‰ï¼Œtrans_2ç±»ä¼¼ETTm2ï¼ˆæ•°å€¼è¾ƒå¤§ï¼‰ã€‚ä½†æ•°æ®ç‚¹æ•°é‡ç•¥å°‘äºæ ‡å‡†ETTï¼ˆ69,680 vs 70,080ï¼‰ï¼Œå¯èƒ½æ˜¯å˜ä½“ç‰ˆæœ¬ã€‚

**Q4: åº”è¯¥é€‰æ‹©LSTMè¿˜æ˜¯GRUï¼Ÿ**
A: å¯¹äºæ²¹æ¸©é¢„æµ‹ä»»åŠ¡ï¼ŒGRUé€šå¸¸æ˜¯é¦–é€‰ï¼šè®­ç»ƒé€Ÿåº¦å¿«20-30%ï¼Œå‚æ•°å°‘ï¼Œæ€§èƒ½æ¥è¿‘LSTMã€‚ä»…å½“éœ€è¦æ•æ‰éå¸¸é•¿çš„ä¾èµ–å…³ç³»æ—¶æ‰è€ƒè™‘LSTMã€‚

---

**æŠ¥å‘Šç»“æŸ / End of Report**

---

**å£°æ˜ / Disclaimer**: æœ¬æŠ¥å‘ŠåŸºäºå…¬å¼€æ–‡çŒ®å’Œæ•°æ®é›†ä¿¡æ¯ç¼–å†™ï¼Œç”¨äºå­¦æœ¯ç ”ç©¶å’Œè¯¾ç¨‹é¡¹ç›®ã€‚æ‰€æœ‰å¼•ç”¨ä¿¡æ¯æˆªè‡³2025å¹´10æœˆï¼Œæœ€æ–°è¿›å±•è¯·å‚è€ƒç›¸å…³è®ºæ–‡å’Œæ•°æ®é›†å®˜æ–¹é¡µé¢ã€‚

**Disclaimer**: This report is based on publicly available literature and dataset information, intended for academic research and course projects. All cited information is current as of October 2025. For the latest developments, please refer to relevant papers and official dataset pages.
